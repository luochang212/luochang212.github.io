<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Hadoop streaming on Chang Luo</title>
    <link>http://luochang212.github.io/tags/hadoop-streaming/</link>
    <description>Recent content in Hadoop streaming on Chang Luo</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 25 Jul 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="http://luochang212.github.io/tags/hadoop-streaming/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>漫谈 Hadoop Streaming</title>
      <link>http://luochang212.github.io/posts/hadoop_intro/</link>
      <pubDate>Sat, 25 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>http://luochang212.github.io/posts/hadoop_intro/</guid>
      <description>Hadoop 是用 Java 写的，因此最原生的方法就是用 Java 编写 MapReduce 程序。但随着 Hadoop 的影响力在其他语言的使用者中扩大，他们也希望用自己的语言来编写 MapReduce 程序，由是 Hadoop Streaming 应运而生。它用 Unix pipeline 在任务间传递数据，使得我们几乎可以使用任何一个主流语言编写 MapReduce。
PS: 本文主要关注 Python 在 Hadoop Streaming 上的应用。
 过去半个多世纪，随着算力的高速增长，半导体工业似乎达到了它的物理极限，摩尔定律正在失效，寄托于更好更快的芯片来提高算力的期望正在落空。但业务的增长却不会因此而中止，人们亟需一个解决方案来满足对我们算力的渴求。
分布式计算似乎是个好主意。“当古人用一头牛拉不动一根原木时，他们从未想过培育更高更壮的牛。同样，我们也不需要尝试开发超级计算机，而应该试着结合使用更多的计算机系统。” (Haddop 权威指南)。但分布式计算的发展存在进程间交互、数据存储、分布式算法等瓶颈。Google 的几位工程师为了解决这些痛点，开发了 Hadoop。
Hadoop 是一个分布式计算框架，它建立在计算机集群上，负责协同集群上的机器共同工作。Hadoop 处理了分布式计算中的大部分难题，大量复杂细节都无需用户考虑，用户只需要告诉 hadoop 应该如何处理数据就可以了。
Hadoop 将数据处理抽象成 MapReduce 框架。顾名思义，MapReduce 包含了两个过程，Map 和 Reduce。Hadoop 编程，其实主要就是编写 MapReduce （以及一系列烦人的配置文件）。
 Note: 对 Hadoop 原理感兴趣的同学，可以看看这个 -&amp;gt; MapReduce: Simplified Data Processing on Large Clusters
 1. MapReduce OK，终于进入正题了。
MapReduce 的重要性不必详说。MapReduce 描述了数据在 Hadoop 中是如何被处理的。数据处理可大致分为三个过程：Map, Shuffle 和 Reduce。其中，Shuffle 由 Hadoop 完成，因此我们编写 Map 和 Reduce 就好。</description>
    </item>
    
  </channel>
</rss>