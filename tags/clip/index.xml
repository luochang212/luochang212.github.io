<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>CLIP on Chang Luo</title>
    <link>https://luochang212.github.io/tags/clip/</link>
    <description>Recent content in CLIP on Chang Luo</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 29 Dec 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://luochang212.github.io/tags/clip/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>搭建一款简单的『以文搜图』应用</title>
      <link>https://luochang212.github.io/posts/clip_app/</link>
      <pubDate>Sun, 29 Dec 2024 00:00:00 +0000</pubDate>
      <guid>https://luochang212.github.io/posts/clip_app/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;在手机相册搜索框中输入“笔记本电脑”时，即使照片本身并未包含“笔记本电脑”这几个字，相关图片依然能够被精准地检索出来。这说明现代相册 APP 不仅使用图片 OCR 文本来召回搜索结果。它综合使用了多种技术，包括多模态技术。&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;p&gt;本文使用多模态模型 CLIP 搭建一个简单的『以文搜图』应用，实现与相册 APP 类似的搜索效果。&lt;/p&gt;&#xA;&lt;p&gt;GitHub 项目地址：&lt;a href=&#34;https://github.com/luochang212/clip-app&#34; target=&#34;_blank&#34;&gt;clip-app&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;本文涉及的内容包括：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;用 FastAPI 搭建图文向量生成服务&lt;/li&gt;&#xA;&lt;li&gt;用 FastAPI 搭建 Faiss 向量搜索服务&lt;/li&gt;&#xA;&lt;li&gt;集成以上两个服务，实现『以文搜图』应用&lt;/li&gt;&#xA;&lt;li&gt;使用 &lt;code&gt;@torch.inference_mode()&lt;/code&gt; 装饰器，优化推理性能&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;✨ 如果你对多模态模型的效果有更高的要求，可以尝试 &lt;a href=&#34;https://huggingface.co/docs/transformers/en/model_doc/blip-2&#34; target=&#34;_blank&#34;&gt;BLIP-2&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;h2 id=&#34;一加载-clip-模型&#34;&gt;一、加载 CLIP 模型&lt;/h2&gt;&#xA;&lt;p&gt;加载 CLIP 模型，生成图文 Embedding。&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;获取文本 Embedding&lt;/li&gt;&#xA;&lt;li&gt;获取图像 Embedding&lt;/li&gt;&#xA;&lt;li&gt;多条文本对一张图片&lt;/li&gt;&#xA;&lt;li&gt;一条文本对多张图片&lt;/li&gt;&#xA;&lt;li&gt;多条文本对多张图片&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;br&gt;&#xA;&lt;center&gt;&#xA;&lt;button class=&#34;demo-btn&#34; onclick=&#34;window_on(&#39;https://nbviewer.org/github/luochang212/clip-app/blob/main/1.clip_model.ipynb&#39;)&#34;&gt;查看笔记&lt;/button&gt;&#xA;&lt;/center&gt;&#xA;&lt;br&gt;&#xA;&lt;h2 id=&#34;二faiss-向量搜索&#34;&gt;二、Faiss 向量搜索&lt;/h2&gt;&#xA;&lt;p&gt;用 FastAPI + Faiss 写一个向量检索服务 &lt;a href=&#34;https://github.com/luochang212/clip-app/blob/main/faiss/server.py&#34; target=&#34;_blank&#34;&gt;faiss/server.py&lt;/a&gt;，该服务提供两个接口：&lt;/p&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;路由名&lt;/th&gt;&#xA;          &lt;th&gt;描述&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;code&gt;add&lt;/code&gt;&lt;/td&gt;&#xA;          &lt;td&gt;用于向索引中添加新的 Embedding&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;code&gt;search&lt;/code&gt;&lt;/td&gt;&#xA;          &lt;td&gt;用于从索引中取回给定 Embedding 的最近邻 Embedding&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;br&gt;&#xA;&lt;center&gt;&#xA;&lt;button class=&#34;demo-btn&#34; onclick=&#34;window_on(&#39;https://nbviewer.org/github/luochang212/clip-app/blob/main/2.faiss_client.ipynb&#39;)&#34;&gt;查看笔记&lt;/button&gt;&#xA;&lt;/center&gt;&#xA;&lt;br&gt;&#xA;&lt;h2 id=&#34;三clip-向量生成&#34;&gt;三、CLIP 向量生成&lt;/h2&gt;&#xA;&lt;p&gt;用 FastAPI 写一个简单的 CLIP Embedding 生成服务 &lt;a href=&#34;https://github.com/luochang212/clip-app/blob/main/embedding/server.py&#34; target=&#34;_blank&#34;&gt;embedding/server.py&lt;/a&gt;。接口输入是图片、文本，输出是图文 Embedding。该服务提供 3 个 API 接口：&lt;/p&gt;</description>
    </item>
    <item>
      <title>Triton 部署 CLIP 图文 Embedding 推理服务</title>
      <link>https://luochang212.github.io/posts/clip_triton_server/</link>
      <pubDate>Sat, 30 Nov 2024 00:00:00 +0000</pubDate>
      <guid>https://luochang212.github.io/posts/clip_triton_server/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;本文介绍如何用 Triton 在多 GPU 环境下部署高性能 CLIP 推理服务。&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;p&gt;GitHub 项目地址：&lt;a href=&#34;https://github.com/luochang212/clip-server&#34; target=&#34;_blank&#34;&gt;clip-server&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;CLIP 是一个多模态模型。它能将图像和文本映射到同一个向量空间中，由此可以产生诸多应用。比如，通过计算图片与文本的相似性，可以用近似最近邻 (ANN) 从相册中检索与给定 query 语义相近的图片。此外，CLIP 的 Vision Encoder 可以作为特征提取器使用，用于生成的图像 Embedding。如果在 Vision Encoder 后加一个 fc 层，并且冻住骨干网络仅对 fc 层做训练，通常可以得到一个效果不错的图像分类器。&lt;/p&gt;&#xA;&lt;p&gt;本文涉及的内容包括：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;用 &lt;code&gt;transformers&lt;/code&gt; 库运行 &lt;code&gt;openai/clip-vit-base-patch32&lt;/code&gt; 的简单示例&lt;/li&gt;&#xA;&lt;li&gt;在 &lt;code&gt;titanic&lt;/code&gt; 数据集上训练一个 MLP 并导出成 ONNX 格式&lt;/li&gt;&#xA;&lt;li&gt;介绍如何安装预装了 Triton 的 Nvidia 官方 Docker 镜像 &lt;code&gt;&amp;amp;&lt;/code&gt; 启动容器&lt;/li&gt;&#xA;&lt;li&gt;介绍如何将 MLP 的 ONNX 模型配置到 Triton 模型仓库中&lt;/li&gt;&#xA;&lt;li&gt;写了一个简单的 &lt;a href=&#34;https://github.com/luochang212/clip-server/blob/main/utils.py#L108&#34; target=&#34;_blank&#34;&gt;客户端&lt;/a&gt; 用于获取 Triton 的推理结果&lt;/li&gt;&#xA;&lt;li&gt;介绍 Triton 的 Python Backend，其通常用于模型预处理和后处理&lt;/li&gt;&#xA;&lt;li&gt;用 Model Ensemble 组装 Python Backend 和 ONNX 组成完整的推理服务&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;✨ 注意：运行以下代码依赖 &lt;a href=&#34;https://github.com/luochang212/clip-server/blob/main/utils.py&#34; target=&#34;_blank&#34;&gt;utils.py&lt;/a&gt; 文件和 &lt;a href=&#34;https://github.com/luochang212/clip-server/blob/main/mlp.py&#34; target=&#34;_blank&#34;&gt;mlp.py&lt;/a&gt; 文件。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
