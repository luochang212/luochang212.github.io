<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Hungarian Algorithm on Chang Luo</title>
    <link>https://luochang212.github.io/tags/hungarian-algorithm/</link>
    <description>Recent content in Hungarian Algorithm on Chang Luo</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 19 Apr 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://luochang212.github.io/tags/hungarian-algorithm/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>DNN 模型聚类特征更新方法</title>
      <link>https://luochang212.github.io/posts/cluster_label_assign/</link>
      <pubDate>Sat, 19 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://luochang212.github.io/posts/cluster_label_assign/</guid>
      <description>本文探讨如何在 DNN 模型中天级更新聚类特征时，保持聚类标签的稳定性。&#xA;GitHub 项目地址：label-assignment&#xA;本文的主要内容包括：&#xA;使用 BLIP-2 将图片转为 embedding 使用匈牙利算法建立重训练标签到原标签的映射 开发以 样本重合率 为度量的方法 开发以 类心距离 为度量的方法 赋予 embedding 近似聚类 ID 的方法：最近邻法 时至今日，多塔模型仍以 ID 类特征为主。将模型特征以 raw data 的形式直接送入模型，效果往往不好。因此，我们通常先将特征 ID 化，然后用 mmh3 哈希打散后，再送入模型。其中，特征 ID 化 是一个重要步骤，如果 ID 的粒度太细，细到极致相当于每个样本一个 ID，这时样本就无法和与之相似的样本通过 ID 进行交互；如果 ID 的粒度太粗，则 ID 下的样本过多，此时模型无法从中学到指向足够明确的信息。&#xA;将模型特征 ID 化有很多方法，比如 聚类（无监督）、分类（有监督）、量化等等。本文仅讨论 聚类算法 及其在深度学习模型中的应用。&#xA;一、引子：频繁变更索引的代价 为了理解聚类算法产生的聚类 ID 是如何在深度模型中发生作用的，有必要介绍一下 嵌入层 (Embedding Layer) 的工作原理。&#xA;嵌入层是聚类 ID 与深度模型连接的桥梁。嵌入层的输入是聚类 ID，输出是该聚类 ID 对应的 embedding。在嵌入层中，聚类 ID 的每个枚举值都对应一个可学习的 embedding。如下图，假设聚类 ID 有 5 个枚举值 [0, 1, 2, 3, 4]，枚举值对应的索引分别为 idx0, idx1 &amp;hellip; idx4。当一个样本进入模型，它会根据聚类 id 号（比如 2 号）去找对应的索引（idx2），然后将索引下的 N 维 embedding 取回。嵌入层在有些地方也被称为码本 (codebook).</description>
    </item>
  </channel>
</rss>
