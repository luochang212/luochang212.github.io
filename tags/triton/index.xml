<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Triton on Chang Luo</title>
    <link>https://luochang212.github.io/tags/triton/</link>
    <description>Recent content in Triton on Chang Luo</description>
    <generator>Hugo</generator>
    <language>zh-cn</language>
    <lastBuildDate>Sat, 30 Nov 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://luochang212.github.io/tags/triton/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Triton 部署 CLIP 图文 Embedding 推理服务</title>
      <link>https://luochang212.github.io/posts/clip_triton_server/</link>
      <pubDate>Sat, 30 Nov 2024 00:00:00 +0000</pubDate>
      <guid>https://luochang212.github.io/posts/clip_triton_server/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;本文介绍如何用 Triton 在多 GPU 环境下部署高性能 CLIP 推理服务。&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;p&gt;GitHub 项目地址：&lt;a href=&#34;https://github.com/luochang212/clip-server&#34; target=&#34;_blank&#34;&gt;clip-server&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;CLIP 是一个多模态模型。它能将图像和文本映射到同一个向量空间中，由此可以产生诸多应用。比如，通过计算图片与文本的相似性，可以用近似最近邻 (ANN) 从相册中检索与给定 query 语义相近的图片。此外，CLIP 的 Vision Encoder 可以作为特征提取器使用，用于生成的图像 Embedding。如果在 Vision Encoder 后加一个 fc 层，并且冻住骨干网络仅对 fc 层做训练，通常可以得到一个效果不错的图像分类器。&lt;/p&gt;&#xA;&lt;p&gt;本文涉及的内容包括：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;用 &lt;code&gt;transformers&lt;/code&gt; 库运行 &lt;code&gt;openai/clip-vit-base-patch32&lt;/code&gt; 的简单示例&lt;/li&gt;&#xA;&lt;li&gt;在 &lt;code&gt;titanic&lt;/code&gt; 数据集上训练一个 MLP 并导出成 ONNX 格式&lt;/li&gt;&#xA;&lt;li&gt;介绍如何安装预装了 Triton 的 Nvidia 官方 Docker 镜像 &lt;code&gt;&amp;amp;&lt;/code&gt; 启动容器&lt;/li&gt;&#xA;&lt;li&gt;介绍如何将 MLP 的 ONNX 模型配置到 Triton 模型仓库中&lt;/li&gt;&#xA;&lt;li&gt;写了一个简单的 &lt;a href=&#34;https://github.com/luochang212/clip-server/blob/main/utils.py#L108&#34; target=&#34;_blank&#34;&gt;客户端&lt;/a&gt; 用于获取 Triton 的推理结果&lt;/li&gt;&#xA;&lt;li&gt;介绍 Triton 的 Python Backend，其通常用于模型预处理和后处理&lt;/li&gt;&#xA;&lt;li&gt;用 Model Ensemble 组装 Python Backend 和 ONNX 组成完整的推理服务&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;✨ 注意：运行以下代码依赖 &lt;a href=&#34;https://github.com/luochang212/clip-server/blob/main/utils.py&#34; target=&#34;_blank&#34;&gt;utils.py&lt;/a&gt; 文件和 &lt;a href=&#34;https://github.com/luochang212/clip-server/blob/main/mlp.py&#34; target=&#34;_blank&#34;&gt;mlp.py&lt;/a&gt; 文件。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
