<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Jupyter on Chang Luo</title>
    <link>https://luochang212.github.io/tags/jupyter/</link>
    <description>Recent content in Jupyter on Chang Luo</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 09 Jun 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://luochang212.github.io/tags/jupyter/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>注意力机制笔记</title>
      <link>https://luochang212.github.io/posts/attention_note/</link>
      <pubDate>Sun, 09 Jun 2024 00:00:00 +0000</pubDate>
      <guid>https://luochang212.github.io/posts/attention_note/</guid>
      <description>马毅：要想正确理解深度神经网络，就必须认识到其本质是学习高维数据中的低维结构的手段。从第一性原理出发，把目的和手段分清楚，其余的都很容易被统一、被解释。&#xA;从 Attention 的角度理解马毅老师这句话，Embedding 的时候本来就升维了，再做 QKV 就相当于在高维里面抽低维信息。而且 Q 也是可学习的，所以就既能学到好的抽取方法；对于每一种抽取方法，又能特别高效地抽取。&#xA;GitHub 项目地址：rnn-note / attention-note&#xA;一、语言模型入门：RNN 1.1 序列模型 马尔可夫假设，当前数据只跟最近 τ 个数据点相关。把最近 τ 个数据点作为特征，用 MLP 预测当前数据点的值。&#xA;查看笔记 1.2 文本预处理 对文本词元化 (tokenize) 并构建词表，就是把文本映射到从 0 开始的索引。&#xA;查看笔记 1.3 语言模型和数据集 对语料分批量 (batch) 处理。介绍了两种（batch 内的）采样策略：&#xA;随机采样策略：每个 batch 内的相邻子序列是随机的 顺序分区策略：每个 batch 内的相邻子序列是顺序的 查看笔记 1.4 循环神经网络的从零开始实现 每次输出仅由前一个隐状态和当前新输入 x 决定，是为 RNN。&#xA;提及的知识点：&#xA;独热编码：文本经过词元化后，还要经过 one-hot 处理，才能进入模型 困惑度：我们用困惑度来描述文本生成的质量，通过一个序列中所有的 n 个词元的交叉熵损失的平均值来衡量 $$\frac{1}{n} \sum_{t=1}^n-\log P\left(x_t \mid x_{t-1}, \ldots, x_1\right)$$ 梯度裁剪：对于 $T$ 长序列将产生 $O(T)$ 长矩阵乘法链。当 $T$ 较大时，可能导致数值不稳定，例如可能导致梯度爆炸或梯度消失。这种情况下优化算法可能无法收敛。下式通过将梯度 $g$ 投影回给定半径 $\theta$ 来限制梯度的大小。其中 $\frac{\theta}{|\mathbf{g}|}$ 可以理解为梯度 $g$ 的单位方向向量。 $$\mathbf{g} \leftarrow \min\left(1, \frac{\theta}{|\mathbf{g}|}\right) \mathbf{g}$$ 查看笔记 1.</description>
    </item>
    <item>
      <title>后台管理工具介绍</title>
      <link>https://luochang212.github.io/posts/process_manager/</link>
      <pubDate>Thu, 30 May 2024 00:00:00 +0000</pubDate>
      <guid>https://luochang212.github.io/posts/process_manager/</guid>
      <description>呀嘞呀嘞，我的 JupyterLab 怎么又挂了。&#xA;简单的 nohup [CMD] &amp;amp; 已经不够用，该研究一下后台管理工具了。&#xA;问了一下 Qwen，大概有五款后台管理工具可选。这五款工具又可以分两类：&#xA;进程管理器：systemd, pm2, supervisor 终端复用器：screen, tmux 总之，保持单个程序在后台运行，systemd 就够用。如果要维持多个后台程序，pm2 比较合适。screen 和 tmux 则是更临时的方案，适合偶尔用用的情况。&#xA;一、systemd 使用 systemd 管理 Jupyter lab 服务，必须先创建一个 systemd unit 文件来定义服务的启动、重启等行为。以下是创建 systemd 服务的步骤。&#xA;1.1 创建 unit 文件 用 vi 新建并打开 jupyterlab.service 文件：&#xA;sudo vi /etc/systemd/system/jupyterlab.service 配置如下：&#xA;[Unit] Description=Jupyter Lab After=network.target [Service] Type=simple User=[YOUR_USERNAME] ExecStart=/home/[YOUR_USERNAME]/miniconda3/bin/jupyter lab --ip=0.0.0.0 --port=443 --no-browser --allow-root WorkingDirectory=/home/[YOUR_USERNAME]/ Restart=on-failure RestartSec=8s [Install] WantedBy=multi-user.target 将 [YOUR_USERNAME] 替换为你的用户名。如果你在 root 上开服务，记得在 ExecStart 后加一个 --allow-root 如果你的服务不在 https 上，请用 --port=80 或 --port=8888 之类的其他端口 在 https 上搭建 jupyter lab 服务的方法，参见 在服务器上使用 JupyterLab 1.</description>
    </item>
    <item>
      <title>JupyterLab 中有哪些黑科技</title>
      <link>https://luochang212.github.io/posts/jupyter_lab/</link>
      <pubDate>Wed, 15 May 2024 00:00:00 +0000</pubDate>
      <guid>https://luochang212.github.io/posts/jupyter_lab/</guid>
      <description>JupyterLab 你是真的火了&amp;hellip;&#xA;5 月 14 号 OpenAI 春季发布会 出现了这个画面：&#xA;才知道 JupyterLab 是 OpenAI 的日常开发工具。感谢 OpenAI 亲自带货。&#xA;JupyterLab 拥有丰富的功能，并不只是 Python 解释器这么简单，让我来向你们展示它的强大！&#xA;〇、安装 JupyterLab 执行以下命令安装 JupyterLab：&#xA;mamba install -c conda-forge jupyterlab Note: mamba 是 miniforge 自带的包管理工具。大多数时候，你可以用 mamba 直接替代 conda，比如 mamba info --envs。使用 mamba 通常可以获得更高的下载速度。&#xA;一、制作 PPT 1.1 Notebook 转 PPT 只需两步，就能把 Notebook 转成 PPT：&#xA;设置 Slide Type：为保证页面被正确渲染，你需要设置 Cell 的 Slide Type。对于新版 Jupyter Lab，在右侧边栏上有带俩齿轮的按钮，点进去，然后一路点 [Property Inspector] -&amp;gt; [COMMON TOOLS] -&amp;gt; [Slide Type]，在这里对 Cell 进行设置。</description>
    </item>
  </channel>
</rss>
