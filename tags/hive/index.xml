<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Hive on Chang Luo</title>
    <link>https://luochang212.github.io/tags/hive/</link>
    <description>Recent content in Hive on Chang Luo</description>
    <generator>Hugo</generator>
    <language>zh-cn</language>
    <lastBuildDate>Sat, 15 Nov 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://luochang212.github.io/tags/hive/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>使用 Docker Compose 部署大数据集群：Spark &#43; Hadoop &#43; Hive &#43; JupyterLab</title>
      <link>https://luochang212.github.io/posts/bigdata_env/</link>
      <pubDate>Sat, 15 Nov 2025 00:00:00 +0000</pubDate>
      <guid>https://luochang212.github.io/posts/bigdata_env/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;麻雀虽小，五脏俱全。&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;p&gt;GitHub 项目地址：&lt;a href=&#34;https://github.com/luochang212/bigdata-env&#34; target=&#34;_blank&#34;&gt;bigdata-env&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h3 id=&#34;引子&#34;&gt;引子&lt;/h3&gt;&#xA;&lt;p&gt;我有两台树莓派。&lt;/p&gt;&#xA;&lt;p&gt;凭借超高颜值，安安静静地摆在那里，就是超绝桌搭。担心没有实用性？有的兄弟，包有的。装上 &lt;a href=&#34;https://jupyterlab.readthedocs.io/en/stable/&#34;&gt;JupyterLab&lt;/a&gt;，它是数据科学工作站；装上 &lt;a href=&#34;https://www.kali.org/&#34;&gt;Kali Linux&lt;/a&gt;，它是黑客界的瑞士军刀；装上 &lt;a href=&#34;https://github.com/ggml-org/llama.cpp&#34;&gt;llama.cpp&lt;/a&gt;，它是你的私有 LLM 推理服务器。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://luochang212.github.io/img/raspberry_pi_cluster.JPG&#34; alt=&#34;raspberry_pi_cluster&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;你可能不屑一顾，这些事一台树莓派也能搞定，何必弄两台呢？看来只有做一些两台机器才能办到的事，才算物尽其用。因此，我计划部署一个大数据集群。部署大数据集群是个技术活，不要期待一开始就在硬件上部署，可以先在 Docker Compose 上跑通，再尝试硬件部署。&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; 如果对装机过程感兴趣，可以参考我的博客&lt;a href=&#34;https://luochang212.github.io/posts/raspberry_pi_5/&#34;&gt;《树莓派 5 装机指南》&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;h3 id=&#34;一集群功能&#34;&gt;一、集群功能&lt;/h3&gt;&#xA;&lt;p&gt;「大数据集群」是个宽泛的词儿。&lt;/p&gt;&#xA;&lt;p&gt;装了 Spark 的，可以是大数据集群；装了 Spark + Hadoop 的，也可以是大数据集群。那么到底要装到什么程度呢？这取决于我们的需求。作为常年耕作在数据一线的工程师，我认为基础需求包括：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;必须能分布式计算&lt;/li&gt;&#xA;&lt;li&gt;必须能分布式存储&lt;/li&gt;&#xA;&lt;li&gt;必须可以建分区表&lt;/li&gt;&#xA;&lt;li&gt;必须能使用分布式机器学习库 &lt;a href=&#34;https://spark.apache.org/docs/latest/api/python/reference/pyspark.ml.html&#34;&gt;pyspark.ml&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;必须有调度工具（当然 crontab 也算）&lt;/li&gt;&#xA;&lt;li&gt;必须有 JupyterLab&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;我的目标是搭建一个满足这些需求的集群。当然，我们没有必要从零开始搭建，因为前人已经有很优秀的工作。只需要基于前人的工作做一些拓展，就能实现我们想要的功能。&lt;a href=&#34;https://github.com/s1mplecc&#34;&gt;s1mplecc&lt;/a&gt; 大佬的&lt;a href=&#34;https://s1mple.cc/2021/10/12/%E4%BD%BF%E7%94%A8-Docker-%E5%BF%AB%E9%80%9F%E9%83%A8%E7%BD%B2-Spark-Hadoop-%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%9B%86%E7%BE%A4/&#34;&gt;《使用 Docker 快速部署 Spark + Hadoop 大数据集群》&lt;/a&gt;就是一个很棒的基础工作。&lt;/p&gt;&#xA;&lt;p&gt;大佬已经实现了 &lt;a href=&#34;https://github.com/s1mplecc/spark-hadoop-docker&#34;&gt;Spark + Hadoop 集群&lt;/a&gt;，我只需要新增以下内容：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;沿用一主（Master）二从（Worker）的配置&lt;/li&gt;&#xA;&lt;li&gt;启用 Worker 节点的 DataNode 以支持数据同步&lt;/li&gt;&#xA;&lt;li&gt;安装 Hive 环境&lt;/li&gt;&#xA;&lt;li&gt;安装并初始化 miniconda3&lt;/li&gt;&#xA;&lt;li&gt;安装与 Spark 版本配适的 Python 和 PySpark&lt;/li&gt;&#xA;&lt;li&gt;安装 JupyterLab&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;主要增加了 Hive、JupyterLab 和 miniconda3。Hive 让我们更轻松地管理分区表；JupyterLab 提供了用于调试开发的浏览器界面；miniconda3 用作 Python 包管理。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
