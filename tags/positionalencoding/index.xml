<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>PositionalEncoding on Chang Luo</title>
    <link>https://luochang212.github.io/tags/positionalencoding/</link>
    <description>Recent content in PositionalEncoding on Chang Luo</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 09 Jun 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://luochang212.github.io/tags/positionalencoding/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>注意力机制笔记</title>
      <link>https://luochang212.github.io/posts/attention_note/</link>
      <pubDate>Sun, 09 Jun 2024 00:00:00 +0000</pubDate>
      <guid>https://luochang212.github.io/posts/attention_note/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://people.eecs.berkeley.edu/~yima/&#34; target=&#34;_blank&#34;&gt;马毅&lt;/a&gt;：要想正确理解深度神经网络，就必须认识到其本质是学习高维数据中的低维结构的手段。从第一性原理出发，把目的和手段分清楚，其余的都很容易被统一、被解释。&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;p&gt;从 Attention 的角度理解马毅老师这句话，Embedding 的时候本来就升维了，再做 QKV 就相当于在高维里面抽低维信息。而且 Q 也是可学习的，所以就既能学到好的抽取方法；对于每一种抽取方法，又能特别高效地抽取。&lt;/p&gt;&#xA;&lt;p&gt;GitHub 项目地址：&lt;a href=&#34;https://github.com/luochang212/rnn-note&#34; target=&#34;_blank&#34;&gt;rnn-note&lt;/a&gt; / &lt;a href=&#34;https://github.com/luochang212/attention-note&#34; target=&#34;_blank&#34;&gt;attention-note&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h3 id=&#34;一语言模型入门rnn-lstm-gru&#34;&gt;一、语言模型入门：RNN, LSTM, GRU&lt;/h3&gt;&#xA;&lt;h4 id=&#34;11-序列模型&#34;&gt;1.1 序列模型&lt;/h4&gt;&#xA;&lt;p&gt;马尔可夫假设，当前数据只跟最近 τ 个数据点相关。把最近 τ 个数据点作为特征，用 MLP 预测当前数据点的值。&lt;/p&gt;&#xA;&lt;br&gt;&#xA;&lt;center&gt;&#xA;&lt;button class=&#34;demo-btn&#34; onclick=&#34;window_on(&#39;https://nbviewer.org/github/luochang212/rnn-note/blob/main/1.序列模型.ipynb&#39;)&#34;&gt;查看笔记&lt;/button&gt;&#xA;&lt;/center&gt;&#xA;&lt;br&gt;&#xA;&lt;h4 id=&#34;12-文本预处理&#34;&gt;1.2 文本预处理&lt;/h4&gt;&#xA;&lt;p&gt;对文本词元化 (tokenize) 并构建词表，就是把文本映射到从 0 开始的索引。&lt;/p&gt;&#xA;&lt;br&gt;&#xA;&lt;center&gt;&#xA;&lt;button class=&#34;demo-btn&#34; onclick=&#34;window_on(&#39;https://nbviewer.org/github/luochang212/rnn-note/blob/main/2.文本预处理.ipynb&#39;)&#34;&gt;查看笔记&lt;/button&gt;&#xA;&lt;/center&gt;&#xA;&lt;br&gt;&#xA;&lt;h4 id=&#34;13-语言模型和数据集&#34;&gt;1.3 语言模型和数据集&lt;/h4&gt;&#xA;&lt;p&gt;对语料分批量 (batch) 处理。介绍了两种（batch 内的）采样策略：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;随机采样策略：每个 batch 内的相邻子序列是随机的&lt;/li&gt;&#xA;&lt;li&gt;顺序分区策略：每个 batch 内的相邻子序列是顺序的&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;br&gt;&#xA;&lt;center&gt;&#xA;&lt;button class=&#34;demo-btn&#34; onclick=&#34;window_on(&#39;https://nbviewer.org/github/luochang212/rnn-note/blob/main/3.语言模型和数据集.ipynb&#39;)&#34;&gt;查看笔记&lt;/button&gt;&#xA;&lt;/center&gt;&#xA;&lt;br&gt;&#xA;&lt;h4 id=&#34;14-循环神经网络的从零开始实现&#34;&gt;1.4 循环神经网络的从零开始实现&lt;/h4&gt;&#xA;&lt;p&gt;每次输出仅由前一个隐状态和当前新输入 x 决定，是为 RNN。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://luochang212.github.io/img/rnn_flow.svg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;提及的知识点：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;独热编码&lt;/strong&gt;：文本经过词元化后，还要经过 one-hot 处理，才能进入模型&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;困惑度&lt;/strong&gt;：我们用困惑度来描述文本生成的质量，通过一个序列中所有的 n 个词元的交叉熵损失的平均值来衡量&#xA;$$\frac{1}{n} \sum_{t=1}^n-\log P\left(x_t \mid x_{t-1}, \ldots, x_1\right)$$&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;梯度裁剪&lt;/strong&gt;：对于 $T$ 长序列将产生 $O(T)$ 长矩阵乘法链。当 $T$ 较大时，可能导致数值不稳定，例如可能导致梯度爆炸或梯度消失。这种情况下优化算法可能无法收敛。下式通过将梯度 $g$ 投影回给定半径 $\theta$ 来限制梯度的大小。其中 $\frac{\theta}{|\mathbf{g}|}$ 可以理解为梯度 $g$ 的单位方向向量。&#xA;$$\mathbf{g} \leftarrow \min\left(1, \frac{\theta}{|\mathbf{g}|}\right) \mathbf{g}$$&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;br&gt;&#xA;&lt;center&gt;&#xA;&lt;button class=&#34;demo-btn&#34; onclick=&#34;window_on(&#39;https://nbviewer.org/github/luochang212/rnn-note/blob/main/4.循环神经网络的从零开始实现.ipynb&#39;)&#34;&gt;查看笔记&lt;/button&gt;&#xA;&lt;/center&gt;&#xA;&lt;br&gt;&#xA;&lt;h4 id=&#34;15-循环神经网络的简洁实现&#34;&gt;1.5 循环神经网络的简洁实现&lt;/h4&gt;&#xA;&lt;p&gt;使用高级 API 实现循环神经网络。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
