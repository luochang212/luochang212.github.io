<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>D2L on Chang Luo</title>
    <link>https://luochang212.github.io/tags/d2l/</link>
    <description>Recent content in D2L on Chang Luo</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 09 Feb 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://luochang212.github.io/tags/d2l/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>手写深度学习</title>
      <link>https://luochang212.github.io/posts/d2l_from_scratch/</link>
      <pubDate>Fri, 09 Feb 2024 00:00:00 +0000</pubDate>
      <guid>https://luochang212.github.io/posts/d2l_from_scratch/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;与其说深度学习是一门技术，不如说深度学习是一种语言&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;p&gt;GitHub 项目地址：&lt;a href=&#34;https://github.com/luochang212/AI-Project/tree/main/scratch&#34; target=&#34;_blank&#34;&gt;AI-Project/scratch&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h3 id=&#34;一自动微分&#34;&gt;一、自动微分&lt;/h3&gt;&#xA;&lt;h4 id=&#34;1-简单的例子&#34;&gt;1. 简单的例子&lt;/h4&gt;&#xA;&lt;p&gt;1.1 张量 x 的梯度&lt;/p&gt;&#xA;&lt;p&gt;张量 &lt;code&gt;$x$&lt;/code&gt; 的梯度可以存储在 &lt;code&gt;$x$&lt;/code&gt; 上。&lt;/p&gt;&#xA;&lt;p&gt;要点：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;code&gt;x.grad&lt;/code&gt;: 取 &lt;code&gt;$x$&lt;/code&gt; 的梯度&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;x.requires_grad_(True)&lt;/code&gt;: 允许 tenser &lt;code&gt;$x$&lt;/code&gt; 存储自己的梯度&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;x.grad.zero_()&lt;/code&gt;: 将 &lt;code&gt;$x$&lt;/code&gt; 的梯度置零&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;import torch&#xA;&#xA;# 初始化张量 x (tensor x)&#xA;x = torch.arange(4.0)&#xA;&#xA;x.requires_grad_(True)  # 允许 tensor x 存储梯度&#xA;x.grad is None  # 梯度默认为 None&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;code&gt;&amp;gt; True&lt;/code&gt;&lt;/p&gt;&#xA;&lt;p&gt;初始化带梯度的张量，下面是两个例子：&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;torch.tensor([1., 2., 3.], requires_grad=True)&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;code&gt;&amp;gt; tensor([1., 2., 3.], requires_grad=True)&lt;/code&gt;&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;torch.randn((2, 5), requires_grad=True)&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;code&gt;&amp;gt; tensor([[ 0.4075,  1.1930,  0.5716, -1.0924,  0.0653], [-1.2869,  1.5768,  1.3445,  0.6309, -0.0484]], requires_grad=True)&lt;/code&gt;&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
