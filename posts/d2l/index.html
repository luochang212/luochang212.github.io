<!DOCTYPE html>
<html lang="en-us">
    
    


    <head>
    <link href="https://gmpg.org/xfn/11" rel="profile">
    
    <link rel="canonical" href="/posts/d2l/">
    
    <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<!-- Enable responsiveness on mobile devices -->
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
<meta name="generator" content="Hugo 0.118.2">

    
    
    

<title>深度学习笔记 • Chang Luo</title>


<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="深度学习笔记"/>
<meta name="twitter:description" content="我踏马记记记"/>

<meta property="og:title" content="深度学习笔记" />
<meta property="og:description" content="我踏马记记记" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/d2l/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-11-11T00:00:00+00:00" />
<meta property="article:modified_time" content="2023-11-11T00:00:00+00:00" /><meta property="og:site_name" content="Title" />


    


<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">








<link rel="stylesheet" href="/scss/hyde-hyde.3081c4981fb69a2783dd36ecfdd0e6ba7a158d4cbfdd290ebce8f78ba0469fc6.css" integrity="sha256-MIHEmB&#43;2mieD3Tbs/dDmunoVjUy/3SkOvOj3i6BGn8Y=">


<link rel="stylesheet" href="/scss/print.2744dcbf8a0b2e74f8a50e4b34e5f441be7cf93cc7de27029121c6a09f9e77bc.css" integrity="sha256-J0Tcv4oLLnT4pQ5LNOX0Qb58&#43;TzH3icCkSHGoJ&#43;ed7w=" media="print">




<link rel="stylesheet" href="/scss/tocbot.5ef07cebc3c477b54270456f149ee02922479bb7555fd344b2c69f953b0e7e5e.css" integrity="sha256-XvB868PEd7VCcEVvFJ7gKSJHm7dVX9NEssaflTsOfl4=">



    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
    <!-- Icons -->
    <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/apple-touch-icon-144-precomposed.png">
    <link rel="shortcut icon" href="/favicon.png">
    
    

</head>


    <body class=" ">
    <head>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <script src="https://upcdn.b0.upaiyun.com/libs/jquery/jquery-1.9.0.min.js"></script>

  <style>
    body {
      transition: background-color .5s;
    }

    #overlay {
      position: fixed;
      display: none;
      width: calc(100vw - 580px);
      height: 100%;
      top: 0;
      left: 0;
       
      z-index: 2;
      cursor: pointer;
    }

    .sidenav {
      height: 100%;
      width: 0;
      position: fixed;
      z-index: 1000;
      top: 0;
      right: 0;
      background-color: #FFF;
       
      overflow-x: hidden;
      transition: 0.5s;
       
       
    }

    #main {
      transition: margin-left .5s;
       
      padding: 16px;
      position: absolute;
      top: 0;
      right: 0;
      bottom: 0;
      left: 0;
      overflow: hidden;
    }

     
    .tab {
      overflow: hidden;
      border: 1px solid #ccc;
      background-color: #f1f1f1;
    }

     
    .tab button {
      background-color: inherit;
      float: left;
      border: none;
      outline: none;
      cursor: pointer;
      padding: 14px 16px;
      transition: 0.3s;
      font-size: 17px;
    }

     
    .tab button:hover {
      background-color: #ddd;
    }

     
    .tab button.active {
      background-color: #ccc;
    }

     
    .tabcontent {
      display: none;
      padding: 12px 12px;
      margin: 0;
      border: 1px solid #ccc;
      border-top: none;
    }

    .dropbtn {
      background-color: #3498DB;
      color: white;
      padding: 16px;
      font-size: 16px;
      border: none;
    }

    .dropup {
      position: relative;
      display: inline-block;
    }

    .dropup-content {
      display: none;
      position: absolute;
      background-color: #f1f1f1;
      min-width: 160px;
      bottom: 50px;
      z-index: 1;
    }

    .dropup-content a {
      color: black;
      padding: 12px 16px;
      text-decoration: none;
      display: block;
    }

    .dropup-content a:hover {
      background-color: #ccc
    }

    .dropup:hover .dropup-content {
      display: block;
    }

    .dropup:hover .dropbtn {
      background-color: #2980B9;
    }

    #video2,
    #video3 {
      display: none;
    }
  </style>

</head>

<body>

  
  <div class="sidebar">
    <div class="container ">
      <div class="sidebar-about">
        <span class="site__title">
          <a href="/">Chang Luo</a>
        </span>
        
        
        
        <div class="author-image">
          <a href="#" class="load-iframe" onclick="openNav()"><img src="//images/profile.webp" id="author-iamge"
              alt="Author Image" class="img--circle img--headshot element--center"></a>
        </div>
        
        <p class="site__description">
          
        </p>
      </div>
      <div class="collapsible-menu">
        <input type="checkbox" id="menuToggle">
        <label for="menuToggle">Chang Luo</label>
        <div class="menu-content">
          <div>
	<ul class="sidebar-nav">
		 
		 
			 
				<li>
					<a href="/posts/">
						<span>Posts</span>
					</a>
				</li>
			 
		 
			 
				<li>
					<a href="/portfolio/">
						<span>Projects</span>
					</a>
				</li>
			 
		 
			 
				<li>
					<a href="/about/">
						<span>About Me</span>
					</a>
				</li>
			 
		
	</ul>
</div>

          <section class="social">
	
	<a href="https://twitter.com/MinosPalace" rel="me"><i class="fab fa-twitter fa-lg" aria-hidden="true"></i></a>
	
	
	
	
	<a href="https://github.com/luochang212" rel="me"><i class="fab fa-github fa-lg" aria-hidden="true"></i></a>
	
	
	
	
	
	
	<a href="https://instagram.com/suphenshin" rel="me"><i class="fab fa-instagram fa-lg" aria-hidden="true"></i></a>
	
	
	<a href="https://linkedin.com/in/bupt-luochang" rel="me"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a>
	
	
	
	
	
	
	
	
	
	
	
	
	
</section>

        </div>
      </div>
      
<div class="copyright">
  &copy; 2024 Chang Luo
  
</div>



    </div>
  </div>

  
  

  <div id="overlay" onclick="off()"></div>

  <div id="mySidenav" class="sidenav">

    <div id="main">
      <div class="tab">
        <button id="default-tab" class="tablinks" onclick="openItem(event, 'Resources')">Resources</button>
        <button class="tablinks" onclick="openItem(event, 'netease-player')">Music</button>
        <button class="tablinks" onclick="openItem(event, 'video-player')">Video</button>
        <button class="tablinks" onclick="openItem(event, 'gallery')">Gallery</button>
        <button class="tablinks" onclick="openItem(event, 'gadget')">Gadget</button>
        <button class="tablinks" onclick="openItem(event, 'categories')">Cats</button>
      </div>

      <div id="Resources" class="tabcontent">
        <iframe src="about:blank" data-src="/resources/" frameborder="0" height="560" width="100%" marginheight="0"
          marginwidth="0" scrolling="yes"></iframe>
      </div>

      <div id="netease-player" class="tabcontent">
        <iframe src="about:blank" data-src="//music.163.com/outchain/player?type=0&id=2250585392&auto=0&height=430"
          frameborder="no" border="0" marginwidth="0" marginheight="0" width=100% height=450></iframe>
      </div>

      <div id="video-player" class="tabcontent">

        <div id="video1">
          <iframe src="about:blank"
            data-src="//player.bilibili.com/player.html?aid=663375832&bvid=BV11a4y1S7Pt&cid=1334196946&p=1&high_quality=1&danmaku=0&autoplay=0"
            style="width:100%; height:460px" scrolling="no" border="0" frameborder="no" framespacing="0"
            allowfullscreen="true"></iframe>
        </div>
        <div id="video2">
          <iframe src="about:blank"
            data-src="//player.bilibili.com/player.html?aid=958254107&bvid=BV1rp4y1L7i4&cid=1264513494&p=1&high_quality=1&danmaku=0&autoplay=0"
            style="width:100%; height:460px" scrolling="no" border="0" frameborder="no" framespacing="0"
            allowfullscreen="true"></iframe>
        </div>
        <div id="video3">
          <iframe src="about:blank"
            data-src="//player.bilibili.com/player.html?aid=566507193&bvid=BV1Av4y147QE&cid=997936232&p=1&high_quality=1&danmaku=0&autoplay=0"
            style="width:100%; height:460px" scrolling="no" border="0" frameborder="no" framespacing="0"
            allowfullscreen="true"></iframe>
        </div>

        

        

        <br>
        <div class="dropup">
          <button class="dropbtn">更多视频</button>
          <div class="dropup-content">
            <a onclick="link1()">发财财</a>
            <a onclick="link2()">岁岁恋</a>
            <a onclick="link3()">真物论</a>
          </div>
        </div>
      </div>

      <div id="gallery" class="tabcontent">
        <iframe src="about:blank" data-src="/gadget/gallery.html#two" frameborder="0" height="560" width="100%"
          scrolling="yes"></iframe>
      </div>

      <div id="gadget" class="tabcontent">
        <iframe src="about:blank" data-src="/gadget/" frameborder="0" height="560" width="100%"
          scrolling="yes"></iframe>
      </div>

      <div id="categories" class="tabcontent">
        <iframe src="about:blank" data-src="/categories/" frameborder="0" height="560" width="100%"
          scrolling="yes"></iframe>
      </div>

    </div>
  </div>

  
  <script>
    'use strict'

    function openNav() {
      on();
      document.getElementById("mySidenav").style.width = "580px";
      document.body.style.backgroundColor = "rgba(0,0,0,0.5)";
    }

    function closeNav() {
      document.getElementById("mySidenav").style.width = "0";
      document.body.style.backgroundColor = "white";
    }

    function on() {
      document.getElementById("overlay").style.display = "block";
    }

    function off() {
      closeNav();
      document.getElementById("overlay").style.display = "none";
    }

    
    document.getElementById('default-tab').click();

    function openItem(evt, itemName) {
      var i, tabcontent, tablinks;
      tabcontent = document.getElementsByClassName("tabcontent");
      for (i = 0; i < tabcontent.length; i++) {
        tabcontent[i].style.display = "none";
      }
      tablinks = document.getElementsByClassName("tablinks");
      for (i = 0; i < tablinks.length; i++) {
        tablinks[i].className = tablinks[i].className.replace(" active", "");
      }
      document.getElementById(itemName).style.display = "block";
      evt.currentTarget.className += " active";
    }

    function link1() {
      document.getElementById("video1").style.display = "block";
      document.getElementById("video2").style.display = "none";
      document.getElementById("video3").style.display = "none";
    }

    function link2() {
      document.getElementById("video1").style.display = "none";
      document.getElementById("video2").style.display = "block";
      document.getElementById("video3").style.display = "none";
    }

    function link3() {
      document.getElementById("video1").style.display = "none";
      document.getElementById("video2").style.display = "none";
      document.getElementById("video3").style.display = "block";
    }

     
    var flag = 0;

     
    $(".load-iframe").click(function () {
      if (flag < 1) {
        $("iframe").each(function () {
          $(this).attr("src", $(this).data("src"));
        });
        flag = flag + 1;
      }
    });
  </script>

</body>



        <div class="content container">
            
    <style>
  .my-emoji {
    height: 25px;
    display: inline-block;
    margin: 0;
    vertical-align: text-bottom;
  }
</style>



<article>
  <header>
    <h1>深度学习笔记</h1>
    
    
<div class="post__meta">
    
    
      <i class="fas fa-calendar-alt"></i> Nov 11, 2023
    
    
    
      
      
          in
          
          
              <a class="badge badge-category" href="/categories/deeplearning">DEEPLEARNING</a>
              
          
      
    
    
    
      
      
          <br/>
           <i class="fas fa-tags"></i>
          
          <a class="badge badge-tag" href="/tags/python">python</a>
           
      
          <a class="badge badge-tag" href="/tags/note">note</a>
          
      
    
    
    <br/>
    <i class="fas fa-clock"></i> 5 min read
</div>


  </header>
  
  
  
  <div class="toc-wrapper">
    <input type="checkbox" id="tocToggle">
    <label for="tocToggle">目录</label>
    
    <div class="toc" id="TableOfContents"></div>
    
  </div>
  
  
  <div class="post">
    <blockquote>
<p>跟李沐老师学深度学习，课程见 <a href="https://zh-v2.d2l.ai/index.html">d2l</a>，如有错误，欢迎拍砖 <img src="/img/quyin/witty.png" class="my-emoji" style = "height: 32px;"></p>
</blockquote>
<p>GitHub 项目地址：<a href="https://github.com/luochang212/AI-Project" target="_blank">AI-Project</a></p>
<h3 id="技术路线图">〇、技术路线图</h3>
<pre class="mermaid">
flowchart TD
    A[softmax 回归] -->|无法拟合 XOR 函数| B[多层感知机]
    B --> |高像素图片作为输入，模型参数爆炸| C[卷积]
    C -->|数据的长宽下降太快| D[填充]
    C -->|数据的长宽下降太慢| E[步幅]
    C -->|缓解卷积对位置敏感| F[池化]
    C -->|多模式识别与组合| G[多通道输入/输出]

</pre>
<center>❤️ powered by <a href="https://github.com/mermaid-js/mermaid" target="_blank">mermaid</a></center>
<h3 id="一softmax-回归">一、softmax 回归</h3>
<h4 id="1-虽然叫回归但是softmax-解决的是分类问题">1. 虽然叫回归，但是softmax 解决的是分类问题</h4>
<ul>
<li>回归估计是一个连续值</li>
<li>分类预测是一个离散类别</li>
</ul>
<h4 id="2-分类应用举例">2. 分类应用举例</h4>
<ul>
<li>MINIST</li>
<li>ImageNet</li>
<li>human-protein-atlas-image-classification (<strong>Kaggle</strong>)</li>
<li>malware-classification (<strong>Kaggle</strong>)</li>
<li>jigsaw-comment-classification (<strong>Kaggle</strong>)</li>
</ul>
<h4 id="3-从回归到多类分类----均方损失">3. 从回归到多类分类 &ndash; 均方损失</h4>
<p>对分类结果做 one-hot 编码：</p>
<p><code>$y = [y_1, y_2, , ... , y_n]^T$</code></p>
<p><code>$y_i=\left\{\begin{array}{l}1 \text { if } i=y \\ 0 \text { otherwise }\end{array}\right.$</code></p>
<p>使用均方损失 ($O_i$) 训练：</p>
<p><code>$\hat{y}=\underset{i}{\operatorname{argmax}} o_i$</code></p>
<p>该式含义为：取最大化 <code>$O_i$</code> 对应的 <code>$i$</code> 作为 <code>$\hat{y}$</code> 的估计值</p>
<h4 id="4-无校验比例">4. 无校验比例</h4>
<p>需要更置信地识别正确类（大余量）</p>
<p><code>$O_y - O_i \geq \Delta (y, i)$</code></p>
<h4 id="5-校验比例">5. 校验比例</h4>
<p>现在我们得到的输出 $O_i$ 是一个向量，我们希望把它转化成每一种分类对应的概率。我们可以通过添加 softmax 操作子实现这一目标，它对 $O_i$ 做如下操作：</p>
<p><code>$\hat{y_i} = \frac{\exp(O_i)}{\sum_{k} \exp(O_k)}$</code></p>
<p>此时，<code>$y$</code> 与 <code>$\hat{y}$</code> 都是概率，我们可以把两个概率的区别 <code>$y - \hat{y}$</code> 作为损失</p>
<h4 id="6-交叉熵损失">6. 交叉熵损失</h4>
<p>交叉熵常用来衡量两个概率的区别 <code>$H(p, q) = \sum_{i} - P_i log(q_i)$</code></p>
<p>将它作为损失：</p>
<p><code>$l(\mathbf{y}, \hat{\mathbf{y}})=-\sum_i y_i \log \hat{y}_i=-\log \hat{y}_y$</code></p>
<p>PS：因为除了 <code>$i = y$</code> 的情况，<code>$i$</code> 为其他值时 <code>$y_i$</code> 为 0</p>
<p>其梯度是真实概率和预测概率的区别：</p>
<p><code>$\partial_{o_i} l(\mathbf{y}, \hat{\mathbf{y}})=\operatorname{softmax}(\mathbf{o})_i-y_i$</code></p>
<h4 id="7-总结">7. 总结</h4>
<ul>
<li>Softmax回归是一个多类分类模型</li>
<li>使用Softmax操作子得到每个类的预测置信度</li>
<li>使用交叉熵来衡量预测和标号的区别</li>
</ul>
<center>
<button class="demo-btn" onclick="window_on('https://nbviewer.jupyter.org/github/luochang212/AI-Project/blob/main/src/09.softmax回归.ipynb')">查看示例</button>
</center>
<h3 id="二多层感知机">二、多层感知机</h3>
<p>感知机解决的是二分类问题</p>
<h4 id="1-什么是感知机">1. 什么是感知机</h4>
<p>给定输入 <code>$x$</code>，权重 <code>$w$</code>，和偏移 <code>$b$</code>，感知机输出：</p>
<p><code>$o = \sigma \left(\left&lt;W, X\right&gt; + b\right)$</code></p>
<p><code>$\sigma(x) = \left\{\begin{array}{l}1 \text { if } x &gt; 0 \\ -1 \text { otherwise }\end{array}\right.$</code></p>
<h4 id="2-训练感知机">2. 训练感知机</h4>
<ol>
<li>初始化：w = 0, b = 0</li>
<li>如果分类分错：<code>$y_i [\left&lt; W, X_i \right&gt;] \leq 0 \text{ then } w \gets w + y_i x_i \text{ and } b \gets b + y_i $</code></li>
<li>停止条件：所有类别都分对的时候停止</li>
</ol>
<p>等价于使用批量大小为1的梯度下降，并使用如下损失函数：</p>
<p><code>$l\left(y, X, W\right) = max\left(0, -y\left&lt;W, X\right&gt;\right)$</code></p>
<h4 id="3-收敛定理">3. 收敛定理</h4>
<p>对于：</p>
<ul>
<li>数据在半径 <code>$r$</code> 内</li>
<li>余量 <code>$\rho$</code> 将数据点分两类</li>
<li><code>$\lvert\lvert w \rvert\rvert^{2} + b^2 \leq 1$</code></li>
</ul>
<p>感知机保证在 <code>$\frac{r^2 + 1}{\rho^2}$</code> 步后收敛</p>
<h4 id="4-xor问题-minsky--papert-1969">4. XOR问题 (Minsky &amp; Papert, 1969)</h4>
<p>感知机不能拟合 XOR 函数，它只能产生线性分割面</p>
<pre tabindex="0"><code>        |
    1   |   -1
        |
-----------------
        |
   -1   |    1
        |
</code></pre><p>由于感知机无法拟合 XOR 函数，导致了第一次 AI 寒冬。但是其实有办法解决这个问题，解决的方法叫 <strong>多层感知机</strong>。</p>
<h4 id="5-多层感知机">5. 多层感知机</h4>
<pre tabindex="0"><code>    　   |
   ①    |    ②
    　   |
-------------------
    　   |
   ③    |    ④
    　   |
</code></pre><ul>
<li>先学一次：对于竖线，左边为 <code>$+$</code> ，右边为 <code>$-$</code></li>
<li>再学一次：对于横线：上边为 <code>$+$</code> ，下边为 <code>$-$</code></li>
</ul>
<p>把两次分类结果组合一下（做乘法），就能表达 XOR 了。</p>
<p>对于我们的启发是：如果一个复杂问题一次性做不了，可以先用一个简单函数，再用一个简单函数，接着用一个简单函数组合这两者。也就是一层变多层，就可以表达复杂结果。</p>
<p><img src="../img/perceptron-1.png" alt=""></p>
<p>为什么说隐藏层的层数是超参？因为输入数据的维度 <code>$n$</code> 和输出数据的维度 <code>$m$</code> 都是由数据决定的，我们惟一能调的，只有隐藏层的层数。</p>
<h4 id="6-单隐藏层">6. 单隐藏层</h4>
<ul>
<li>输入：<code>$\mathbf{x} \in \mathbb{R}^{n}$</code></li>
<li>隐藏层：<code>$\mathbf{W}_1 \in \mathbb{R}^{m \times n}, \mathbf{b}_1 \in \mathbb{R}^m$</code></li>
<li>输出层：<code>$\mathbf{w}_2 \in \mathbb{R}^{m}, \mathbf{b}_2 \in \mathbb{R}$</code></li>
</ul>
<p><code>$~~~~~~~~~\mathbf{h} = \sigma \left( \mathbf{W}_1 + \mathbf{b}_1 \right)$</code></p>
<p><code>$~~~~~~~~~\mathbf{o} = \mathbf{w}_2^\mathbf{T} \mathbf{h} + \mathbf{b}_2$</code></p>
<p>$\sigma$ 是按元素的<strong>激活函数</strong></p>
<blockquote>
<p><strong>Note</strong>: 为什么需要非线性的激活函数？</p>
<p>如果 <code>$\sigma$</code> 是线性的，把公式一的 <code>$\mathbf{h}$</code> 代入到公式二中，可得：</p>
<p><code>$\mathbf{hence} \space \mathbf{o} = \mathbf{w}_2^T \mathbf{W}_1 \mathbf{o} + b^{\prime}$</code> 依然是线性，折腾半天发现我们得到的依旧是一个最简单的线性模型。</p>
</blockquote>
<h4 id="7-sigmoid-激活函数">7. Sigmoid 激活函数</h4>
<p>将输入投影到 <code>$(0, 1)$</code></p>
<p><code>$sigmoid(x) = \frac{1}{1 + \mathbf{exp}(-x)}$</code></p>
<p><img src="/img/Sigmoid-%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0.png" alt="Sigmoid-激活函数"></p>
<h4 id="8-tanh-激活函数">8. Tanh 激活函数</h4>
<p>将输入投影到 <code>$(-1, 1)$</code></p>
<p><code>$tanh(x) = \frac{1 - \mathbf{exp}(-2x)}{1 + \mathbf{exp}(-2x)}$</code></p>
<p><img src="/img/Tanh-%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0.png" alt="Tanh-激活函数"></p>
<h4 id="9-relu-激活函数">9. ReLU 激活函数</h4>
<p>ReLU: rectified linear unit</p>
<p>将输入投影到 <code>$(0, +\infty)$</code></p>
<p><code>$ReLU(x) = \mathbf{max}(x, 0)$</code></p>
<p>指数运算是一个很贵的操作，所以为什么大家爱用ReLU，因为一个max就好了</p>
<p><img src="/img/ReLU-%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0.png" alt="ReLU-激活函数"></p>
<h4 id="10-多类分类借鉴-softmax">10. 多类分类：借鉴 softmax</h4>
<p><code>$softmax$</code> 就是输出一个堆概率 <code>$y_1, y_2, ..., y_k$</code>，所有这些加起来等于1</p>
<p><code>$y_1, y_2, ..., y_k = softmax(o_1, o_1, ... , o_k)$</code></p>
<h4 id="11-多隐藏层">11. 多隐藏层</h4>
<p><code>$\mathbf{h}_1 = \sigma(\mathbf{W}_1\mathbf{x} + b_1)$</code></p>
<p><code>$\mathbf{h}_2 = \sigma(\mathbf{W}_2\mathbf{h}_1 + b_2)$</code></p>
<p><code>$\mathbf{h}_3 = \sigma(\mathbf{W}_3\mathbf{h}_2 + b_3)$</code></p>
<p><code>$\mathbf{o} = \mathbf{W}_4\mathbf{h}_3 + b_4$</code></p>
<p>激活函数主要是为了防止层数的塌陷，所以最后一层输出层不需要激活函数。</p>
<p>超参数：</p>
<ul>
<li>隐藏层数</li>
<li>每层隐藏层的大小</li>
</ul>
<h4 id="12-总结">12. 总结</h4>
<ul>
<li>多层感知机使用隐藏层和激活函数来得到非线性模型</li>
<li>常用激活函数是Sigmoid, Tanh, ReLU</li>
<li>使用Softmax来处理多类分类</li>
<li>超参数为隐藏层数，和各个隐藏层大小</li>
</ul>
<center>
<button class="demo-btn" onclick="window_on('https://nbviewer.jupyter.org/github/luochang212/AI-Project/blob/main/src/10.多层感知机.ipynb')">查看示例</button>
</center>
<h3 id="三卷积层">三、卷积层</h3>
<p>一张 12,000,000 像素的猫或者狗的图片，分RGB三种颜色，如果使用单隐藏层的 MLP 处理，模型有 3.6B 个参数，远多于世界上所有猫和狗的数量。</p>
<h4 id="1-识别器的原则">1. 识别器的原则</h4>
<ul>
<li>平移不变性（在图片的哪个位置都能识别到）</li>
<li>局部性（不需要看整张图就能识别）</li>
</ul>
<h4 id="2-重新考察全连接层">2. 重新考察全连接层</h4>
<ul>
<li>将输入和输出变形为矩阵（宽度，高度）</li>
<li>将权重变形为4-D张量 <code>$(h, w)$</code> 到 <code>$(h^\prime, w^\prime)$</code>
<code>$h_{i,j} = \sum_{k,l} w_{i,j,k,l}x_{k,l} = \sum_{a,b} v_{i,j,a,b}x_{i+a,j+b}$</code></li>
<li><code>$v$</code> 是 <code>$w$</code> 的重新索引 <code>$v_{i,j,i+a,j+b}$</code></li>
</ul>
<h4 id="3-原则-1---平移不变性">3. 原则 #1 - 平移不变性</h4>
<ul>
<li>x的平移导致h的平移 <code>$h_{i,j} = \sum_{a,b} v_{i,j,a,b} x_{i+a,j+b}$</code></li>
<li>v不应该依赖于(i, j)</li>
<li>解决方案：<code>$v_{i,j,a,b} = v_{a,b}$</code>
<code>$h_{i,j} = \sum_{a,b} v_{a,b}x_{i+a,j+b}$</code></li>
</ul>
<p>这就是二维<del>卷积</del>交叉相关</p>
<h4 id="4-原则-2---局部性">4. 原则 #2 - 局部性</h4>
<p>$h_{i,j} = \sum_{a,b} \mathbf{v}<em>{a,b} \mathbf{x}</em>{i+a,j+b}$</p>
<ul>
<li>当评估 <code>$h_{i,j}$</code> 时，我们不应该用远离 <code>$x_{i,j}$</code> 的参数</li>
<li>解决方案：当 <code>$|a|, |b| &gt; \Delta$ 时，使得 $v_{a,b} = 0$</code>
<code>$h_{i,j} = \sum_{a=-\Delta}^{\Delta} \sum_{b=-\Delta}^{\Delta} v_{a,b} x_{i+a,j+b}$</code></li>
</ul>
<h4 id="5-小结">5. 小结</h4>
<ul>
<li>对全连接层使用平移不变性和局部性得到卷积层</li>
</ul>
<p><code>$~~~~~~~~~~~h_{i,j} = \sum_{a,b} \mathbf{v}_{i,j,a,b} \mathbf{x}_{i+a,j+b}$</code></p>
<p><code>$~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~$</code>⬇</p>
<p><code>$~~~~~~~~~~~h_{i,j} = \sum_{a=-\Delta}^{\Delta} \sum_{b=-\Delta}^{\Delta} \mathbf{v}_{a,b} \mathbf{x}_{i+a,j+b}$</code></p>
<h4 id="6-二维交叉相关">6. 二维交叉相关</h4>
<ul>
<li>卷积核 (Kernel)，其实就是 <code>$\mathbf{w}$</code></li>
<li>核是不随扫描的位置变化的，这就实现了平移不变性</li>
</ul>
<h4 id="7-二维卷积层">7. 二维卷积层</h4>
<ul>
<li>输入 <code>$\mathbf{X}: n_h \times n_w$</code></li>
<li>核 <code>$\mathbf{W}: k_h \times k_w$</code></li>
<li>偏差 <code>$b \in \mathbb{R}$</code></li>
<li>输出 <code>$\mathbf{Y}: (n_h - k_h + 1) \times (n_w - k_w + 1)$</code></li>
</ul>
<p><code>$\mathbf{Y} = \mathbf{X} \mathbf{W} + b$</code></p>
<p><code>$\mathbf{W}$</code> 和 <code>$b$</code> 是可学习的参数</p>
<h4 id="8-例子">8. 例子</h4>
<p>不同的卷积核，会得到不同的效果</p>
<p><strong>边缘检测</strong></p>
<p><code>$\left[\begin{array}{c} -1 &amp; -1 &amp; -1 \\ -1 &amp; 8 &amp; -1 \\ -1 &amp; -1 &amp; -1 \end{array}\right]$</code></p>
<p><img src="/img/conv-1.png" alt=""></p>
<p><strong>锐化</strong></p>
<p><code>$\left[\begin{array}{c} 0 &amp; -1 &amp; 0 \\ -1 &amp; 5 &amp; -1 \\ 0 &amp; -1 &amp; 0 \end{array}\right]$</code></p>
<p><img src="/img/conv-2.png" alt=""></p>
<p><strong>高斯模糊</strong></p>
<p><code>$\frac{1}{16}\left[\begin{array}{c} 1 &amp; 2 &amp; 1 \\ 2 &amp; 4 &amp; 2 \\ 1 &amp; 2 &amp; 1 \end{array}\right]$</code></p>
<p><img src="/img/conv-3.png" alt=""></p>
<h4 id="9-交叉相关-vs-卷积">9. 交叉相关 vs 卷积</h4>
<ul>
<li>二维交叉相关</li>
<li>二维卷积</li>
<li>由于对称性，在实际使用中没有区别</li>
</ul>
<p>因为使用是一样的，所以没有使用数学上严格定义的卷积</p>
<h4 id="10-一维和三维交叉相关">10. 一维和三维交叉相关</h4>
<ul>
<li>一维：文本、语言、时需序列</li>
<li>二维：视频、医学图像、气象图像</li>
</ul>
<h4 id="11-总结">11. 总结</h4>
<ul>
<li>卷积层将输入和核矩阵进行交叉相关，加上偏移后得到输出</li>
<li>核矩阵和偏移是可学习的参数</li>
<li>核矩阵的大小是超参数</li>
</ul>
<center>
<button class="demo-btn" onclick="window_on('https://nbviewer.jupyter.org/github/luochang212/AI-Project/blob/main/src/19.卷积层.ipynb')">查看示例</button>
</center>
<h3 id="四lenet">四、LeNet</h3>
<p><a href="https://en.wikipedia.org/wiki/LeNet">LeNet</a> is a convolutional neural network structure proposed by LeCun et al. in 1998.</p>
<p>最早应用于手写数字识别。</p>
<p>MNIST 是 LeNet 附带的数据集</p>
<ul>
<li>5w个训练数据</li>
<li>1w个测试数据</li>
<li>图像大小$28 \times 28$</li>
<li>10类</li>
</ul>
<p><img src="/img/lenet-1.png" alt="LeNet"></p>
<h4 id="1-小结">1. 小结</h4>
<ul>
<li>LeNet是早期成功的神经网络</li>
<li>先使用卷积层来学习图片空间信息</li>
<li>然后使用全连接层来转换到类别空间</li>
</ul>
<h4 id="2-卷积神经网络lenet">2. 卷积神经网络（LeNet）</h4>
<p>LeNet (LeNet-5) 由两个部分组成：卷积编码器和全连接层密集块</p>
<center>
<button class="demo-btn" onclick="window_on('https://nbviewer.jupyter.org/github/luochang212/AI-Project/blob/main/src/23.经典卷积神经网络LeNet.ipynb')">查看示例</button>
</center>
<h3 id="五alexnet">五、AlexNet</h3>
<h4 id="1-技术回顾">1. 技术回顾</h4>
<p>1）支持向量机</p>
<p>在2000年左右，最流行的机器学习的算法是核方法 (Learning with Kernels).</p>
<p>the Support Vector Machine (SVM)</p>
<ul>
<li>特征提取</li>
<li>选择核函数来计算相似性</li>
<li>凸优化问题</li>
<li>漂亮的定理（来自泛函）</li>
</ul>
<p>优点：对调参不敏感，闭着眼睛都可以用</p>
<p>2）几何学</p>
<ul>
<li>抽取特征</li>
<li>描述几何（例如多相机）</li>
<li>（非）凸优化</li>
<li>漂亮定理</li>
<li>如果假设满足，效果很好</li>
</ul>
<p>3）特征工程</p>
<p>直接把特征放到SVM里效果非常差，所以需要做特征工程</p>
<ul>
<li>（在计算机视觉里）特征工程是关键</li>
<li>特征描述子：SIFT, SURF</li>
</ul>
<h4 id="2-imagenet-2020">2. ImageNet (2020)</h4>
<ul>
<li>图片：自然物体的彩色图片</li>
<li>大小：$469 \times 387$</li>
<li>样本数 1.2M</li>
<li>类数：1000</li>
</ul>
<p>因为你有了更大的数据集，所以允许用更深的神经网络，用来抽取信息</p>
<h4 id="3-alexnet">3. AlexNet</h4>
<ul>
<li>AlexNet赢了2012年ImageNet竞赛</li>
<li>更深更大的 LeNet</li>
<li>主要改进：
<ul>
<li>丢弃法（因为模型大了，所以用丢弃做一点正则）</li>
<li>ReLU（$Sigmoid \space (LeNet) \to ReLU$，ReLU在零点的一阶导更好，梯度更大）</li>
<li>MaxPooling（数值比较大，梯度比较大，使得训练比较容易）</li>
<li>计算机视觉方法论的改变
<ul>
<li>核方法：人工特征提取 $\to$ SVM</li>
<li>神经网络：通过 CNN 学习特征 $\to$ Softmax回归</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="4-alexnet架构">4. AlexNet架构</h4>
<p>1）第一个卷积层和池化层的区别</p>
<table>
<thead>
<tr>
<th>AlexNet</th>
<th>LeNet</th>
</tr>
</thead>
<tbody>
<tr>
<td>image ($3 \times 224 \times 224$)</td>
<td>image ($32 \times 32$)</td>
</tr>
<tr>
<td>11*11 Conv(96), stride 4</td>
<td>5*5 Conv(6), pad 2</td>
</tr>
<tr>
<td>3*3 MaxPool, stride 2</td>
<td>2*2 AvgPool, stride 2</td>
</tr>
</tbody>
</table>
<ul>
<li>卷积：更大的窗口，更大的通道数，更大的步幅</li>
<li>池化：更大的窗口且stride不变（对位置更不敏感），使用MaxPool</li>
</ul>
<p>2）接下来</p>
<table>
<thead>
<tr>
<th>AlexNet</th>
<th>LeNet</th>
</tr>
</thead>
<tbody>
<tr>
<td>5*5 Conv(256), pad 2</td>
<td>5*5 Conv()</td>
</tr>
<tr>
<td>3*3 MaxPool, stride 2</td>
<td>2*2 AvgPool, stride 2</td>
</tr>
<tr>
<td>3*3 Conv(384), pad 1</td>
<td></td>
</tr>
<tr>
<td>3*3 Conv(384), pad 1</td>
<td></td>
</tr>
<tr>
<td>3*3 Conv(384), pad 1</td>
<td></td>
</tr>
<tr>
<td>3*3 MaxPool, stride 2</td>
<td></td>
</tr>
</tbody>
</table>
<ul>
<li>新增了3层卷积层</li>
<li>更多的输出通道</li>
</ul>
<p>3）全连接层</p>
<table>
<thead>
<tr>
<th>AlexNet</th>
<th>LeNet</th>
</tr>
</thead>
<tbody>
<tr>
<td>Dense(4096)</td>
<td>Dense(120)</td>
</tr>
<tr>
<td>Dense(4096)</td>
<td>Dense(84)</td>
</tr>
<tr>
<td>Dense(1000)</td>
<td>Dense(10)</td>
</tr>
</tbody>
</table>
<ul>
<li>隐藏层大小：120 $\to$ 4096</li>
<li>输出类别：10 $\to$ 1000</li>
</ul>
<h4 id="5-更多细节">5. 更多细节</h4>
<ul>
<li>激活函数从 Sigmoid 变到了 ReLU（减缓梯度消失，因为梯度比较大）</li>
<li>隐藏全连接层后加入了丢弃层</li>
<li>数据增强（随机截取采样，调亮度/色温。神经网络会记住所有数据，数据增强能让记住数据的能力变低）</li>
</ul>
<h4 id="6-总结">6. 总结</h4>
<ul>
<li>AlexNet是更大更深的LeNet，10x参数个数，260x计算复杂度</li>
<li>新加入了丢弃法，ReLU，最大池化层，和数据增强</li>
<li>AlexNet赢下了2012ImageNet竞赛后，标志着新的一轮神经网络热潮的开始</li>
</ul>
<center>
<button class="demo-btn" onclick="window_on('https://nbviewer.jupyter.org/github/luochang212/AI-Project/blob/main/src/24.深度卷积神经网络AlexNet.ipynb')">查看示例</button>
</center>
<blockquote>
<p>todo: 未完待续</p>
</blockquote>
<div id="mini-overlay" onclick="overlay_off()"></div>
<div id="mini-window"><iframe id="mini-iframe" frameBorder="0"></iframe></div>
<button id="btn-close" onclick="overlay_off()">×</button>
<script src="/python-tips/overlay.js"></script>
<link rel="stylesheet" href="/python-tips/style.css">
<script type="module">
  import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
</script>

  </div>
  

<div class="navigation navigation-single">
    
    <a href="/posts/pypi_packaging/" class="navigation-prev">
      <i aria-hidden="true" class="fa fa-chevron-left"></i>
      <span class="navigation-tittle">PyPI 打包小记</span>
    </a>
    
    
    <a href="/posts/inventory_list/" class="navigation-next">
      <span class="navigation-tittle">居家物资清单</span>
      <i aria-hidden="true" class="fa fa-chevron-right"></i>
    </a>
    
</div>


  

  
    


</article>

        </div>
        
    <script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
  });
  MathJax.Hub.Queue(function() {
    
    
    
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });

  MathJax.Hub.Config({
  
  TeX: { equationNumbers: { autoNumber: "AMS" } }
  });
</script>


  
  
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'G-CTTYXM88J2', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>


<script defer src="https://use.fontawesome.com/releases/v5.12.1/js/all.js" integrity="sha384-ZbbbT1gw3joYkKRqh0kWyRp32UAvdqkpbLedQJSlnI8iLQcFVxaGyrOgOJiDQTTR" crossorigin="anonymous"></script>


    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.13.1/highlight.min.js"></script>
        
    <script type="text/javascript">
        
        hljs.initHighlightingOnLoad();
    </script>
    



<script src="https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.4.2/tocbot.js"></script>
<script type="text/javascript">
  if (tocbot) {
    tocbot.init({
      
      tocSelector: '.toc',
      
      contentSelector: '.post',
      
      headingSelector: 'h2, h3, h4',
      collapseDepth: 4
    });
  }
</script>



    



    </body>
</html>
