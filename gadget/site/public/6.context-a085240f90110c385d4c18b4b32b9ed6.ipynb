{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22142d03-67ac-4dab-ba27-9f22690244d5",
   "metadata": {},
   "source": [
    "# ä¸Šä¸‹æ–‡å·¥ç¨‹\n",
    "\n",
    "[ä¸Šä¸‹æ–‡å·¥ç¨‹](https://docs.langchain.com/oss/python/langchain/context-engineering)ï¼ˆContext Engineeringï¼‰å¯¹äº LLM å¾—å‡ºæ­£ç¡®çš„ç»“æœè‡³å…³é‡è¦ã€‚å¾ˆå¤šæ—¶å€™ï¼Œæ¨¡å‹å›ç­”ä¸å¥½å¹¶éå› ä¸ºæ¨¡å‹èƒ½åŠ›ä¸è¶³ï¼Œè€Œæ˜¯å› ä¸ºæ²¡æœ‰è·å¾—è¶³ä»¥æ¨æ–­å‡ºæ­£ç¡®ç»“æœçš„ä¿¡æ¯ã€‚LangGraph å¯ä»¥é€šè¿‡ä¸Šä¸‹æ–‡å·¥ç¨‹ï¼Œå¢å¼ºä¸Šä¸‹æ–‡çš„ç®¡ç†èƒ½åŠ›ã€‚\n",
    "\n",
    "**æŒ‰å‘ç”Ÿä½œç”¨çš„ä½ç½®åˆ†ï¼Œå¯å°†ä¸Šä¸‹æ–‡åˆ†ä¸ºï¼š**\n",
    "\n",
    "- æ¨¡å‹ä¸Šä¸‹æ–‡ï¼ˆModel Contextï¼‰\n",
    "- å·¥å…·ä¸Šä¸‹æ–‡ï¼ˆTool Contextï¼‰\n",
    "- ç”Ÿå‘½å‘¨æœŸä¸Šä¸‹æ–‡ï¼ˆLift-cycle Contextï¼‰\n",
    "\n",
    "LangGraph æä¾›äº†ç›¸å½“å¤§çš„è‡ªç”±åº¦ï¼Œä½ å¯ä»¥ä½¿ç”¨ `dataclasses`ã€`pydantic`ã€`TypedDict` ä¸­çš„ä»»æ„ä¸€ä¸ªåˆ›å»º Context Schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4412b776-1f74-41e8-9444-f1724bcff581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ipynbname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54a92bc3-bd5e-4ad9-8b4a-2ae1d0f171cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "import sqlite3\n",
    "\n",
    "from typing import Callable\n",
    "from dotenv import load_dotenv\n",
    "from dataclasses import dataclass\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import dynamic_prompt, wrap_model_call, ModelRequest, ModelResponse, SummarizationMiddleware\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "from langgraph.store.sqlite import SqliteStore\n",
    "\n",
    "# åŠ è½½æ¨¡å‹é…ç½®\n",
    "_ = load_dotenv()\n",
    "\n",
    "# åŠ è½½æ¨¡å‹\n",
    "llm = ChatOpenAI(\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    base_url=os.getenv(\"DASHSCOPE_BASE_URL\"),\n",
    "    model=\"qwen3-coder-plus\",\n",
    "    temperature=0.7,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833f5631-a9f6-40d5-9e57-d652e347c993",
   "metadata": {},
   "source": [
    "## ä¸€ã€åŠ¨æ€ä¿®æ”¹ç³»ç»Ÿæç¤ºè¯\n",
    "\n",
    "ä¸Šä¸‹æ–‡å·¥ç¨‹ä¸å‰åºç« èŠ‚çš„ä¸­é—´ä»¶ï¼ˆmiddlewareï¼‰å’Œè®°å¿†ï¼ˆmemoryï¼‰å¯†ä¸å¯åˆ†ã€‚ä¸Šä¸‹æ–‡çš„å…·ä½“å®ç°ä¾èµ–ä¸­é—´ä»¶ï¼Œè€Œä¸Šä¸‹æ–‡çš„å­˜å‚¨åˆ™ä¾èµ–è®°å¿†ç³»ç»Ÿã€‚å…·ä½“æ¥è®²ï¼ŒLangGraph é¢„ç½®äº† `@dynamic_prompt` ä¸­é—´ä»¶ï¼Œç”¨äºåŠ¨æ€ä¿®æ”¹ç³»ç»Ÿæç¤ºè¯ã€‚\n",
    "\n",
    "æ—¢ç„¶æ˜¯åŠ¨æ€ä¿®æ”¹ï¼Œè‚¯å®šéœ€è¦æŸä¸ªæ¡ä»¶æ¥è§¦å‘ä¿®æ”¹ã€‚é™¤äº†å¼€å‘è§¦å‘é€»è¾‘ï¼Œæˆ‘ä»¬è¿˜éœ€è¦ä»æ™ºèƒ½ä½“ä¸­è·å–è§¦å‘é€»è¾‘æ‰€éœ€çš„å³æ—¶å˜é‡ã€‚è¿™äº›å˜é‡é€šå¸¸å­˜å‚¨åœ¨ä»¥ä¸‹ä¸‰ä¸ªå­˜å‚¨ä»‹è´¨ä¸­ï¼š\n",
    "\n",
    "- è¿è¡Œæ—¶ï¼ˆRuntimeï¼‰- æ‰€æœ‰èŠ‚ç‚¹å…±äº«ä¸€ä¸ª Runtimeã€‚åŒä¸€æ—¶åˆ»ï¼Œæ‰€æœ‰èŠ‚ç‚¹å–åˆ°çš„ Runtime çš„å€¼æ˜¯ç›¸åŒçš„ã€‚ä¸€èˆ¬ç”¨äºå­˜å‚¨æ—¶æ•ˆæ€§è¦æ±‚è¾ƒé«˜çš„ä¿¡æ¯ã€‚\n",
    "- çŸ­æœŸè®°å¿†ï¼ˆStateï¼‰- åœ¨èŠ‚ç‚¹ä¹‹é—´æŒ‰é¡ºåºä¼ é€’ï¼Œæ¯ä¸ªèŠ‚ç‚¹æ¥æ”¶ä¸Šä¸€ä¸ªèŠ‚ç‚¹å¤„ç†åçš„ Stateã€‚ä¸»è¦ç”¨äºå­˜å‚¨ Prompt å’Œ AI Messageã€‚\n",
    "- é•¿æœŸè®°å¿†ï¼ˆStoreï¼‰- è´Ÿè´£æŒä¹…åŒ–å­˜å‚¨ï¼Œå¯ä»¥è·¨ Workflow / Agent ä¿å­˜ä¿¡æ¯ã€‚å¯ä»¥ç”¨æ¥å­˜ç”¨æˆ·åå¥½ã€ä»¥å‰ç®—è¿‡çš„ç»Ÿè®¡å€¼ç­‰ã€‚\n",
    "\n",
    "ä»¥ä¸‹ä¸‰ä¸ªä¾‹å­ï¼Œåˆ†åˆ«æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨æ¥è‡ª Runtimeã€Stateã€Store ä¸­çš„ä¸Šä¸‹æ–‡ï¼Œç¼–å†™è§¦å‘æ¡ä»¶ã€‚\n",
    "\n",
    "### 1ï¼‰ä½¿ç”¨ `State` åŠ è½½ä¸Šä¸‹æ–‡\n",
    "\n",
    "åˆ©ç”¨ `State` ä¸­è•´å«çš„ä¿¡æ¯æ“çºµ system prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a9eb1bf-37b9-4aab-a8f3-0e1cffca6eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful assistant.\n",
      "This is a long conversation - be extra concise.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "å¹¿å·ä»Šå¤©çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "å¹¿å·å¤©æ°”å¾ˆå¥½\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "åƒç‚¹ä»€ä¹ˆå¥½å‘¢\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "è¦ä¸è¦åƒé¦™èŒ…é³—é±¼ç…²\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "é¦™èŒ…æ˜¯ä»€ä¹ˆ\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "é¦™èŒ…åˆåæŸ æª¬è‰ï¼Œå¸¸è§äºæ³°å¼å†¬é˜´åŠŸæ±¤ã€è¶Šå—çƒ¤è‚‰\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "auv é‚£è¿˜ç­‰ä»€ä¹ˆï¼Œå’±åƒå»å§\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "å¥½ä¸»æ„ï¼é¦™èŒ…é³—é±¼ç…²å¬èµ·æ¥å¾ˆç¾å‘³ï¼Œèµ°å§ï¼\n"
     ]
    }
   ],
   "source": [
    "@dynamic_prompt\n",
    "def state_aware_prompt(request: ModelRequest) -> str:\n",
    "    # request.messages is a shortcut for request.state[\"messages\"]\n",
    "    message_count = len(request.messages)\n",
    "\n",
    "    base = \"You are a helpful assistant.\"\n",
    "\n",
    "    if message_count > 6:\n",
    "        base += \"\\nThis is a long conversation - be extra concise.\"\n",
    "\n",
    "    # ä¸´æ—¶æ‰“å°baseçœ‹æ•ˆæœ\n",
    "    print(base)\n",
    "\n",
    "    return base\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    middleware=[state_aware_prompt]\n",
    ")\n",
    "\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"å¹¿å·ä»Šå¤©çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"å¹¿å·å¤©æ°”å¾ˆå¥½\"},\n",
    "        {\"role\": \"user\", \"content\": \"åƒç‚¹ä»€ä¹ˆå¥½å‘¢\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"è¦ä¸è¦åƒé¦™èŒ…é³—é±¼ç…²\"},\n",
    "        {\"role\": \"user\", \"content\": \"é¦™èŒ…æ˜¯ä»€ä¹ˆ\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"é¦™èŒ…åˆåæŸ æª¬è‰ï¼Œå¸¸è§äºæ³°å¼å†¬é˜´åŠŸæ±¤ã€è¶Šå—çƒ¤è‚‰\"},\n",
    "        {\"role\": \"user\", \"content\": \"auv é‚£è¿˜ç­‰ä»€ä¹ˆï¼Œå’±åƒå»å§\"},\n",
    "    ]},\n",
    ")\n",
    "\n",
    "for message in result['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9c9a5d-90a9-464d-b0dd-bc0b383ce149",
   "metadata": {},
   "source": [
    "æŠŠ `message_count > 6` é‡Œçš„ 6 æ”¹æˆ 7ï¼Œè¯•è¯•çœ‹ä¼šå‘ç”Ÿä»€ä¹ˆã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f4c6d6-cea7-448a-ae42-33bcc64b77a3",
   "metadata": {},
   "source": [
    "### 2ï¼‰ä½¿ç”¨ `Store` åŠ è½½ä¸Šä¸‹æ–‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e98294b9-7a56-499b-a190-e0181e2d6a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Context:\n",
    "    user_id: str\n",
    "\n",
    "@dynamic_prompt\n",
    "def store_aware_prompt(request: ModelRequest) -> str:\n",
    "    user_id = request.runtime.context.user_id\n",
    "\n",
    "    # Read from Store: get user preferences\n",
    "    store = request.runtime.store\n",
    "    user_prefs = store.get((\"preferences\",), user_id)\n",
    "\n",
    "    base = \"You are a helpful assistant.\"\n",
    "\n",
    "    if user_prefs:\n",
    "        style = user_prefs.value.get(\"communication_style\", \"balanced\")\n",
    "        base += f\"\\nUser prefers {style} responses.\"\n",
    "\n",
    "    return base\n",
    "\n",
    "store = InMemoryStore()\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    middleware=[store_aware_prompt],\n",
    "    context_schema=Context,\n",
    "    store=store,\n",
    ")\n",
    "\n",
    "# é¢„ç½®ä¸¤æ¡åå¥½ä¿¡æ¯\n",
    "store.put((\"preferences\",), \"user_1\", {\"communication_style\": \"Chinese\"})\n",
    "store.put((\"preferences\",), \"user_2\", {\"communication_style\": \"Korean\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "509b7bc4-1a3b-4b32-9afe-3db4894c1ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "You are a helpful assistant. Please be extra concise.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is a \"hold short line\"?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "\"Hold short line\" æ˜¯èˆªç©ºæœ¯è¯­ï¼ŒæŒ‡è·‘é“æˆ–æ»‘è¡Œé“ä¸Šçš„ä¸€æ¡æ ‡è®°çº¿ï¼Œè¦æ±‚é£æœºåœ¨æ­¤çº¿å‰åœæ­¢ï¼Œä¸å¾—è¶Šè¿‡ã€‚é€šå¸¸ç”¨äºï¼š\n",
      "\n",
      "1. **è·‘é“ç­‰å¾…çº¿** - ç­‰å¾…èµ·é£è®¸å¯\n",
      "2. **æ»‘è¡Œé“ç­‰å¾…çº¿** - ç­‰å¾…è¿›å…¥è·‘é“æˆ–å…¶ä»–åŒºåŸŸ\n",
      "\n",
      "è¿™æ˜¯é£è¡Œå®‰å…¨çš„é‡è¦ç¨‹åºã€‚\n"
     ]
    }
   ],
   "source": [
    "# ç”¨æˆ·1å–œæ¬¢ä¸­æ–‡å›å¤\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant. Please be extra concise.\"},\n",
    "        {\"role\": \"user\", \"content\": 'What is a \"hold short line\"?'}\n",
    "    ]},\n",
    "    context=Context(user_id=\"user_1\"),\n",
    ")\n",
    "\n",
    "for message in result['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "288d2a65-b328-4448-a155-222afc84f3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "You are a helpful assistant. Please be extra concise.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is a \"hold short line\"?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "\"í™€ë“œ ì‡¼íŠ¸ ë¼ì¸(Hold Short Line)\"ì€ ê³µí•­ í™œì£¼ë¡œì—ì„œ í•­ê³µê¸°ê°€ íŠ¹ì • ì§€ì ê¹Œì§€ë§Œ ì§„ì…í•˜ë„ë¡ ì§€ì‹œí•˜ëŠ” ì„ ì…ë‹ˆë‹¤. ì´ ì„ ì„ ë„˜ì–´ì„œëŠ” ê²ƒì€ ê¸ˆì§€ë˜ì–´ ìˆìœ¼ë©°, ê´€ì œì†Œì˜ í—ˆê°€ë¥¼ ë°›ì•„ì•¼ë§Œ ì§„ì…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì£¼ë¡œ í™œì£¼ë¡œì™€ êµì°¨í•˜ëŠ” ì§€ì ì´ë‚˜ í™œì£¼ë¡œ ì§„ì… ì „ì— ì„¤ì¹˜ë˜ì–´ ì•ˆì „ì„ í™•ë³´í•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# ç”¨æˆ·2å–œæ¬¢éŸ©æ–‡å›å¤\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant. Please be extra concise.\"},\n",
    "        {\"role\": \"user\", \"content\": 'What is a \"hold short line\"?'}\n",
    "    ]},\n",
    "    context=Context(user_id=\"user_2\"),\n",
    ")\n",
    "\n",
    "for message in result['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea07a9a-289f-4f4c-987c-a76f4818e753",
   "metadata": {},
   "source": [
    "### 3ï¼‰ä½¿ç”¨ `Runtime` åŠ è½½ä¸Šä¸‹æ–‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8776b008-b2a7-4947-8bed-f51460d37712",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Context:\n",
    "    user_role: str\n",
    "    deployment_env: str\n",
    "\n",
    "@dynamic_prompt\n",
    "def context_aware_prompt(request: ModelRequest) -> str:\n",
    "    # Read from Runtime Context: user role and environment\n",
    "    user_role = request.runtime.context.user_role\n",
    "    env = request.runtime.context.deployment_env\n",
    "\n",
    "    base = \"You are a helpful assistant.\"\n",
    "\n",
    "    if user_role == \"admin\":\n",
    "        base += \"\\nYou can use the get_weather tool.\"\n",
    "    else:\n",
    "        base += \"\\nYou are prohibited from using the get_weather tool.\"\n",
    "\n",
    "    if env == \"production\":\n",
    "        base += \"\\nBe extra careful with any data modifications.\"\n",
    "\n",
    "    return base\n",
    "\n",
    "@tool\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=[get_weather],\n",
    "    middleware=[context_aware_prompt],\n",
    "    context_schema=Context,\n",
    "    checkpointer=InMemorySaver(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db1a91c1-f87f-46ce-b6fe-251040867390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "å¹¿å·ä»Šå¤©çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_weather (call_b7a1beefd02f4703a3d0caaa)\n",
      " Call ID: call_b7a1beefd02f4703a3d0caaa\n",
      "  Args:\n",
      "    city: å¹¿å·\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_weather\n",
      "\n",
      "It's always sunny in å¹¿å·!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "æ ¹æ®æˆ‘è·å–çš„ä¿¡æ¯ï¼Œå¹¿å·ä»Šå¤©æ˜¯æ™´å¤©ï¼æ°”æ¸©é€‚å®œï¼Œé˜³å…‰æ˜åªšã€‚å¦‚æœä½ åœ¨å¹¿å·ï¼Œè®°å¾—åšå¥½é˜²æ™’æªæ–½ï¼Œäº«å—ç¾å¥½çš„ä¸€å¤©ï¼\n"
     ]
    }
   ],
   "source": [
    "# åˆ©ç”¨ Runtime ä¸­çš„ä¸¤ä¸ªå˜é‡ï¼ŒåŠ¨æ€æ§åˆ¶ System prompt\n",
    "# å°† user_role è®¾ä¸º adminï¼Œå…è®¸ä½¿ç”¨å¤©æ°”æŸ¥è¯¢å·¥å…·\n",
    "config = {'configurable': {'thread_id': str(uuid.uuid4())}}\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"å¹¿å·ä»Šå¤©çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ\"}]},\n",
    "    context=Context(user_role=\"admin\", deployment_env=\"production\"),\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "for message in result['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d51ba924-4b11-4268-a498-29104a3916bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "å¹¿å·ä»Šå¤©çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•è·å–å¤©æ°”ä¿¡æ¯ã€‚æ‚¨å¯ä»¥é€šè¿‡å…¶ä»–é€”å¾„æŸ¥è¯¢å¹¿å·ä»Šå¤©çš„å¤©æ°”ï¼Œä¾‹å¦‚ä½¿ç”¨å¤©æ°”åº”ç”¨æˆ–è®¿é—®å¤©æ°”ç½‘ç«™ã€‚\n"
     ]
    }
   ],
   "source": [
    "# è‹¥å°† user_role æ”¹ä¸º viewerï¼Œåˆ™æ— æ³•ä½¿ç”¨å¤©æ°”æŸ¥è¯¢å·¥å…·\n",
    "config = {'configurable': {'thread_id': str(uuid.uuid4())}}\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"å¹¿å·ä»Šå¤©çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ\"}]},\n",
    "    context=Context(user_role=\"viewer\", deployment_env=\"production\"),\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "for message in result['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ae08b79-0e58-4d4a-90c9-22e9624a4a71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='å¹¿å·ä»Šå¤©çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ', additional_kwargs={}, response_metadata={}, id='58493935-80a8-4f05-818d-4fa3ef684657'),\n",
       " AIMessage(content='æŠ±æ­‰ï¼Œæˆ‘æ— æ³•è·å–å¤©æ°”ä¿¡æ¯ã€‚æ‚¨å¯ä»¥é€šè¿‡å…¶ä»–é€”å¾„æŸ¥è¯¢å¹¿å·ä»Šå¤©çš„å¤©æ°”ï¼Œä¾‹å¦‚ä½¿ç”¨å¤©æ°”åº”ç”¨æˆ–è®¿é—®å¤©æ°”ç½‘ç«™ã€‚', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 287, 'total_tokens': 313, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'qwen3-coder-plus', 'system_fingerprint': None, 'id': 'chatcmpl-b3da39f7-8f49-4a63-9794-06bd7578354f', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--5c17667c-38c3-4856-9610-9d6f4cfd4d16-0', usage_metadata={'input_tokens': 287, 'output_tokens': 26, 'total_tokens': 313, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}})]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['messages']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705e6d02-152c-4a13-a5fc-60e27113d596",
   "metadata": {},
   "source": [
    "## äºŒã€åŠ¨æ€ä¿®æ”¹æ¶ˆæ¯åˆ—è¡¨\n",
    "\n",
    "LangGraph é¢„åˆ¶äº†åŠ¨æ€ä¿®æ”¹æ¶ˆæ¯åˆ—è¡¨ï¼ˆMessagesï¼‰çš„ä¸­é—´ä»¶ `@wrap_model_call`ã€‚ä¸Šä¸€èŠ‚å·²ç»æ¼”ç¤ºå¦‚ä½•ä» `State`ã€`Store`ã€`Runtime` ä¸­è·å–ä¸Šä¸‹æ–‡ï¼Œæœ¬èŠ‚å°†ä¸å†ä¸€ä¸€æ¼”ç¤ºã€‚åœ¨ä¸‹é¢è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬ä¸»è¦æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ `Runtime` å°†æœ¬åœ°æ–‡ä»¶çš„å†…å®¹æ³¨å…¥æ¶ˆæ¯åˆ—è¡¨ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc7b4e4a-1dca-4e40-bafa-840373986c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class FileContext:\n",
    "    uploaded_files: list[dict]\n",
    "\n",
    "@wrap_model_call\n",
    "def inject_file_context(\n",
    "    request: ModelRequest,\n",
    "    handler: Callable[[ModelRequest], ModelResponse]\n",
    ") -> ModelResponse:\n",
    "    \"\"\"Inject context about files user has uploaded this session.\"\"\"\n",
    "    uploaded_files = request.runtime.context.uploaded_files\n",
    "\n",
    "    try:\n",
    "        base_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "    except Exception as e:\n",
    "        import ipynbname\n",
    "        import os\n",
    "        notebook_path = ipynbname.path()\n",
    "        base_dir = os.path.dirname(notebook_path)\n",
    "\n",
    "    file_sections = []\n",
    "    for file in uploaded_files:\n",
    "        name, ftype = \"\", \"\"\n",
    "        path = file.get(\"path\")\n",
    "        if path:\n",
    "            base_filename = os.path.basename(path)\n",
    "            stem, ext = os.path.splitext(base_filename)\n",
    "            name = stem or base_filename\n",
    "            ftype = (ext.lstrip(\".\") if ext else None)\n",
    "\n",
    "            # æ„å»ºæ–‡ä»¶æè¿°å†…å®¹\n",
    "            content_list = [f\"åç§°: {name}\"]\n",
    "            if ftype:\n",
    "                content_list.append(f\"ç±»å‹: {ftype}\")\n",
    "\n",
    "            # è§£æç›¸å¯¹è·¯å¾„ä¸ºç»å¯¹è·¯å¾„\n",
    "            abs_path = path if os.path.isabs(path) else os.path.join(base_dir, path)\n",
    "\n",
    "            # è¯»å–æ–‡ä»¶å†…å®¹\n",
    "            content_block = \"\"\n",
    "            if abs_path and os.path.exists(abs_path):\n",
    "                try:\n",
    "                    with open(abs_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                        content_block = f.read()\n",
    "                except Exception as e:\n",
    "                    content_block = f\"[è¯»å–æ–‡ä»¶é”™è¯¯ '{abs_path}': {e}]\"\n",
    "            else:\n",
    "                content_block = \"[æ–‡ä»¶è·¯å¾„ç¼ºå¤±æˆ–æœªæ‰¾åˆ°]\"\n",
    "\n",
    "            section = (\n",
    "                f\"---\\n\"\n",
    "                f\"{chr(10).join(content_list)}\\n\\n\"\n",
    "                f\"{content_block}\\n\"\n",
    "                f\"---\"\n",
    "            )\n",
    "            file_sections.append(section)\n",
    "\n",
    "        file_context = (\n",
    "            \"å·²åŠ è½½çš„ä¼šè¯æ–‡ä»¶ï¼š\\n\"\n",
    "            f\"{chr(10).join(file_sections)}\"\n",
    "            \"\\nå›ç­”é—®é¢˜æ—¶è¯·å‚è€ƒè¿™äº›æ–‡ä»¶ã€‚\"\n",
    "        )\n",
    "\n",
    "        # Inject file context before recent messages\n",
    "        messages = [  \n",
    "            *request.messages,\n",
    "            {\"role\": \"user\", \"content\": file_context},\n",
    "        ]\n",
    "        request = request.override(messages=messages)  \n",
    "\n",
    "    return handler(request)\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    middleware=[inject_file_context],\n",
    "    context_schema=FileContext,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9048a7e0-2131-4841-82f2-b1f7fca1c1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "å…³äºä¸Šæµ·åœ°é“çš„æ— è„¸ä¹˜å®¢ï¼Œæœ‰ä»€ä¹ˆéœ€è¦æ³¨æ„çš„ï¼Ÿ\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "æ ¹æ®ã€Šä¸Šæµ·è§„åˆ™æ€ªè°ˆã€‹ä¸­çš„æè¿°ï¼Œå…³äºä¸Šæµ·åœ°é“çš„â€œæ— è„¸ä¹˜å®¢â€ï¼Œä½ éœ€è¦ç‰¹åˆ«æ³¨æ„ä»¥ä¸‹å‡ ç‚¹ï¼š\n",
      "\n",
      "---\n",
      "\n",
      "### ğŸš‡ **åœ°é“ä¸Šçš„é™Œç”Ÿäººï¼ˆæ— è„¸ä¹˜å®¢ï¼‰è§„åˆ™ï¼š**\n",
      "\n",
      "> **â€œåœ°é“è¿è¥ç»“æŸåï¼Œè‹¥ä½ ä»èº«å¤„è½¦å¢å†…ï¼Œä¼šå‡ºç°ä¸€ä½æ— è„¸ä¹˜å®¢ã€‚ä»–ä¼šä½å£°é—®ï¼šâ€˜ä½ è¦å»å“ªï¼Ÿâ€™åªèƒ½æŠ¥ä¸€ä¸ªçœŸå®å­˜åœ¨çš„ä¸Šæµ·åœ°åã€‚è¯´å‡ºä¸å­˜åœ¨çš„åœ°åæˆ–ä¿æŒæ²‰é»˜ï¼Œä½ ä¼šåœ¨è½¦å¢å†…çœ‹åˆ°è‡ªå·±çš„å°¸ä½“ã€‚â€**\n",
      "\n",
      "---\n",
      "\n",
      "### âš ï¸ æ³¨æ„äº‹é¡¹ï¼š\n",
      "\n",
      "1. **æ—¶é—´ç‚¹ï¼š**  \n",
      "   è¯¥ç°è±¡å‘ç”Ÿåœ¨**åœ°é“è¿è¥ç»“æŸä¹‹å**ï¼Œå¦‚æœä½ å› æŸç§åŸå› æ»ç•™åœ¨åœ°é“è½¦å¢å†…ï¼Œè¯·æé«˜è­¦æƒ•ã€‚\n",
      "\n",
      "2. **æ— è„¸ä¹˜å®¢çš„å‡ºç°ï¼š**  \n",
      "   ä»–ä¼šä¸»åŠ¨é è¿‘ä½ ï¼Œå¹¶ä½å£°è¯¢é—®ï¼šâ€œ**ä½ è¦å»å“ªï¼Ÿ**â€\n",
      "\n",
      "3. **æ­£ç¡®åº”å¯¹æ–¹å¼ï¼š**  \n",
      "   - å¿…é¡»å›ç­”ä¸€ä¸ª**çœŸå®å­˜åœ¨äºä¸Šæµ·çš„åœ°å**ï¼Œä¾‹å¦‚â€œäººæ°‘å¹¿åœºâ€ã€â€œå¾å®¶æ±‡â€ã€â€œé™†å®¶å˜´â€ç­‰ã€‚\n",
      "   - å›ç­”è¦æ¸…æ™°ã€å‡†ç¡®ï¼Œä¸èƒ½çŠ¹è±«æˆ–è¯´é”™ã€‚\n",
      "\n",
      "4. **é”™è¯¯è¡Œä¸ºåŠåæœï¼š**  \n",
      "   - è‹¥ä½ å›ç­”ä¸€ä¸ª**ä¸å­˜åœ¨çš„åœ°å**ï¼ˆå¦‚â€œæ–°å®¿â€ã€â€œç‹åºœäº•â€ï¼‰ï¼Œæˆ–**ä¿æŒæ²‰é»˜**ï¼Œä½ å°†ä¼šåœ¨è½¦å¢ä¸­çœ‹åˆ°**è‡ªå·±çš„å°¸ä½“**ã€‚\n",
      "   - è¿™æ„å‘³ç€ä½ å°†æ— æ³•é€ƒè„±æ­»äº¡çš„å‘½è¿ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### ğŸ§  å°è´´å£«ï¼š\n",
      "\n",
      "- å¦‚æœä½ ä¸ç¡®å®šæŸä¸ªåœ°åæ˜¯å¦å±äºä¸Šæµ·ï¼Œå»ºè®®æå‰äº†è§£ä¸€äº›çœŸå®åœ°åä»¥é˜²ä¸‡ä¸€ã€‚\n",
      "- è‹¥çœŸçš„é­é‡æ­¤æƒ…æ™¯ï¼Œä¿æŒå†·é™ï¼Œè¿…é€Ÿå›å¿†ä¸€ä¸ªç¡®åˆ‡çš„ä¸Šæµ·åœ°åä½œç­”ã€‚\n",
      "- åˆ‡å‹¿è¯•å›¾æ¬ºéª—ã€å¼€ç©ç¬‘æˆ–æ²‰é»˜ä¸è¯­ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "**è®°ä½ï¼šè§„åˆ™æ˜¯ç”Ÿå­˜çš„åº•çº¿ï¼Œè¿è€…â€”â€”åæœè‡ªè´Ÿã€‚**\n"
     ]
    }
   ],
   "source": [
    "result = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"å…³äºä¸Šæµ·åœ°é“çš„æ— è„¸ä¹˜å®¢ï¼Œæœ‰ä»€ä¹ˆéœ€è¦æ³¨æ„çš„ï¼Ÿ\",\n",
    "        }],\n",
    "    },\n",
    "    context=FileContext(uploaded_files=[{\"path\": \"./docs/rule_horror.md\"}]),\n",
    ")\n",
    "\n",
    "for message in result['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59498b8d-9b5d-4cb3-bc86-0230e76a8121",
   "metadata": {},
   "source": [
    "## ä¸‰ã€åœ¨å·¥å…·ä¸­ä½¿ç”¨ä¸Šä¸‹æ–‡\n",
    "\n",
    "ä¸‹é¢ï¼Œæˆ‘ä»¬å°è¯•åœ¨å·¥å…·ä¸­ä½¿ç”¨å­˜å‚¨åœ¨ `SqliteStore` ä¸­çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a33e3357-71e3-4ae3-a956-9e6ad0076a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ é™¤SQLiteæ•°æ®åº“\n",
    "if os.path.exists(\"user-info.db\"):\n",
    "    os.remove(\"user-info.db\")\n",
    "\n",
    "# åˆ›å»ºSQLiteå­˜å‚¨\n",
    "conn = sqlite3.connect(\"user-info.db\", check_same_thread=False, isolation_level=None)\n",
    "conn.execute(\"PRAGMA journal_mode=WAL;\")\n",
    "conn.execute(\"PRAGMA busy_timeout = 30000;\")\n",
    "\n",
    "store = SqliteStore(conn)\n",
    "\n",
    "# é¢„ç½®ä¸¤æ¡ç”¨æˆ·ä¿¡æ¯\n",
    "store.put((\"user_info\",), \"æŸ³å¦‚çƒŸ\", {\"description\": \"æ¸…å†·æ‰å¥³ï¼Œèº«æ€€ç»æŠ€ï¼Œä¸ºå¯»èº«ä¸–ä¹‹è°œè¸å…¥æ±Ÿæ¹–ã€‚\", \"birthplace\": \"å´å…´å¿\"})\n",
    "store.put((\"user_info\",), \"è‹æ…•ç™½\", {\"description\": \"å­¤å‚²å‰‘å®¢ï¼Œå‰‘æ³•è¶…ç¾¤ï¼ŒèƒŒè´Ÿå®¶æ—è¡€ä»‡ï¼Œéšäºå¸‚äº•è¿½å¯»çœŸç›¸ã€‚\", \"birthplace\": \"æ­å¿\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0dd8c15-f80a-4885-9477-37d84bbf9495",
   "metadata": {},
   "source": [
    "### 1ï¼‰åŸºç¡€ç”¨ä¾‹\n",
    "\n",
    "ä½¿ç”¨ `ToolRuntime`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de7547ce-963e-48bf-9855-ab32521c034e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def fetch_user_data(\n",
    "    user_id: str,\n",
    "    runtime: ToolRuntime\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Fetch user information from the in-memory store.\n",
    "\n",
    "    :param user_id: The unique identifier of the user.\n",
    "    :param runtime: The tool runtime context injected by the framework.\n",
    "    :return: The user's description string if found; an empty string otherwise.\n",
    "    \"\"\"\n",
    "    store = runtime.store\n",
    "    user_info = store.get((\"user_info\",), user_id)\n",
    "\n",
    "    user_desc = \"\"\n",
    "    if user_info:\n",
    "        user_desc = user_info.value.get(\"description\", \"\")\n",
    "\n",
    "    return user_desc\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=[fetch_user_data],\n",
    "    store=store,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60289d99-0235-464c-837c-407065b0096d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "äº”åˆ†é’Ÿä¹‹å†…ï¼Œæˆ‘è¦æŸ³å¦‚çƒŸçš„å…¨éƒ¨ä¿¡æ¯\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  fetch_user_data (call_bb5059c893d74cebac0f7727)\n",
      " Call ID: call_bb5059c893d74cebac0f7727\n",
      "  Args:\n",
      "    user_id: æŸ³å¦‚çƒŸ\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: fetch_user_data\n",
      "\n",
      "æ¸…å†·æ‰å¥³ï¼Œèº«æ€€ç»æŠ€ï¼Œä¸ºå¯»èº«ä¸–ä¹‹è°œè¸å…¥æ±Ÿæ¹–ã€‚\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "æ ¹æ®æˆ‘ç›®å‰æŒæ¡çš„ä¿¡æ¯ï¼ŒæŸ³å¦‚çƒŸæ˜¯ä¸€ä½æ¸…å†·æ‰å¥³ï¼Œèº«æ€€ç»æŠ€ï¼Œä¸ºäº†æ¢å¯»è‡ªå·±çš„èº«ä¸–ä¹‹è°œè€Œè¸å…¥æ±Ÿæ¹–ã€‚ä¸è¿‡ï¼Œè¿™ä»…ä»…æ˜¯å¥¹çš„ä¸€éƒ¨åˆ†ä¿¡æ¯ï¼Œæ›´å¤šè¯¦ç»†èµ„æ–™å¯èƒ½éœ€è¦è¿›ä¸€æ­¥è°ƒæŸ¥æ‰èƒ½è·å¾—ã€‚ä½ å¯¹å¥¹æœ‰ä»€ä¹ˆç‰¹åˆ«çš„å…´è¶£æˆ–ç›®çš„å—ï¼Ÿæˆ–è®¸æˆ‘å¯ä»¥å¸®ä½ äº†è§£æ›´å¤šã€‚\n"
     ]
    }
   ],
   "source": [
    "result = agent.invoke({\n",
    "    \"messages\": [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"äº”åˆ†é’Ÿä¹‹å†…ï¼Œæˆ‘è¦æŸ³å¦‚çƒŸçš„å…¨éƒ¨ä¿¡æ¯\"\n",
    "    }]\n",
    "})\n",
    "\n",
    "for message in result['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d620c05d-aa96-4d3b-9dfd-9774c99e38f7",
   "metadata": {},
   "source": [
    "### 2ï¼‰å¤æ‚ä¸€ç‚¹çš„ä¾‹å­\n",
    "\n",
    "ä½¿ç”¨ `ToolRuntime[Context]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1950ba66-93e9-43d2-af5b-b048783287bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Context:\n",
    "    key: str\n",
    "\n",
    "@tool\n",
    "def fetch_user_data(\n",
    "    user_id: str,\n",
    "    runtime: ToolRuntime[Context]\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Fetch user information from the in-memory store.\n",
    "\n",
    "    :param user_id: The unique identifier of the user.\n",
    "    :param runtime: The tool runtime context injected by the framework.\n",
    "    :return: The user's description string if found; an empty string otherwise.\n",
    "    \"\"\"\n",
    "    key = runtime.context.key\n",
    "\n",
    "    store = runtime.store\n",
    "    user_info = store.get((\"user_info\",), user_id)\n",
    "\n",
    "    user_desc = \"\"\n",
    "    if user_info:\n",
    "        user_desc = user_info.value.get(key, \"\")\n",
    "\n",
    "    return f\"{key}: {user_desc}\"\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=[fetch_user_data],\n",
    "    store=store,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3dd427af-d129-401c-a643-eea926af05d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "äº”åˆ†é’Ÿä¹‹å†…ï¼Œæˆ‘è¦æŸ³å¦‚çƒŸçš„å…¨éƒ¨ä¿¡æ¯\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  fetch_user_data (call_5373b11fd735425990cc9748)\n",
      " Call ID: call_5373b11fd735425990cc9748\n",
      "  Args:\n",
      "    user_id: æŸ³å¦‚çƒŸ\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: fetch_user_data\n",
      "\n",
      "birthplace: å´å…´å¿\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "æŸ³å¦‚çƒŸçš„åŸºæœ¬ä¿¡æ¯å¦‚ä¸‹ï¼š\n",
      "\n",
      "- **å‡ºç”Ÿåœ°**ï¼šå´å…´å¿\n",
      "\n",
      "ç”±äºæ—¶é—´é™åˆ¶ï¼Œç›®å‰ä»…è·å–åˆ°ä»¥ä¸Šä¿¡æ¯ã€‚å¦‚éœ€æ›´è¯¦ç»†çš„èµ„æ–™ï¼Œè¯·æä¾›æ›´å¤šçº¿ç´¢æˆ–å»¶é•¿æŸ¥è¯¢æ—¶é—´ã€‚\n"
     ]
    }
   ],
   "source": [
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"äº”åˆ†é’Ÿä¹‹å†…ï¼Œæˆ‘è¦æŸ³å¦‚çƒŸçš„å…¨éƒ¨ä¿¡æ¯\"}]},\n",
    "    context=Context(key=\"birthplace\"),\n",
    ")\n",
    "\n",
    "for message in result['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a892c0-3a74-47d4-aef2-dd7bf3270ead",
   "metadata": {},
   "source": [
    "### å››ã€å‹ç¼©ä¸Šä¸‹æ–‡\n",
    "\n",
    "LangChain æä¾›äº†å†…ç½®çš„ä¸­é—´ä»¶ `SummarizationMiddleware` ç”¨äºå‹ç¼©ä¸Šä¸‹æ–‡ã€‚è¯¥ä¸­é—´ä»¶ç»´æŠ¤çš„æ˜¯å…¸å‹çš„ **ç”Ÿå‘½å‘¨æœŸä¸Šä¸‹æ–‡**ï¼Œä¸ **æ¨¡å‹ä¸Šä¸‹æ–‡** å’Œ **å·¥å…·ä¸Šä¸‹æ–‡** çš„ç¬æ€æ›´æ–°ä¸åŒï¼Œç”Ÿå‘½å‘¨æœŸä¸Šä¸‹æ–‡ä¼šæŒç»­æ›´æ–°ï¼šæŒç»­å°†æ—§æ¶ˆæ¯æ›¿æ¢ä¸ºæ‘˜è¦ã€‚\n",
    "\n",
    "é™¤éä¸Šä¸‹æ–‡è¶…é•¿ï¼Œå¯¼è‡´æ¨¡å‹èƒ½åŠ›é™ä½ï¼Œå¦åˆ™ä¸éœ€è¦ä½¿ç”¨ `SummarizationMiddleware`ã€‚ä¸€èˆ¬æ¥è¯´ï¼Œè§¦å‘æ‘˜è¦å¾—å€¼å¯ä»¥è®¾å¾—è¾ƒå¤§ã€‚æ¯”å¦‚ï¼š\n",
    "\n",
    "- `max_tokens_before_summary`: 3000\n",
    "- `messages_to_keep`: 20\n",
    "\n",
    "> å¦‚æœä½ æƒ³äº†è§£æ›´å¤šå…³äºä¸Šä¸‹æ–‡è…åï¼ˆContext Rotï¼‰çš„ä¿¡æ¯ï¼ŒChroma å›¢é˜Ÿåœ¨ 2025 å¹´ 7 æœˆ 14 æ—¥å‘å¸ƒçš„ [*Context Rot: How Increasing Input Tokens Impacts LLM Performance*](https://research.trychroma.com/context-rot)ï¼Œç³»ç»Ÿæ€§åœ°æ­ç¤ºäº†é•¿ä¸Šä¸‹æ–‡å¯¼è‡´æ¨¡å‹æ€§èƒ½é€€åŒ–çš„ç°è±¡ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c75a7d59-9edf-4a00-af8a-3a6d06d6f27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»ºçŸ­æœŸè®°å¿†\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "# åˆ›å»ºå¸¦å†…ç½®æ‘˜è¦ä¸­é—´ä»¶çš„Agent\n",
    "# ä¸ºäº†è®©é…ç½®èƒ½åœ¨æˆ‘ä»¬çš„ä¾‹å­é‡Œç”Ÿæ•ˆï¼Œè¿™é‡Œçš„è§¦å‘å€¼è®¾å¾—å¾ˆå°\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    middleware=[\n",
    "        SummarizationMiddleware(\n",
    "            model=llm,\n",
    "            max_tokens_before_summary=40,  # Trigger summarization at 40 tokens\n",
    "            messages_to_keep=1,  # Keep last 1 messages after summary\n",
    "        ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91068064-ef38-4ae3-841b-5bc7be34c624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Here is a summary of the conversation to date:\n",
      "\n",
      "å¹¿å·å¤©æ°”å¾ˆå¥½ï¼›å»ºè®®åƒé¦™èŒ…é³—é±¼ç…²ï¼›é¦™èŒ…åˆåæŸ æª¬è‰ï¼Œå¸¸è§äºæ³°å¼å†¬é˜´åŠŸæ±¤ã€è¶Šå—çƒ¤è‚‰ã€‚\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "auv é‚£è¿˜ç­‰ä»€ä¹ˆï¼Œå’±åƒå»å§\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "å“ˆå“ˆï¼Œçœ‹èµ·æ¥ä½ å·²ç»è¿«ä¸åŠå¾…äº†ï¼ğŸ˜„\n",
      "\n",
      "æ—¢ç„¶å¹¿å·å¤©æ°”è¿™ä¹ˆå¥½ï¼Œé¦™èŒ…é³—é±¼ç…²å¬èµ·æ¥ç¡®å®æ˜¯ä¸ªä¸é”™çš„é€‰æ‹©ã€‚ä½ æåˆ°çš„é¦™èŒ…ï¼ˆæŸ æª¬è‰ï¼‰ç¡®å®æ˜¯ä¸œå—äºšæ–™ç†ä¸­çš„ç»å…¸é¦™æ–™ï¼Œèƒ½ä¸ºé³—é±¼å¢æ·»ç‹¬ç‰¹çš„æ¸…é¦™ã€‚\n",
      "\n",
      "ä¸è¿‡æˆ‘å¾—æé†’ä¸€ä¸‹ï¼Œä½œä¸ºAIï¼Œæˆ‘æ— æ³•çœŸæ­£å’Œä½ ä¸€èµ·å»åƒé¥­ã€‚å¦‚æœä½ çœŸçš„è¦å»å“å°è¿™é“èœï¼Œè®°å¾—é€‰æ‹©é£Ÿææ–°é²œã€å£ç¢‘å¥½çš„é¤å…å“¦ï¼\n",
      "\n",
      "ä½ æ˜¯åœ¨å¹¿å·å—ï¼Ÿè¿˜æ˜¯åœ¨å…¶ä»–åœ°æ–¹æƒ³å°è¯•è¿™é“èœï¼Ÿ\n"
     ]
    }
   ],
   "source": [
    "result = agent.invoke(\n",
    "    {\"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"å¹¿å·ä»Šå¤©çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"å¹¿å·å¤©æ°”å¾ˆå¥½\"},\n",
    "        {\"role\": \"user\", \"content\": \"åƒç‚¹ä»€ä¹ˆå¥½å‘¢\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"è¦ä¸è¦åƒé¦™èŒ…é³—é±¼ç…²\"},\n",
    "        {\"role\": \"user\", \"content\": \"é¦™èŒ…æ˜¯ä»€ä¹ˆ\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"é¦™èŒ…åˆåæŸ æª¬è‰ï¼Œå¸¸è§äºæ³°å¼å†¬é˜´åŠŸæ±¤ã€è¶Šå—çƒ¤è‚‰\"},\n",
    "        {\"role\": \"user\", \"content\": \"auv é‚£è¿˜ç­‰ä»€ä¹ˆï¼Œå’±åƒå»å§\"},\n",
    "    ]},\n",
    "    checkpointer=checkpointer,\n",
    ")\n",
    "\n",
    "for message in result['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725262df-d313-4499-ad09-fe12ac9c7955",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
