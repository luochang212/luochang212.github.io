{"version":2,"kind":"Notebook","sha256":"43a7e0439ed9c1dd39a2e8b2b24de24fb239448f61d2ce1186ff559d879577c9","slug":"middleware","location":"/3.middleware.ipynb","dependencies":[],"frontmatter":{"title":"中间件","content_includes_title":false,"kernelspec":{"name":"py313","display_name":"Python (py3.13)","language":"python"},"github":"https://github.com/luochang212/langgraph-tutorial","keywords":["LangGraph","Langchain"],"source_url":"https://github.com/luochang212/langgraph-tutorial/blob/main/3.middleware.ipynb","edit_url":"https://github.com/luochang212/langgraph-tutorial/edit/main/3.middleware.ipynb","exports":[{"format":"ipynb","filename":"3.middleware.ipynb","url":"/3.middleware-636d923e44e09ffc5f851eb2a56cb1f7.ipynb"}]},"widgets":{},"mdast":{"type":"root","children":[{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"一、预算控制","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"TZRs5eSz3H"}],"identifier":"id","label":"一、预算控制","html_id":"id","implicit":true,"key":"o6mwzf6lfQ"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"利用运行时（runtime）和上下文（context），我们可以动态地更改模型配置。这种动态性能帮助我们更好地控制模型。","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"rlGKemwwPE"}],"key":"dLX1UzPj2g"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"一个实用的场景是「预算控制」。随着对话轮次增加，积累的历史对话越来越多，每次请求的费用也随之增加。为了控制预算，我们可以设定在对话超过某个轮次之后，切换到费率较低的模型。该功能可以通过中间件实现。","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"JtoAtr1HQl"}],"key":"PMssjEUb3B"},{"type":"paragraph","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"事实上，中间件（middleware）能实现的功能有很多，可以将它视为 Agent 的万能控制接口。","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"EkpKPsvEyt"},{"type":"inlineCode","value":"LangChain v1.0","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"bdVzL1Tm4g"},{"type":"text","value":" 通过引入中间件，极大增强了对 Agent 的掌控力。","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"Au5B3QTixJ"}],"key":"jMH1qCMp0q"}],"key":"EpZe1ujatV"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"import os\nfrom dotenv import load_dotenv\nfrom langchain_openai import ChatOpenAI\nfrom langchain.agents import create_agent\nfrom langchain.agents.middleware import wrap_model_call, ModelRequest, ModelResponse\nfrom langchain_core.messages import HumanMessage\nfrom langgraph.graph import MessagesState\n\n# 加载模型配置\n_ = load_dotenv()\n\n# 低费率模型\nbasic_model = ChatOpenAI(\n    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n    base_url=os.getenv(\"DASHSCOPE_BASE_URL\"),\n    model=\"qwen3-coder-plus\",\n)\n\n# 高费率模型\nadvanced_model = ChatOpenAI(\n    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n    base_url=os.getenv(\"DASHSCOPE_BASE_URL\"),\n    model=\"qwen3-max\",\n)","key":"w4NHEYEduS"},{"type":"output","id":"deXk2Kll3B_oVeowWhwiq","data":[],"key":"BkYvawyAZ5"}],"key":"jTznsHZCvK"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"具体来讲，使用 ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"i7JjWjJuKW"},{"type":"link","url":"https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.wrap_model_call","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"cite","identifier":"wrap_model_call","label":"wrap_model_call","kind":"narrative","position":{"start":{"line":1,"column":10},"end":{"line":1,"column":26}},"error":"not found","key":"zUcLYfHePV"}],"urlSource":"https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.wrap_model_call","key":"VWIvzoZD7q"},{"type":"text","value":" 装饰器可以创建控制模型的中间件。","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"mGv82yowAM"}],"key":"fgE1nMzFep"}],"key":"Gdh2VsxajC"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"@wrap_model_call\ndef dynamic_model_selection(request: ModelRequest, handler) -> ModelResponse:\n    \"\"\"Choose model based on conversation complexity.\"\"\"\n    message_count = len(request.state[\"messages\"])\n\n    if message_count > 5:\n        # Use an advanced model for longer conversations\n        model = advanced_model\n    else:\n        model = basic_model\n\n    request.model = model\n    print(f\"message_count: {message_count}\")\n    print(f\"model_name: {model.model_name}\")\n\n    return handler(request)\n\nagent = create_agent(\n    model=basic_model,  # Default model\n    middleware=[dynamic_model_selection]\n)","key":"QWwDaG3H5V"},{"type":"output","id":"nlcfI-XBANvXtJ-H5uBmp","data":[],"key":"gdBzSVDj60"}],"key":"JSuyHjJBJ0"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"state: MessagesState = {\"messages\": []}\nitems = ['汽车', '飞机', '摩托车', '自行车']\nfor idx, i in enumerate(items):\n    print(f\"\\n=== Round {idx+1} ===\")\n    state[\"messages\"] += [HumanMessage(content=f\"{i}有几个轮子，请简单回答\")]\n    result = agent.invoke(state)\n    state[\"messages\"] = result[\"messages\"]\n    print(f\"content: {result[\"messages\"][-1].content}\")","key":"gdGx2htmN2"},{"type":"output","id":"Up9u26bb-JGMdmXnN8SDA","data":[{"name":"stdout","output_type":"stream","text":"\n=== Round 1 ===\nmessage_count: 1\nmodel_name: qwen3-coder-plus\ncontent: 汽车有4个轮子。\n\n=== Round 2 ===\nmessage_count: 3\nmodel_name: qwen3-coder-plus\ncontent: 飞机有3个轮子（起落架）。\n\n=== Round 3 ===\nmessage_count: 5\nmodel_name: qwen3-coder-plus\ncontent: 摩托车有2个轮子。\n\n=== Round 4 ===\nmessage_count: 7\nmodel_name: qwen3-max\ncontent: 自行车有2个轮子。\n"}],"key":"IstdPsgTAi"}],"key":"zO6htPr5NX"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"二、消息截断","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"v6i9cPmzYf"}],"identifier":"id","label":"二、消息截断","html_id":"id-1","implicit":true,"key":"v5gmWhTYYp"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"智能体系统的上下文长度是有限的，若超过限制，就要想办法压缩上下文。在所有方法中，最简单粗暴的方法就是截断。消息截断的功能可以用 ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"dVf8DGez8n"},{"type":"inlineCode","value":"@before_model","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"YdpSiKLc0q"},{"type":"text","value":" 装饰器实现。","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"k2wOfO5ZS4"}],"key":"J9lPMgJStx"}],"key":"QmbIPu7Rmc"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"from langchain.messages import RemoveMessage\nfrom langgraph.graph.message import REMOVE_ALL_MESSAGES\nfrom langgraph.checkpoint.memory import InMemorySaver\nfrom langchain.agents import create_agent, AgentState\nfrom langchain.agents.middleware import before_model\nfrom langgraph.runtime import Runtime\nfrom langchain_core.runnables import RunnableConfig\nfrom typing import Any","key":"fMUZuhYakr"},{"type":"output","id":"sWXYiNsSGmylimr-bi84V","data":[],"key":"TxDu1cI4ja"}],"key":"HLBkEDpWhV"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"在下面的例子中，由于我们始终保留第一条消息，因此智能体总是记得我叫 bob。","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"TnuKVugBcP"}],"key":"Mtlehh3VqU"}],"key":"NZkTR4YzIs"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"@before_model\ndef trim_messages(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n    \"\"\"Keep only the last few messages to fit context window.\"\"\"\n    messages = state[\"messages\"]\n\n    if len(messages) <= 3:\n        return None  # No changes needed\n\n    first_msg = messages[0]\n    recent_messages = messages[-3:] if len(messages) % 2 == 0 else messages[-4:]\n    new_messages = [first_msg] + recent_messages\n\n    return {\n        \"messages\": [\n            RemoveMessage(id=REMOVE_ALL_MESSAGES),\n            *new_messages\n        ]\n    }\n\nagent = create_agent(\n    basic_model,\n    middleware=[trim_messages],\n    checkpointer=InMemorySaver(),\n)\n\nconfig: RunnableConfig = {\"configurable\": {\"thread_id\": \"1\"}}\n\ndef agent_invoke(agent):\n    agent.invoke({\"messages\": \"hi, my name is bob\"}, config)\n    agent.invoke({\"messages\": \"write a short poem about cats\"}, config)\n    agent.invoke({\"messages\": \"now do the same but for dogs\"}, config)\n    final_response = agent.invoke({\"messages\": \"what's my name?\"}, config)\n    \n    final_response[\"messages\"][-1].pretty_print()\n\nagent_invoke(agent)","key":"iHvsussEQA"},{"type":"output","id":"hQ4w5YyaBbqIhCnhyT1zj","data":[{"name":"stdout","output_type":"stream","text":"==================================\u001b[1m Ai Message \u001b[0m==================================\n\nYour name is Bob! You introduced yourself to me earlier.\n"}],"key":"iPtOZAg5ED"}],"key":"EgUYBtkdPO"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"我们对中间件进行一些修改，仅保留最后两条对话记录，现在智能体不记得我是 bob 了。","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"QPSj0kKUSP"}],"key":"gsa1MmqaTu"}],"key":"nURfs1fdre"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"@before_model\ndef trim_without_first_message(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n    \"\"\"Keep only the last few messages to fit context window.\"\"\"\n    messages = state[\"messages\"]\n\n    return {\n        \"messages\": [\n            RemoveMessage(id=REMOVE_ALL_MESSAGES),\n            *messages[-2:]\n        ]\n    }\n\nagent = create_agent(\n    basic_model,\n    middleware=[trim_without_first_message],\n    checkpointer=InMemorySaver(),\n)\n\nagent_invoke(agent)","key":"KZ8nvz2fAK"},{"type":"output","id":"o_0Zf-XWs7kVhVQ8TzOdL","data":[{"name":"stdout","output_type":"stream","text":"==================================\u001b[1m Ai Message \u001b[0m==================================\n\nI don't have access to your name or personal information. I don't know who you are beyond our current conversation. If you'd like to share your name, I'd be happy to use it, but I can't access that information on my own. Is there something specific I can help you with today?\n"}],"key":"cLgXqxt1xS"}],"key":"LGqx13BIfG"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"三、护栏：敏感词过滤","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"YJRsIuSF06"}],"identifier":"id","label":"三、护栏：敏感词过滤","html_id":"id-2","implicit":true,"key":"JSBCY4xLCg"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"智能体能在模型之外提供额外的安全性，我们一般把这种安全能力称为护栏（Guardrails）。在 LangGraph 中，护栏可以通过中间件实现。下面通过两个具体的例子，演示如何使用护栏提升智能体的安全性。","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"pc3wsuH9m9"}],"key":"AFd86TIVmE"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"我们先实现一个简单的安全策略：检测用户最新一条输入，若其中包含指定的敏感词，则智能体拒绝回答用户的问题。","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"oy8hiw81dg"}],"key":"OTYlhVQcwd"}],"key":"I7KkjZtPqQ"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"from typing import Any\n\nfrom langchain.agents.middleware import before_agent, AgentState, hook_config\nfrom langgraph.runtime import Runtime\n\nbanned_keywords = [\"hack\", \"exploit\", \"malware\"]\n\n@before_agent(can_jump_to=[\"end\"])\ndef content_filter(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n    \"\"\"Deterministic guardrail: Block requests containing banned keywords.\"\"\"\n    # Get the first user message\n    if not state[\"messages\"]:\n        return None\n\n    last_message = state[\"messages\"][-1]\n    if last_message.type != \"human\":\n        return None\n\n    content = last_message.content.lower()\n\n    # Check for banned keywords\n    for keyword in banned_keywords:\n        if keyword in content:\n            # Block execution before any processing\n            return {\n                \"messages\": [{\n                    \"role\": \"assistant\",\n                    \"content\": \"I cannot process requests containing inappropriate content. Please rephrase your request.\"\n                }],\n                \"jump_to\": \"end\"\n            }\n\n    return None\n\nagent = create_agent(\n    model=basic_model,\n    middleware=[content_filter],\n)\n\n# This request will be blocked before any processing\nresult = agent.invoke({\n    \"messages\": [{\"role\": \"user\", \"content\": \"How do I hack into a database?\"}]\n})","key":"KcVIHLAJn0"},{"type":"output","id":"2w5EoyKLmuci1sCTZTuyS","data":[],"key":"RRQwW0peBl"}],"key":"zSw2YWkec8"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"for message in result[\"messages\"]:\n    message.pretty_print()","key":"JTOAGaNJBr"},{"type":"output","id":"rGQThCPXt6fDxCTmdqMAl","data":[{"name":"stdout","output_type":"stream","text":"================================\u001b[1m Human Message \u001b[0m=================================\n\nHow do I hack into a database?\n==================================\u001b[1m Ai Message \u001b[0m==================================\n\nI cannot process requests containing inappropriate content. Please rephrase your request.\n"}],"key":"qdVzPjjuuz"}],"key":"GDvasItJXD"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"四、护栏：PII 检测","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"KtBTyfMoEl"}],"identifier":"id-pii","label":"四、护栏：PII 检测","html_id":"id-pii","implicit":true,"key":"SZix9PRMUo"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"link","url":"https://docs.langchain.com/oss/python/langchain/guardrails#pii-detection","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"PII","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"HOHAbnNtlT"}],"urlSource":"https://docs.langchain.com/oss/python/langchain/guardrails#pii-detection","key":"jFbWAt8WxT"},{"type":"text","value":"（Personally Identifiable Information）检测是一个常见的、用于过滤用户敏感信息的功能。它能检测用户的电子邮件、信用卡、IP 地址等敏感信息，以防止信息泄漏。","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"AOtvj57OiM"}],"key":"PLStsIDJAF"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"在下面的例子中，我们使用 LLM 检测敏感信息，并使用两种策略进行处理。","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"MCOh6EgHYn"}],"key":"FDMEoLfjic"}],"key":"TYx77XNV4T"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"from textwrap import dedent\nfrom pydantic import BaseModel, Field\n\n# 可信任的模型，一般是本地模型，为了方便，这里依然使用qwen\ntrusted_model = ChatOpenAI(\n    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n    base_url=os.getenv(\"DASHSCOPE_BASE_URL\"),\n    model=\"qwen3-coder-plus\",\n)\n\n# 用于格式化智能体输出，若发现敏感信息返回Ture，没发现返回False\nclass PiiCheck(BaseModel):\n    \"\"\"Structured output indicating whether text contains PII.\"\"\"\n    is_pii: bool = Field(description=\"Whether the text contains PII\")\n\ndef message_with_pii(pii_middleware):\n    agent = create_agent(\n        model=basic_model,\n        middleware=[pii_middleware],\n    )\n\n    # This request will be blocked before any processing\n    result = agent.invoke({\n        \"messages\": [{\n            \"role\": \"user\",\n            \"content\": dedent(\n                \"\"\"\n                File \"/home/luochang/proj/agent.py\", line 53, in my_agent\n                    agent = create_react_agent(\n                            ^^^^^^^^^^^^^^^^^^^\n                File \"/home/luochang/miniconda3/lib/python3.12/site-packages/typing_extensions.py\", line 2950, in wrapper\n                    return arg(*args, **kwargs)\n                        ^^^^^^^^^^^^^^^^^^^^\n                File \"/home/luochang/miniconda3/lib/python3.12/site-packages/langgraph/prebuilt/chat_agent_executor.py\", line 566, in create_react_agent\n                    model = cast(BaseChatModel, model).bind_tools(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n                AttributeError: 'RunnableLambda' object has no attribute 'bind_tools'\n    \n                ---\n    \n                为啥报错\n                \"\"\").strip()\n        }]\n    })\n\n    return result","key":"ITupI8DOCh"},{"type":"output","id":"vK82tMKwHWDDyHLnPBt86","data":[],"key":"IQNisIEkhZ"}],"key":"qid3GNnkFC"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"策略一","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"xHuD05nqRg"}],"key":"YjIx3ZPBUI"},{"type":"text","value":"：如遇敏感信息，拒绝回复。","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"hE9r2l1T6e"}],"key":"MTibqgj2E4"}],"key":"YJX8gyerhY"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"@before_agent(can_jump_to=[\"end\"])\ndef content_blocker(state: AgentState,  runtime: Runtime) -> dict[str, Any] | None:\n    \"\"\"Deterministic guardrail: Block requests containing banned keywords.\"\"\"\n    # Get the first user message\n    if not state[\"messages\"]:\n        return None\n\n    last_message = state[\"messages\"][-1]\n    if last_message.type != \"human\":\n        return None\n\n    content = last_message.content.lower()\n    prompt = (\n        \"你是一个隐私保护助手。请识别下面文本中涉及个人可识别信息（PII），\"\n        \"例如：姓名、身份证号、护照号、电话号码、邮箱、住址、银行卡号、社交账号、车牌等。\"\n        \"特别注意，若代码、文件路径中包含用户名，也应被视为敏感信息。\"\n        \"若包含敏感信息，请返回{\\\"is_pii\\\": True}，否则返回{\\\"is_pii\\\": False}。\"\n        \"请严格以 json 格式返回，并且只输出 json。文本如下：\\n\\n\" + content\n    )\n\n    pii_agent = trusted_model.with_structured_output(PiiCheck)\n    result = pii_agent.invoke(prompt)\n\n    if result.is_pii is True:\n        # Block execution before any processing\n        return {\n            \"messages\": [{\n                \"role\": \"assistant\",\n                \"content\": \"I cannot process requests containing inappropriate content. Please rephrase your request.\"\n            }],\n            \"jump_to\": \"end\"\n        }\n    else:\n        print(\"No PII found\")\n\n    return None","key":"qX4to6wo2L"},{"type":"output","id":"OkK0YmsYgDSnlza9NU8az","data":[],"key":"v12MXuzkEp"}],"key":"mNQtSfoyAF"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"result = message_with_pii(pii_middleware=content_blocker)\n\nfor message in result[\"messages\"]:\n    message.pretty_print()","key":"CCQ5M45XBn"},{"type":"output","id":"a5EUwq_noTQ86lJgtcDOA","data":[{"name":"stdout","output_type":"stream","text":"================================\u001b[1m Human Message \u001b[0m=================================\n\nFile \"/home/luochang/proj/agent.py\", line 53, in my_agent\n    agent = create_react_agent(\n            ^^^^^^^^^^^^^^^^^^^\nFile \"/home/luochang/miniconda3/lib/python3.12/site-packages/typing_extensions.py\", line 2950, in wrapper\n    return arg(*args, **kwargs)\n        ^^^^^^^^^^^^^^^^^^^^\nFile \"/home/luochang/miniconda3/lib/python3.12/site-packages/langgraph/prebuilt/chat_agent_executor.py\", line 566, in create_react_agent\n    model = cast(BaseChatModel, model).bind_tools(\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAttributeError: 'RunnableLambda' object has no attribute 'bind_tools'\n\n---\n\n为啥报错\n==================================\u001b[1m Ai Message \u001b[0m==================================\n\nI cannot process requests containing inappropriate content. Please rephrase your request.\n"}],"key":"duGUD5fVbA"}],"key":"cfbIFSLimD"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"策略二","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"CGq7mrvdgn"}],"key":"RbG2TfmEvx"},{"type":"text","value":"：如遇敏感信息，使用 ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"M2pAKANmaA"},{"type":"inlineCode","value":"*","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"IDI4ZC5mv3"},{"type":"text","value":" 号屏蔽敏感信息。","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"A17fT29k7x"}],"key":"cJfvGJpCh6"}],"key":"sqSEk8RYRu"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"@before_agent(can_jump_to=[\"end\"])\ndef content_filter(state: AgentState,  runtime: Runtime) -> dict[str, Any] | None:\n    \"\"\"Deterministic guardrail: Block requests containing banned keywords.\"\"\"\n    # Get the first user message\n    if not state[\"messages\"]:\n        return None\n\n    last_message = state[\"messages\"][-1]\n    if last_message.type != \"human\":\n        return None\n\n    content = last_message.content.lower()\n    prompt = (\n        \"你是一个隐私保护助手。请识别下面文本中涉及个人可识别信息（PII），\"\n        \"例如：姓名、身份证号、护照号、电话号码、邮箱、住址、银行卡号、社交账号、车牌等。\"\n        \"特别注意，若代码、文件路径中包含用户名，也应被视为敏感信息。\"\n        \"若包含敏感信息，请返回{\\\"is_pii\\\": True}，否则返回{\\\"is_pii\\\": False}。\"\n        \"请严格以 json 格式返回，并且只输出 json。文本如下：\\n\\n\" + content\n    )\n\n    pii_agent = trusted_model.with_structured_output(PiiCheck)\n    result = pii_agent.invoke(prompt)\n\n    if result.is_pii is True:\n        mask_prompt = (\n            \"你是一个隐私保护助手。请将下面文本中的所有个人可识别信息（PII）用星号（*）替换。\"\n            \"仅替换敏感片段，其他文本保持不变。\"\n            \"只输出处理后的文本，不要任何解释或额外内容。文本如下：\\n\\n\" + last_message.content\n        )\n        masked_message = basic_model.invoke(mask_prompt)\n        return {\n            \"messages\": [{\n                \"role\": \"assistant\",\n                \"content\": masked_message.content\n            }]\n        }\n    else:\n        print(\"No PII found\")\n\n    return None","key":"FxxqnEbp1a"},{"type":"output","id":"iN0vkoPetNbe66iMl2_qy","data":[],"key":"vZnyuNveRF"}],"key":"hcppnA1m2l"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"result = message_with_pii(pii_middleware=content_filter)\n\nfor message in result[\"messages\"]:\n    message.pretty_print()","key":"EucmwPV2wW"},{"type":"output","id":"3csTKl3Ev7rvm9dHkXpj6","data":[{"name":"stdout","output_type":"stream","text":"================================\u001b[1m Human Message \u001b[0m=================================\n\nFile \"/home/luochang/proj/agent.py\", line 53, in my_agent\n    agent = create_react_agent(\n            ^^^^^^^^^^^^^^^^^^^\nFile \"/home/luochang/miniconda3/lib/python3.12/site-packages/typing_extensions.py\", line 2950, in wrapper\n    return arg(*args, **kwargs)\n        ^^^^^^^^^^^^^^^^^^^^\nFile \"/home/luochang/miniconda3/lib/python3.12/site-packages/langgraph/prebuilt/chat_agent_executor.py\", line 566, in create_react_agent\n    model = cast(BaseChatModel, model).bind_tools(\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAttributeError: 'RunnableLambda' object has no attribute 'bind_tools'\n\n---\n\n为啥报错\n==================================\u001b[1m Ai Message \u001b[0m==================================\n\nFile \"/home/********/proj/agent.py\", line 53, in my_agent\n    agent = create_react_agent(\n            ^^^^^^^^^^^^^^^^^^^\nFile \"/home/********/miniconda3/lib/python3.12/site-packages/typing_extensions.py\", line 2950, in wrapper\n    return arg(*args, **kwargs)\n        ^^^^^^^^^^^^^^^^^^^^\nFile \"/home/********/miniconda3/lib/python3.12/site-packages/langgraph/prebuilt/chat_agent_executor.py\", line 566, in create_react_agent\n    model = cast(BaseChatModel, model).bind_tools(\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAttributeError: 'RunnableLambda' object has no attribute 'bind_tools'\n\n---\n\n为啥报错\n==================================\u001b[1m Ai Message \u001b[0m==================================\n\n这个错误的原因是：**你传给 `create_react_agent` 的 model 参数是一个 `RunnableLambda` 对象，而不是一个支持 `bind_tools` 方法的聊天模型**。\n\n## 问题分析\n\n`create_react_agent` 函数期望接收一个实现了 `bind_tools` 方法的聊天模型（如 `ChatOpenAI`、`ChatAnthropic` 等），但你传入的是一个 `RunnableLambda` 对象，这个对象没有 `bind_tools` 方法。\n\n## 解决方案\n\n### 方案1：直接使用聊天模型（推荐）\n\n```python\nfrom langchain_openai import ChatOpenAI\nfrom langgraph.prebuilt import create_react_agent\n\n# 直接使用聊天模型\nmodel = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n\nagent = create_react_agent(\n    model=model,\n    tools=your_tools,\n    # 其他参数...\n)\n```\n\n### 方案2：如果你需要使用 RunnableLambda，需要包装一下\n\n```python\nfrom langchain_openai import ChatOpenAI\nfrom langchain_core.runnables import RunnableLambda\n\n# 先创建聊天模型\nchat_model = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n\n# 如果你需要自定义处理逻辑\ndef custom_process(input_data):\n    # 你的自定义逻辑\n    return input_data\n\n# 创建 RunnableLambda\ncustom_runnable = RunnableLambda(custom_process)\n\n# 在 create_react_agent 中仍然使用原始的聊天模型\nagent = create_react_agent(\n    model=chat_model,  # 使用原始聊天模型，不是 RunnableLambda\n    tools=your_tools,\n)\n```\n\n### 方案3：检查你的 model 创建代码\n\n看起来你可能这样创建了 model：\n\n```python\n# 错误的方式\nmodel = RunnableLambda(some_function)\nagent = create_react_agent(model=model, tools=tools)  # 这会报错\n```\n\n应该改为：\n\n```python\n# 正确的方式\nfrom langchain_openai import ChatOpenAI\n\nmodel = ChatOpenAI(model=\"gpt-3.5-turbo\")  # 或其他聊天模型\nagent = create_react_agent(model=model, tools=tools)\n```\n\n## 总结\n\n确保传给 `create_react_agent` 的 `model` 参数是一个标准的聊天模型对象，而不是 `RunnableLambda` 或其他不支持 `bind_tools` 方法的对象。\n"}],"key":"nIPLDNQSby"}],"key":"PZ49mtepcQ"}],"key":"bnKzMYNIhw"},"references":{"cite":{"order":[],"data":{}}}}