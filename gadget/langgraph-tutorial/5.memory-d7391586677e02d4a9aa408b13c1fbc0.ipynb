{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "892ac848-252a-4b16-975f-b19305ea177f",
   "metadata": {},
   "source": [
    "# 记忆\n",
    "\n",
    "[Memory](https://docs.langchain.com/oss/python/langgraph/add-memory) 是一个可选组件。除非必要，你无需向智能体添加 memory 功能。\n",
    "\n",
    "常见的需要添加 memory 的场景包括：\n",
    "\n",
    "1. 对话的上下文超过限制，需要记忆或压缩上下文\n",
    "2. 触发人工干预（[interrupt](https://docs.langchain.com/oss/python/langgraph/interrupts)）之后，需要存储智能体状态，并在人工干预后恢复\n",
    "3. 需要跨对话提取用户偏好\n",
    "\n",
    "在 LangGraph 中，记忆功能被分为长、短两个模块。如果你想进一步了解，可以参阅它们的文档：\n",
    "\n",
    "- [短期记忆](https://docs.langchain.com/oss/python/langchain/short-term-memory)\n",
    "- [长期记忆](https://docs.langchain.com/oss/python/langchain/long-term-memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2aff8836-8798-4920-b679-7abe02218d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "# 加载模型配置\n",
    "_ = load_dotenv()\n",
    "\n",
    "# 加载模型\n",
    "model = ChatOpenAI(\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    base_url=os.getenv(\"DASHSCOPE_BASE_URL\"),\n",
    "    model=\"qwen3-coder-plus\",\n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "# 创建助手节点\n",
    "def assistant(state: MessagesState):\n",
    "    return {'messages': [model.invoke(state['messages'])]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dfc72f-332c-4c57-b0b7-88e961b79f87",
   "metadata": {},
   "source": [
    "## 一、短期记忆\n",
    "\n",
    "短期记忆（工作记忆）一般用于临时存储，与当前对话内容强相关。与依赖上下文的记忆方式不同，短期记忆可以主动记住重要的内容，增加工程稳定性。\n",
    "\n",
    "### 1）在 `StateGraph` 中使用短期记忆\n",
    "\n",
    "为了方便演示，我们使用 `InMemorySaver` 存储短期记忆。这意味着短期记忆存储在内存中。如果退出当前程序，记忆将会消失。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db7794c6-13cb-4b0f-bf19-ef9bc6dc14b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! i am luochang\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi Luochang! Nice to meet you. How are you doing today? Is there anything I can help you with?\n"
     ]
    }
   ],
   "source": [
    "# 创建短期记忆\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "# 创建图\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "# 添加节点\n",
    "builder.add_node('assistant', assistant)\n",
    "\n",
    "# 添加边\n",
    "builder.add_edge(START, 'assistant')\n",
    "builder.add_edge('assistant', END)\n",
    "\n",
    "graph = builder.compile(checkpointer=checkpointer)\n",
    "\n",
    "# 告诉智能体我叫 luochang\n",
    "result = graph.invoke(\n",
    "    {'messages': ['hi! i am luochang']},\n",
    "    {\"configurable\": {\"thread_id\": \"1\"}},\n",
    ")\n",
    "\n",
    "for message in result['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8c6c699-c2b8-466c-8877-877b3b40382e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! i am luochang\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi Luochang! Nice to meet you. How are you doing today? Is there anything I can help you with?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is my name?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Your name is Luochang, as you introduced yourself to me earlier!\n"
     ]
    }
   ],
   "source": [
    "# 让智能体说出我的名字\n",
    "result = graph.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is my name?\"}]},\n",
    "    {\"configurable\": {\"thread_id\": \"1\"}},  \n",
    ")\n",
    "\n",
    "for message in result['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f2b2f6-9cb0-4b9e-89a2-89de5d53d925",
   "metadata": {},
   "source": [
    "### 2）在 `create_agent` 中使用短期记忆"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59286c68-a72d-4e92-b7b3-b81db8e0e451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! i am luochang\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi Luochang! Nice to meet you. How are you doing today? Is there anything I can help you with?\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "# 创建短期记忆\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    checkpointer=checkpointer\n",
    ")\n",
    "\n",
    "# 告诉智能体我叫 luochang\n",
    "result = agent.invoke(\n",
    "    {'messages': ['hi! i am luochang']},\n",
    "    {\"configurable\": {\"thread_id\": \"2\"}},\n",
    ")\n",
    "\n",
    "for message in result['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93509d9f-370f-4ea8-abdb-ae01fd51e112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! i am luochang\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi Luochang! Nice to meet you. How are you doing today? Is there anything I can help you with?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is my name?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Your name is Luochang, as you introduced yourself to me earlier!\n"
     ]
    }
   ],
   "source": [
    "# 让智能体说出我的名字\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is my name?\"}]},\n",
    "    {\"configurable\": {\"thread_id\": \"2\"}},  \n",
    ")\n",
    "\n",
    "for message in result['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf12a1a-0c98-4c61-9f23-12a829ee2251",
   "metadata": {},
   "source": [
    "为了验证 `InMemorySaver` 是否真的有效果，可以将 `checkpointer=checkpointer` 注释后，再观察智能体能不能正确回复我的名字。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56656f1-dd75-4c97-8244-88bc521a5608",
   "metadata": {},
   "source": [
    "### 3）使用外部数据库支持的短期记忆\n",
    "\n",
    "如果使用 SQLite 保存当前工作状态，即使退出程序，依然能在下次进入时恢复上次退出时的状态，我们来测试这一点。\n",
    "\n",
    "在使用 SQLite 作为短期记忆的外部数据库之前，需要安装一个 Python 包以支持这项功能：\n",
    "\n",
    "```bash\n",
    "pip install langgraph-checkpoint-sqlite\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6ffbd2f-9330-4663-9547-f21df46af401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除SQLite数据库\n",
    "if os.path.exists(\"short-memory.db\"):\n",
    "    os.remove(\"short-memory.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6d3dc0f-dcff-4d2d-b708-8acb516cb3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! i am luochang\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi Luochang! Nice to meet you. How are you doing today? Is there anything I can help you with?\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sqlite3\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "# 加载模型配置\n",
    "_ = load_dotenv()\n",
    "\n",
    "# 加载模型\n",
    "model = ChatOpenAI(\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    base_url=os.getenv(\"DASHSCOPE_BASE_URL\"),\n",
    "    model=\"qwen3-coder-plus\",\n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "# 创建sqlite支持的短期记忆\n",
    "checkpointer = SqliteSaver(\n",
    "    sqlite3.connect(\"short-memory.db\", check_same_thread=False)\n",
    ")\n",
    "\n",
    "# 创建Agent\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    checkpointer=checkpointer,\n",
    ")\n",
    "\n",
    "# 告诉智能体我叫 luochang\n",
    "result = agent.invoke(\n",
    "    {'messages': ['hi! i am luochang']},\n",
    "    {\"configurable\": {\"thread_id\": \"3\"}},\n",
    ")\n",
    "\n",
    "for message in result['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7f7a61-8974-4f67-ab6f-9fcf755d4c4e",
   "metadata": {},
   "source": [
    "重启 Jupyter Notebook 后看智能体能否从 SQLite 中读取关于我名字的记忆。\n",
    "\n",
    "在 `Kernel` -> `Restart Kernel...` 中重启服务。然后运行以下代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "768b2abc-6531-4308-a7b0-16dc80eeca0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! i am luochang\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi Luochang! Nice to meet you. How are you doing today? Is there anything I can help you with?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is my name?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Your name is Luochang, as you introduced yourself to me earlier!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sqlite3\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "# 加载模型配置\n",
    "_ = load_dotenv()\n",
    "\n",
    "# 加载模型\n",
    "model = ChatOpenAI(\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    base_url=os.getenv(\"DASHSCOPE_BASE_URL\"),\n",
    "    model=\"qwen3-coder-plus\",\n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "# 创建sqlite支持的短期记忆\n",
    "checkpointer = SqliteSaver(\n",
    "    sqlite3.connect(\"short-memory.db\", check_same_thread=False)\n",
    ")\n",
    "\n",
    "# 创建Agent\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    checkpointer=checkpointer,\n",
    ")\n",
    "\n",
    "# 让智能体回忆我的名字\n",
    "result = agent.invoke(\n",
    "    {'messages': ['What is my name?']},\n",
    "    {\"configurable\": {\"thread_id\": \"3\"}},\n",
    ")\n",
    "\n",
    "for message in result['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf7455a-da1f-467a-8969-9fd280f35927",
   "metadata": {},
   "source": [
    "## 二、长期记忆"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "45f7cefb-5eb9-4315-be82-b098041832f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain.agents import create_agent\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "from dataclasses import dataclass\n",
    "\n",
    "EMBED_MODEL = \"text-embedding-v4\"\n",
    "EMBED_DIM = 1024\n",
    "\n",
    "# 加载模型配置\n",
    "_ = load_dotenv()\n",
    "\n",
    "# 用于获取text embedding的接口\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    base_url=os.getenv(\"DASHSCOPE_BASE_URL\"),\n",
    ")\n",
    "\n",
    "# 加载模型\n",
    "model = ChatOpenAI(\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    base_url=os.getenv(\"DASHSCOPE_BASE_URL\"),\n",
    "    model=\"qwen3-coder-plus\",\n",
    "    temperature=0.7,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7474fde3-0f84-4a52-bcd8-46c626208e29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1024)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embedding生成函数\n",
    "def embed(texts: list[str]) -> list[list[float]]:\n",
    "    response = client.embeddings.create(\n",
    "        model=EMBED_MODEL,\n",
    "        input=texts,\n",
    "        dimensions=EMBED_DIM,\n",
    "    )\n",
    "\n",
    "    return [item.embedding for item in response.data]\n",
    "\n",
    "# 测试能否正常生成text embedding\n",
    "texts = [\n",
    "    \"LangGraph的中间件非常强大\",\n",
    "    \"LangGraph的MCP也很好用\",\n",
    "]\n",
    "vectors = embed(texts)\n",
    "\n",
    "len(vectors), len(vectors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cf724b-0087-41fb-824b-4f7613618871",
   "metadata": {},
   "source": [
    "### 1）直接读写长期记忆"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7cd1e8f5-9d37-4c62-9060-f801912e1948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Item(namespace=['users'], key='user_1', value={'rules': ['User likes short, direct language', 'User only speaks English & python'], 'rule_id': '3'}, created_at='2025-11-04T10:08:24.319215+00:00', updated_at='2025-11-04T10:08:24.319226+00:00', score=0.4085710154661828)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# InMemoryStore saves data to an in-memory dictionary. Use a DB-backed store in production use.\n",
    "store = InMemoryStore(index={\"embed\": embed, \"dims\": EMBED_DIM})\n",
    "\n",
    "# 添加两条用户数据\n",
    "namespace = (\"users\", )\n",
    "key = \"user_1\"\n",
    "store.put(\n",
    "    namespace,\n",
    "    key,\n",
    "    {\n",
    "        \"rules\": [\n",
    "            \"User likes short, direct language\",\n",
    "            \"User only speaks English & python\",\n",
    "        ],\n",
    "        \"rule_id\": \"3\",\n",
    "    },\n",
    ")\n",
    "\n",
    "store.put( \n",
    "    (\"users\",),  # Namespace to group related data together (users namespace for user data)\n",
    "    \"user_2\",  # Key within the namespace (user ID as key)\n",
    "    {\n",
    "        \"name\": \"John Smith\",\n",
    "        \"language\": \"English\",\n",
    "    }  # Data to store for the given user\n",
    ")\n",
    "\n",
    "# get the \"memory\" by ID\n",
    "item = store.get(namespace, \"a-memory\") \n",
    "\n",
    "# search for \"memories\" within this namespace, filtering on content equivalence, sorted by vector similarity\n",
    "items = store.search( \n",
    "    namespace, filter={\"rule_id\": \"3\"}, query=\"language preferences\"\n",
    ")\n",
    "\n",
    "items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0908fd8e-e04b-41f6-ba2d-61449d219d81",
   "metadata": {},
   "source": [
    "### 2）使用工具读取长期记忆"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dd5f5405-5e7f-4d01-a77d-f5c5e30e54d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "look up user information\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_user_info (call_fb3ff8f64e7f4bd1b7e2d854)\n",
      " Call ID: call_fb3ff8f64e7f4bd1b7e2d854\n",
      "  Args:\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_user_info\n",
      "\n",
      "{'name': 'John Smith', 'language': 'English'}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The user's name is John Smith and their language is English.\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class Context:\n",
    "    user_id: str\n",
    "\n",
    "@tool\n",
    "def get_user_info(runtime: ToolRuntime[Context]) -> str:\n",
    "    \"\"\"Look up user info.\"\"\"\n",
    "    # Access the store - same as that provided to `create_agent`\n",
    "    store = runtime.store \n",
    "    user_id = runtime.context.user_id\n",
    "    # Retrieve data from store - returns StoreValue object with value and metadata\n",
    "    user_info = store.get((\"users\",), user_id) \n",
    "    return str(user_info.value) if user_info else \"Unknown user\"\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[get_user_info],\n",
    "    # Pass store to agent - enables agent to access store when running tools\n",
    "    store=store, \n",
    "    context_schema=Context\n",
    ")\n",
    "\n",
    "# Run the agent\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"look up user information\"}]},\n",
    "    context=Context(user_id=\"user_2\") \n",
    ")\n",
    "\n",
    "for message in result['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f0d880-2ece-429a-b4c0-a93de51e70da",
   "metadata": {},
   "source": [
    "### 3）使用工具写入长期记忆"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "23fce454-a575-412e-a31c-b196731e6539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'John Smith'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing_extensions import TypedDict\n",
    "\n",
    "# InMemoryStore saves data to an in-memory dictionary. Use a DB-backed store in production.\n",
    "store = InMemoryStore() \n",
    "\n",
    "@dataclass\n",
    "class Context:\n",
    "    user_id: str\n",
    "\n",
    "# TypedDict defines the structure of user information for the LLM\n",
    "class UserInfo(TypedDict):\n",
    "    name: str\n",
    "\n",
    "# Tool that allows agent to update user information (useful for chat applications)\n",
    "@tool\n",
    "def save_user_info(user_info: UserInfo, runtime: ToolRuntime[Context]) -> str:\n",
    "    \"\"\"Save user info.\"\"\"\n",
    "    # Access the store - same as that provided to `create_agent`\n",
    "    store = runtime.store \n",
    "    user_id = runtime.context.user_id \n",
    "    # Store data in the store (namespace, key, data)\n",
    "    store.put((\"users\",), user_id, user_info) \n",
    "    return \"Successfully saved user info.\"\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[save_user_info],\n",
    "    store=store,\n",
    "    context_schema=Context\n",
    ")\n",
    "\n",
    "# Run the agent\n",
    "agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"My name is John Smith\"}]},\n",
    "    # user_id passed in context to identify whose information is being updated\n",
    "    context=Context(user_id=\"user_123\") \n",
    ")\n",
    "\n",
    "# You can access the store directly to get the value\n",
    "store.get((\"users\",), \"user_123\").value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e4bfc1-bec6-43ee-9f5d-0130f98b2ef9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py3.13)",
   "language": "python",
   "name": "py313"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
