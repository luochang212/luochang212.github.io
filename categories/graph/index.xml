<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Graph on Chang Luo</title>
    <link>http://localhost:1313/categories/graph/</link>
    <description>Recent content in Graph on Chang Luo</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 10 Aug 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/categories/graph/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>三种图神经网络算法：GraphSAGE, GCN 和 GAT</title>
      <link>http://localhost:1313/posts/graph_embedding/</link>
      <pubDate>Sat, 10 Aug 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/graph_embedding/</guid>
      <description>GitHub 项目地址：graph-embedding&#xA;✨ 本文做了什么：&#xA;对简单版的 GraphSAGE 做逐行注释 使用 Docker 运行 GraphSAGE 的原版示例 用 PyG 实现简单的 GCN 和 GAT 为运行 PyG 写了一些可复用的 pipeline 代码 注意：运行以下代码依赖 util.py 文件。&#xA;一、GraphSAGE 的简单实现 主流图算法大致分两种：&#xA;图嵌入算法 (GE): DeepWalk, Node2Vec 等 图神经网络算法 (GNN): GraphSAGE, GCN, GAT 等 1.1 绪论：图神经网络 图神经网络的输入一般是 节点关联数据 和 节点特征数据，输出是图嵌入。图神经网络算法做的事情，相当于将一种复杂的数据结构，转换成低维向量。低维向量往往是很好用的。&#xA;拿到图嵌入，我们可以做很多事情，比如：&#xA;节点分类 链接预测 社区发现 相似度量 总之，图嵌入是一种很有用的特征。图嵌入甚至可以和其他特征融合，训练更复杂的模型。&#xA;1.1.1 GNN 和 CNN GNN 似乎和 CNN 用了相同的思路。GNN 就像是 CNN 在图这种数据结构上的推广，我个人是这么感觉的。&#xA;我们说，CNN 有平移不变性和局部性。其中 局部性 是指：每个神经元只看一小块像素，但随着神经元在层数上堆叠，层级越高的神经元，“看到”的像素数量越多（如下图）。&#xA;假设 $C_1$ 能看见 4 个像素，$C_2$ 能看见 4 个像素。由于 $B_1$ 能看见 $C_1$ 和 $C_2$，所以相当于 $B_1$ 能够“看见” 4*2=8 个像素。</description>
    </item>
  </channel>
</rss>
