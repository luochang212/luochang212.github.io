<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Agent on Chang Luo</title>
    <link>https://luochang212.github.io/categories/agent/</link>
    <description>Recent content in Agent on Chang Luo</description>
    <generator>Hugo</generator>
    <language>zh-cn</language>
    <lastBuildDate>Sun, 18 Jan 2026 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://luochang212.github.io/categories/agent/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>在树莓派上搭建家用 Agent 服务</title>
      <link>https://luochang212.github.io/posts/rpi_agent_server/</link>
      <pubDate>Sun, 18 Jan 2026 00:00:00 +0000</pubDate>
      <guid>https://luochang212.github.io/posts/rpi_agent_server/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;使用树莓派搭建 &lt;a href=&#34;https://github.com/luochang212/dive-into-langgraph/tree/main/app&#34;&gt;dive-into-langgraph/app&lt;/a&gt; 服务，在家庭局域网内部使用。&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;p&gt;一键部署脚本：&lt;a href=&#34;https://github.com/luochang212/agent-server&#34;&gt;agent-server&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h3 id=&#34;一制作-tf-卡&#34;&gt;一、制作 TF 卡&lt;/h3&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; 你可以参考我的这篇博客《&lt;a href=&#34;https://luochang212.github.io/posts/raspberry_pi_5/&#34;&gt;树莓派 5 装机指南&lt;/a&gt;》，它写得更详细一些。但部分信息已经过时，请注意甄别。&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;h4 id=&#34;1下载&#34;&gt;1）下载&lt;/h4&gt;&#xA;&lt;p&gt;你需要下载两样东西：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.raspberrypi.com/software/&#34;&gt;Raspberry Pi Imager&lt;/a&gt;：将镜像写入 TF 卡的工具&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://ubuntu.com/download/raspberry-pi&#34;&gt;Ubuntu 24.04.3 LTS&lt;/a&gt;：树莓派的 Ubuntu 镜像&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Ubuntu 镜像有两种版本：桌面版、服务器版，我们下载服务器版。下载的时候可以检查一下，安装包的文件名应该是这个 &lt;code&gt;ubuntu-24.04.3-preinstalled-server-arm64+raspi.img.xz&lt;/code&gt;&lt;/p&gt;&#xA;&lt;h4 id=&#34;2将镜像写入-tf-卡&#34;&gt;2）将镜像写入 TF 卡&lt;/h4&gt;&#xA;&lt;p&gt;根据 &lt;strong&gt;Raspberry Pi Imager&lt;/strong&gt; 的指引，完成镜像烧录的过程就好了。并没有什么难的。唯一需要注意的是，由于我们已经下载了 Ubuntu 镜像，所以这里要选「使用自定义镜像」。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://luochang212.github.io/img/Raspberry-Pi-Imager-2025.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;h3 id=&#34;二首次启动-ubuntu&#34;&gt;二、首次启动 Ubuntu&lt;/h3&gt;&#xA;&lt;p&gt;烧录完成后，按以下步骤操作：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;先断电，然后将 TF 卡插入板子&lt;/li&gt;&#xA;&lt;li&gt;连接外接显示屏、键盘、网线&lt;/li&gt;&#xA;&lt;li&gt;最后插入电源&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;一般来讲，插电即可点亮。这时回车一下，即可输入账号密码，初始账密是：&lt;/p&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;&lt;/th&gt;&#xA;          &lt;th&gt;&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;账号&lt;/td&gt;&#xA;          &lt;td&gt;ubuntu&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;密码&lt;/td&gt;&#xA;          &lt;td&gt;ubuntu&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;p&gt;输完账密，它会接着让你设置新密码。这里流程设计得有点人机，需要注意看提示，不然容易卡关。温馨提示：你输入 &lt;code&gt;ubuntu&lt;/code&gt; 的次数比你想象中更多。&lt;/p&gt;&#xA;&lt;h3 id=&#34;三环境配置&#34;&gt;三、环境配置&lt;/h3&gt;&#xA;&lt;h4 id=&#34;1更新软件包&#34;&gt;1）更新软件包&lt;/h4&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#57606a&#34;&gt;# 更新软件源的索引列表&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo apt update&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#57606a&#34;&gt;# 根据更新后的索引，升级所有可更新的软件包&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo apt upgrade -y&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;2安装-pipx-和-uv&#34;&gt;2）安装 pipx 和 uv&lt;/h4&gt;&#xA;&lt;p&gt;先安装 &lt;code&gt;pipx&lt;/code&gt;，再用它安装 &lt;code&gt;uv&lt;/code&gt;：&lt;/p&gt;</description>
    </item>
    <item>
      <title>RAG：大模型时代的搜索基座</title>
      <link>https://luochang212.github.io/posts/rag_intro/</link>
      <pubDate>Sat, 27 Dec 2025 00:00:00 +0000</pubDate>
      <guid>https://luochang212.github.io/posts/rag_intro/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;没有一条帆船能吹动自己行驶，它需要外面的风。 &amp;ndash; 因可觅《量子离歌》&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;p&gt;大模型的训练数据有截止日期，在此之后的事它不知道；大模型的参数量有限，无法容纳所有专业知识。也就是说，大模型在实时性和专业性上都有所欠缺。&lt;/p&gt;&#xA;&lt;p&gt;如何让大模型变得实时且专业呢？最省力的方法是“打小抄”。&lt;strong&gt;知识库&lt;/strong&gt; 就像大模型的“小抄”。在回答问题之前，先瞅一眼小抄，看有没有与问题相关的内容。如果有，就从知识库中取回这段内容，结合大模型的推理能力，生成最终答案。&lt;/p&gt;&#xA;&lt;p&gt;这里「打小抄」的动作，就是 &lt;a href=&#34;https://docs.langchain.com/oss/python/langchain/retrieval&#34;&gt;&lt;strong&gt;RAG&lt;/strong&gt;&lt;/a&gt;（Retrieval-Augmented Generation, 检索增强生成）。&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; 使用知识库可以让大模型的回答有据可依、减少幻觉，代价是需要承担知识库的构建成本。尤其当知识库的规模较大时，有必要想想是否值得支付对价。毕竟，通过扩大知识库的方式提升 Agent 性能，多少有点「用有限对抗无限，用确定对抗不确定」的意思。虽然我们总是在提起 RAG 时提到知识库，但 RAG 是一种检索技术，它可以检索任何内容。比起检索需要手动构建的知识库，用来检索联网内容、历史对话也是可以的，而且性价比很高。你的下一个检索对象，又何必是知识库。&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;h2 id=&#34;一提示词模板&#34;&gt;一、提示词模板&lt;/h2&gt;&#xA;&lt;p&gt;RAG 做的事情并不复杂，就是从知识库中召回与用户问题有关的内容，作为上下文注入到 &lt;strong&gt;提示词模板 (Prompt Template)&lt;/strong&gt; 中。&lt;/p&gt;&#xA;&lt;p&gt;下面是一个提示词模板：&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;{context}&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;---&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;基于上面给出的上下文，回答问题。&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;问题：{question}&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;回答： &#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;使用该模板时，将召回文本填入 &lt;code&gt;{context}&lt;/code&gt;，将用户问题填入 &lt;code&gt;{question}&lt;/code&gt;。然后把填好的提示词模板交给大模型推理。&lt;/p&gt;&#xA;&lt;p&gt;RAG 主要做了两件事：一是从知识库中 &lt;strong&gt;召回&lt;/strong&gt; 与用户问题有关的文本，二是使用提示词模板 &lt;strong&gt;拼接&lt;/strong&gt; 召回文本与用户问题。拼接很容易做到，难度主要集中在召回上。在下一小节中，我将介绍如何召回与用户问题有关的文本。&lt;/p&gt;&#xA;&lt;h2 id=&#34;二向量检索&#34;&gt;二、向量检索&lt;/h2&gt;&#xA;&lt;p&gt;完成「召回与用户问题有关的」这件事，需要用到检索器。实现检索器的方式有 &lt;a href=&#34;https://docs.langchain.com/oss/python/integrations/retrievers&#34;&gt;很多&lt;/a&gt;，比如基于关键词检索的 &lt;a href=&#34;https://docs.langchain.com/oss/python/integrations/retrievers/bm25&#34;&gt;BM25&lt;/a&gt; 算法，但本节主要介绍基于 Embedding 的检索方法：&lt;strong&gt;向量检索&lt;/strong&gt;。&lt;/p&gt;&#xA;&lt;h3 id=&#34;1从文本向量化说起&#34;&gt;1）从文本向量化说起&lt;/h3&gt;&#xA;&lt;p&gt;Embedding 是一种将文本转为向量的技术。它的输入是一段文本，输出是一个定长的向量。&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;&amp;#34;好喜欢你&amp;#34; --&amp;gt; [0.190012, 0.123555, .... ]&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;将文本转为向量的目的，是把语义相近的词分配到同一片向量空间。所以，一对近义词转成向量后，它们的向量之间的距离通常比其他词更近。比如，足球和篮球在向量空间中的距离更近一些，而足球和篮筐之间的距离更远。Embedding 的本质是压缩。从编码角度讲，自然语言存在冗余信息。Embedding 相当于对自然语言进行重编码，用最少的 token 表达最多的语义。&lt;/p&gt;&#xA;&lt;p&gt;Embedding 在多语言场景下也有优势。经过充分训练的 Embedding 模型，会将多语言内容在语义层面上对齐。也就是说，一个向量可以在多语言环境中保持同一语义。这种特性让大模型得以兼容并包。即使加入多语言材料，也不会因为字面上的词不同，而产生“理解”上的混乱。&lt;/p&gt;&#xA;&lt;h3 id=&#34;2向量检索的原理&#34;&gt;2）向量检索的原理&lt;/h3&gt;&#xA;&lt;p&gt;由于 Embedding 模型具有将相似语义的词训练成距离相近的向量的特性，我们可以把「用户问题」与「知识库内容」都转成 Embedding 向量。然后计算向量之间的距离。向量之间的距离越小，则语料之间的相似度越高。借助这个原理，最后返回知识库中与问题向量距离最小的 Top-K 份语料即可。&lt;/p&gt;</description>
    </item>
    <item>
      <title>《LangGraph 1.0 完全指南》发布</title>
      <link>https://luochang212.github.io/posts/dive_into_langgraph/</link>
      <pubDate>Sun, 23 Nov 2025 00:00:00 +0000</pubDate>
      <guid>https://luochang212.github.io/posts/dive_into_langgraph/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;经过三个星期的努力，&lt;a href=&#34;https://luochang212.github.io/dive-into-langgraph/&#34; target=&#34;_blank&#34;&gt;《LangGraph 1.0 完全指南》&lt;/a&gt;终于面世啦！&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;p&gt;10 月中旬，LangGraph 1.0 发布。开发团队承诺这是一个稳定版本，未来不会大改。因此，现在正是学习它的好时候。&lt;/p&gt;&#xA;&lt;p&gt;LangGraph 是由 LangChain 团队开发的开源智能体框架。使用时它俩是紧密耦合的：LangChain 提供底层功能，LangGraph 负责状态管理。因此，两个库的文档都需要学习，这无疑加重了使用者的负担。为了让大家快速入门，我将两个库的主要功能提取出来，分成 13 个章节进行介绍。&lt;/p&gt;&#xA;&lt;p&gt;这是一个开源电子书项目，使用 GitHub Action 自动构建，欢迎 &lt;a href=&#34;https://github.com/luochang212/dive-into-langgraph/pulls&#34; target=&#34;_blank&#34;&gt;Pull Request&lt;/a&gt;。如果你觉得本教程对你有帮助，也欢迎 Star 本教程仓库 &lt;a href=&#34;https://github.com/luochang212/dive-into-langgraph&#34; target=&#34;_blank&#34;&gt;luochang212/dive-into-langgraph&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://luochang212.github.io/img/d2lg-overview.png&#34; alt=&#34;overview&#34;&gt;&lt;/p&gt;&#xA;&lt;h3 id=&#34;一在线资源&#34;&gt;一、在线资源&lt;/h3&gt;&#xA;&lt;p&gt;可以通过以下链接，访问本项目的仓库和在线文档：&lt;/p&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;资源&lt;/th&gt;&#xA;          &lt;th&gt;链接&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;GitHub 仓库&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/luochang212/dive-into-langgraph&#34; target=&#34;_blank&#34;&gt;luochang212/dive-into-langgraph&lt;/a&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;电子书&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://luochang212.github.io/dive-into-langgraph/&#34; target=&#34;_blank&#34;&gt;《LangGraph 1.0 完全指南》&lt;/a&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;h3 id=&#34;二章节介绍&#34;&gt;二、章节介绍&lt;/h3&gt;&#xA;&lt;p&gt;本教程的内容速览：&lt;/p&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;序号&lt;/th&gt;&#xA;          &lt;th&gt;章节&lt;/th&gt;&#xA;          &lt;th&gt;主要内容&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://luochang212.github.io/dive-into-langgraph/quickstart/&#34;&gt;快速入门&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;创建你的第一个 ReAct Agent&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;2&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://luochang212.github.io/dive-into-langgraph/stategraph/&#34;&gt;状态图&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;使用 StateGraph 创建工作流&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;3&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://luochang212.github.io/dive-into-langgraph/middleware/&#34;&gt;中间件&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;使用自定义中间件实现四个功能：预算控制、消息截断、敏感词过滤、PII 检测&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://luochang212.github.io/dive-into-langgraph/human_in_the_loop/&#34;&gt;人机交互&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;使用内置的 HITL 中间件实现人机交互&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;5&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://luochang212.github.io/dive-into-langgraph/memory/&#34;&gt;记忆&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;创建短期记忆、长期记忆&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;6&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://luochang212.github.io/dive-into-langgraph/context/&#34;&gt;上下文工程&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;使用 State、Store、Runtime 管理上下文&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;7&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://luochang212.github.io/dive-into-langgraph/mcp_server/&#34;&gt;MCP Server&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;创建 MCP Server 并接入 LangGraph&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;8&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://luochang212.github.io/dive-into-langgraph/supervisor/&#34;&gt;监督者模式&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;两种方法实现监督者模式：tool-calling、langgraph-supervisor&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;9&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://luochang212.github.io/dive-into-langgraph/parallelization/&#34;&gt;并行&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;如何实现并发：节点并发、&lt;code&gt;@task&lt;/code&gt; 装饰器、Map-reduce、Sub-graphs&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;10&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://luochang212.github.io/dive-into-langgraph/rag/&#34;&gt;RAG&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;三种方式实现 RAG：向量检索、关键词检索、混合检索&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;11&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://luochang212.github.io/dive-into-langgraph/web_search/&#34;&gt;网络搜索&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;实现联网搜索：DashScope、Tavily 和 DDGS&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;12&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://luochang212.github.io/dive-into-langgraph/deep_agents/&#34;&gt;Deep Agents&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;简单介绍 Deep Agents&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;13&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://luochang212.github.io/dive-into-langgraph/langgraph_cli/&#34;&gt;调试页面&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;介绍 langgraph-cli 提供的调试页面&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;h3 id=&#34;三拓展阅读&#34;&gt;三、拓展阅读&lt;/h3&gt;&#xA;&lt;p&gt;以下是推荐阅读的文档和教程：&lt;/p&gt;</description>
    </item>
    <item>
      <title>阿里发布新版 Quick BI，聊聊 ChatBI 的底层架构、交互设计和云计算生态</title>
      <link>https://luochang212.github.io/posts/quick_bi_intro/</link>
      <pubDate>Sat, 06 Sep 2025 00:00:00 +0000</pubDate>
      <guid>https://luochang212.github.io/posts/quick_bi_intro/</guid>
      <description>&lt;p&gt;8月28日，阿里云发布了数据分析工具 &lt;a href=&#34;https://cn.aliyun.com/product/quick-bi&#34;&gt;Quick BI&lt;/a&gt; 的全新版本。它是大模型应用在 BI 行业的最新实践。Quick BI 在云计算基础设施之上，搭建了一个 ChatBI 应用。阿里为这个应用起了一个拟人化的名字：智能小Q。智能小Q允许用户以对话的形式探索数据。无需写 SQL，只需与小Q对话，即可获得想要的统计信息。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://luochang212.github.io/img/quick-bi-func.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;智能小Q其实是一个多智能体系统（multi-agent system），包含多个 Agent：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;报告 Agent&lt;/li&gt;&#xA;&lt;li&gt;问数 Agent&lt;/li&gt;&#xA;&lt;li&gt;搭建 Agent&lt;/li&gt;&#xA;&lt;li&gt;解读 Agent&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;这些 Agent 均由领域大模型驱动。&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; 领域大模型经过 SFT、RL 微调，可将业务知识迁移泛化到同类任务中，从而在特定领域获得更优表现。此外，领域大模型的参数量小、推理速度快，也是优势之一。&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;h3 id=&#34;一智能小q能做什么&#34;&gt;一、智能小Q能做什么？&lt;/h3&gt;&#xA;&lt;p&gt;下面介绍智能小Q的两种模式：问数和解读。&lt;/p&gt;&#xA;&lt;h4 id=&#34;1问数界面&#34;&gt;1）问数界面&lt;/h4&gt;&#xA;&lt;p&gt;当用户提问：“店日均杯量是多少？”小Q可以找到数据并可视化，这就是“问数”。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://luochang212.github.io/img/quick-bi-vis.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;h4 id=&#34;2解读界面&#34;&gt;2）解读界面&lt;/h4&gt;&#xA;&lt;p&gt;解读界面允许用户筛选面板中的数据，并基于筛选后的数据向小Q提问。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://luochang212.github.io/img/quick-bi-context.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;将「筛选后的数据」作为上下文向小Q提问有什么优势？&lt;/p&gt;&#xA;&lt;p&gt;一方面，直接引用数据源意味着大模型无需去猜你想分析哪张表，节省了宝贵的 token；另一方面，直接引用提问涉及的数据范围，有助于大模型关注到真正有用的线索，避免大模型因为找不到重点，变得泛泛而谈。&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;在与智能体的对话中，明确引用所指对象是好文明！&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;h3 id=&#34;二拆解-quick-bi-技术路径&#34;&gt;二、拆解 Quick BI 技术路径&lt;/h3&gt;&#xA;&lt;p&gt;Quick BI 的底层架构是 &lt;strong&gt;Agent + 数据库&lt;/strong&gt;。只要有这两个核心模块，你也能做出简易的 ChatBI，这一点在我的开源项目 &lt;a href=&#34;https://github.com/luochang212/clickhouse-chatbi&#34;&gt;luochang212/clickhouse-chatbi&lt;/a&gt; 中亦有记载。其中，Agent 对 Quick BI 的实现尤为关键。&lt;/p&gt;&#xA;&lt;p&gt;先来盘一盘 Agent 框架有哪些能力？&lt;/p&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;能力&lt;/th&gt;&#xA;          &lt;th&gt;技术&lt;/th&gt;&#xA;          &lt;th&gt;代表&lt;/th&gt;&#xA;          &lt;th&gt;偏向&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;路由&lt;/td&gt;&#xA;          &lt;td&gt;Router&lt;/td&gt;&#xA;          &lt;td&gt;ChatGPT&lt;/td&gt;&#xA;          &lt;td&gt;模型&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;检索&lt;/td&gt;&#xA;          &lt;td&gt;RAG&lt;/td&gt;&#xA;          &lt;td&gt;LlamaIndex&lt;/td&gt;&#xA;          &lt;td&gt;工程&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;状态&lt;/td&gt;&#xA;          &lt;td&gt;Session&lt;/td&gt;&#xA;          &lt;td&gt;Google ADK&lt;/td&gt;&#xA;          &lt;td&gt;工程&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;记忆&lt;/td&gt;&#xA;          &lt;td&gt;Memory&lt;/td&gt;&#xA;          &lt;td&gt;Letta&lt;/td&gt;&#xA;          &lt;td&gt;工程&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;交互&lt;/td&gt;&#xA;          &lt;td&gt;ReActChat&lt;/td&gt;&#xA;          &lt;td&gt;Qwen Agent&lt;/td&gt;&#xA;          &lt;td&gt;模型&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;工具&lt;/td&gt;&#xA;          &lt;td&gt;MCP&lt;/td&gt;&#xA;          &lt;td&gt;Claude&lt;/td&gt;&#xA;          &lt;td&gt;工程&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;规划&lt;/td&gt;&#xA;          &lt;td&gt;Supervisor&lt;/td&gt;&#xA;          &lt;td&gt;LangGraph&lt;/td&gt;&#xA;          &lt;td&gt;工程&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;安全&lt;/td&gt;&#xA;          &lt;td&gt;Guardrails&lt;/td&gt;&#xA;          &lt;td&gt;OpenAI Agents&lt;/td&gt;&#xA;          &lt;td&gt;工程&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;p&gt;&lt;em&gt;* 上面的「代表」不是 SOTA 的意思，只是我第一个想到的例子&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>耶是 ClickHouse！我们有救了！！</title>
      <link>https://luochang212.github.io/posts/chat_to_clickhouse/</link>
      <pubDate>Sat, 26 Jul 2025 00:00:00 +0000</pubDate>
      <guid>https://luochang212.github.io/posts/chat_to_clickhouse/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;本来我懒得装，但是 MySQL 太慢了，遭不住，咱还是把 ClickHouse 装起来吧。&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;p&gt;GitHub 项目地址：&lt;a href=&#34;https://github.com/luochang212/chat-to-clickhouse&#34; target=&#34;_blank&#34;&gt;chat-to-clickhouse&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;在&lt;a href=&#34;https://luochang212.github.io/posts/agent_project/&#34;&gt;《Agent 实战：智能路由、任务拆解和链路工程》&lt;/a&gt;一文中，我实现了一个简单的 ChatBI，它能查询 MySQL 数据库。对于小批量数据量，MySQL 尚可应付，但是当数据量来到千万量级时，一次 MySQL 查询将消耗数秒甚至数十秒，这么长的等待时间是用户难以忍受的。而且 Agent 还有一个技术问题，它的 NL2SQL 尚未做到 one-shot，也就是说，在拿到最终结果前，它也许需要多次试错，这将进一步拉长查询时间。&lt;/p&gt;&#xA;&lt;p&gt;如何无痛解决查询效率低下的问题呢？很简单，只需要换数据库就可以做到。这便引入今天的主角：ClickHouse。&lt;/p&gt;&#xA;&lt;h3 id=&#34;一分析利器&#34;&gt;一、分析利器&lt;/h3&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/ClickHouse/ClickHouse&#34;&gt;ClickHouse&lt;/a&gt; 是 Yandex 旗下的一款开源的列式存储数据库，专为 &lt;strong&gt;联机分析处理&lt;/strong&gt; (OLAP) 场景设计。在做数据分析时，它比传统数据库快几倍到几十倍。分析场景的核心需求是「聚合计算」，即 &lt;code&gt;GROUP BY&lt;/code&gt; 子句下的 &lt;code&gt;SUM&lt;/code&gt;, &lt;code&gt;AVG&lt;/code&gt;, &lt;code&gt;COUNT&lt;/code&gt; 操作，这些正是 ClickHouse 的强项。&lt;/p&gt;&#xA;&lt;p&gt;为什么它的聚合计算如此之快呢？因为它具有如下特性：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;列式存储&lt;/strong&gt;：顾名思义，列存的数据是按列存储的。这种存储方式可以减少无效 I/O，因为列存可以只读取查询中涉及的列。而非行存那样，读取整行后再丢掉不需要的列&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;并行计算&lt;/strong&gt;：列存的另一个优势是数据更容易切分。单列数据的连续性和同构性更强，无需考虑与其他列的关联，因此可以更方便地按维度（如时间区间、数值分段）拆分并分配到不同节点。当然，这种设计的代价是使得插入操作变得更加昂贵&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;物化视图&lt;/strong&gt;：物化视图可以把高频分析的结果提前算好存在表里，后续查询直接读结果，无需重新计算&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;二安装过程&#34;&gt;二、安装过程&lt;/h3&gt;&#xA;&lt;p&gt;用 &lt;a href=&#34;https://hub.docker.com/r/clickhouse/clickhouse-server/&#34;&gt;Docker&lt;/a&gt; 安装，过程相对简单。工业界在集群上装，比咱们这个复杂不少。&lt;/p&gt;&#xA;&lt;h4 id=&#34;1-配置-docker-镜像源&#34;&gt;1. 配置 Docker 镜像源&lt;/h4&gt;&#xA;&lt;p&gt;中国大陆地区下载镜像，需要配置镜像源。&lt;/p&gt;&#xA;&lt;p&gt;对于 Linux 系统，需要在 &lt;code&gt;/etc/docker/daemon.json&lt;/code&gt; 文件中配置镜像源（如下）。&lt;code&gt;Windows&lt;/code&gt; 和 &lt;code&gt;MacOS&lt;/code&gt; 系统更方便一点，可以直接在 &lt;code&gt;Docker Desktop&lt;/code&gt; 的 &lt;code&gt;Settings -&amp;gt; Docker Engine&lt;/code&gt; 页面修改 &lt;code&gt;daemon.json&lt;/code&gt; 文件。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Agent 实战：智能路由、任务拆解和链路工程</title>
      <link>https://luochang212.github.io/posts/agent_project/</link>
      <pubDate>Sun, 15 Jun 2025 00:00:00 +0000</pubDate>
      <guid>https://luochang212.github.io/posts/agent_project/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;大模型天生具有幻觉，为了工程的准确性，我们奉行“非必要不Agent”原则。我们是专业的，除非忍不住，否则绝不用 Agent。&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;p&gt;特别声明：本文使用 &lt;a href=&#34;https://github.com/QwenLM/Qwen-Agent&#34;&gt;Qwen Agent&lt;/a&gt; 实现。&lt;/p&gt;&#xA;&lt;p&gt;本文包含以下两个项目：&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;1）智能路由&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;概述&lt;/strong&gt;：如果一个业务可以分很多种情况处理。针对每种情况，我们开发一个工具函数 (Function Calling)，来处理此种情况内部的复杂性。此时，Agent 充当智能路由的角色，将对应的情况路由到对应的工具函数。工具函数内部带有描述信息，Agent 可以访问这些信息，以此判断在何种情况下，调用这个工具函数。&lt;/p&gt;&#xA;&lt;p&gt;具体来讲，本项目开发了一个 &lt;strong&gt;客诉核查 Agent&lt;/strong&gt;。针对 物流逾期 和 假货 两种客诉，分别开发了对应的工具函数。&lt;strong&gt;Agent 通过接入工具函数，获得了核查以上两种客诉真实性的能力&lt;/strong&gt;。当我们将客诉信息传递给 Agent，它会输出针对该客诉的 &lt;strong&gt;核查结论&lt;/strong&gt; 和 &lt;strong&gt;相应证据&lt;/strong&gt;。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;2）数据库查询优化&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;概述&lt;/strong&gt;：数据库查询是一个非常通用的需求，其中 &lt;strong&gt;NL2SQL&lt;/strong&gt; 是难点。为了提升 NL2SQL 的准确性，很容易想到把数据表的 Schema、样例数据、个别字段的枚举值作为上下文 (context) 注入到原始 Prompt 中。本项目实现了这一点。&lt;/p&gt;&#xA;&lt;p&gt;具体来说，本项目做了以下工作：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;启用 Qwen Agent 的 &lt;strong&gt;ReActChat&lt;/strong&gt; 模式，以提升多步骤情况下的性能&lt;/li&gt;&#xA;&lt;li&gt;开发定制的 &lt;strong&gt;Workflow&lt;/strong&gt;，用于将 Schema 等上下文信息注入原始 Prompt 中&lt;/li&gt;&#xA;&lt;li&gt;开发可流式对话的 &lt;strong&gt;Gradio WebUI&lt;/strong&gt;，以方便调试 Agent 和 Workflow&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;✨ 所有代码见 GitHub 仓库：&lt;a href=&#34;https://github.com/luochang212/agent-project&#34;&gt;luochang212/agent-project&lt;/a&gt;&lt;/p&gt;&#xA;&lt;!-- - 智能路由代码见：[intelligent_routing](https://github.com/luochang212/agent-project/tree/main/intelligent_routing)&#xA;- 数据库查询优化代码见：&#xA;    - Agent: [gradio_postgres_agent.py](https://github.com/luochang212/agent-project/blob/main/gradio_postgres_agent.py)&#xA;    - Workflow: [gradio_postgres_workflow.py](https://github.com/luochang212/agent-project/blob/main/gradio_postgres_workflow.py) --&gt;&#xA;&lt;h2 id=&#34;一引言&#34;&gt;一、引言&lt;/h2&gt;&#xA;&lt;h3 id=&#34;1-尚未到来的涌现&#34;&gt;1. 尚未到来的涌现&lt;/h3&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;We always overestimate the change that will occur in the next two years and underestimate the change that will occur in the next ten. &amp;ndash; Bill Gates&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
