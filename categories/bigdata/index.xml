<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>BigData on Chang Luo</title>
    <link>https://luochang212.github.io/categories/bigdata/</link>
    <description>Recent content in BigData on Chang Luo</description>
    <generator>Hugo</generator>
    <language>zh-cn</language>
    <lastBuildDate>Sat, 15 Nov 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://luochang212.github.io/categories/bigdata/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>使用 Docker Compose 部署大数据集群：Spark &#43; Hadoop &#43; Hive &#43; JupyterLab</title>
      <link>https://luochang212.github.io/posts/bigdata_env/</link>
      <pubDate>Sat, 15 Nov 2025 00:00:00 +0000</pubDate>
      <guid>https://luochang212.github.io/posts/bigdata_env/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;麻雀虽小，五脏俱全。&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;p&gt;GitHub 项目地址：&lt;a href=&#34;https://github.com/luochang212/bigdata-env&#34; target=&#34;_blank&#34;&gt;bigdata-env&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h3 id=&#34;引子&#34;&gt;引子&lt;/h3&gt;&#xA;&lt;p&gt;我有两台树莓派。&lt;/p&gt;&#xA;&lt;p&gt;凭借超高颜值，只要安安静静摆在那里，就是超绝桌搭。担心没有实用性？有的兄弟，包有的。装上 &lt;a href=&#34;https://jupyterlab.readthedocs.io/en/stable/&#34;&gt;JupyterLab&lt;/a&gt;，它是数据科学工作站；装上 &lt;a href=&#34;https://www.kali.org/&#34;&gt;Kali Linux&lt;/a&gt;，它是黑客界的瑞士军刀；装上 &lt;a href=&#34;https://github.com/ggml-org/llama.cpp&#34;&gt;llama.cpp&lt;/a&gt;，它是你的私有 LLM 推理服务器。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://luochang212.github.io/img/raspberry_pi_cluster.JPG&#34; alt=&#34;raspberry_pi_cluster&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;你可能不屑一顾，这些事一台树莓派也能办到，何必弄两台呢？看来必须做一些只有两台机器才能办到的事，才算物尽其用。所以我计划部署一个大数据集群。部署大数据集群是一个技术活，不要期待一开始就在硬件上部署。应该先在 Docker Compose 上跑通，再尝试硬件部署。&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; 如果对装机过程感兴趣，可以参考我的博客&lt;a href=&#34;https://luochang212.github.io/posts/raspberry_pi_5/&#34;&gt;《树莓派 5 装机指南》&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;h3 id=&#34;一集群功能&#34;&gt;一、集群功能&lt;/h3&gt;&#xA;&lt;p&gt;「大数据集群」是个宽泛的词儿。&lt;/p&gt;&#xA;&lt;p&gt;装了 Spark 的，是大数据集群；装了 Spark + Hadoop 的，也是大数据集群。那么到底要装到什么程度呢？这取决于我们的需求。作为常年耕作在数据一线的工程师，我认为基础需求包括：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;必须能分布式计算&lt;/li&gt;&#xA;&lt;li&gt;必须能分布式存储&lt;/li&gt;&#xA;&lt;li&gt;必须可以建分区表&lt;/li&gt;&#xA;&lt;li&gt;必须能使用分布式机器学习库 &lt;a href=&#34;https://spark.apache.org/docs/latest/api/python/reference/pyspark.ml.html&#34;&gt;pyspark.ml&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;必须有调度工具（当然 crontab 也算）&lt;/li&gt;&#xA;&lt;li&gt;必须有 JupyterLab&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;我的目标是搭建一个满足这些需求的集群。当然，没有必要从零开始搭建，前人已经有很优秀的工作。只需要基于前人的工作做一些拓展，就能实现我们想要的功能。&lt;a href=&#34;https://github.com/s1mplecc&#34;&gt;s1mplecc&lt;/a&gt; 大佬的&lt;a href=&#34;https://s1mple.cc/2021/10/12/%E4%BD%BF%E7%94%A8-Docker-%E5%BF%AB%E9%80%9F%E9%83%A8%E7%BD%B2-Spark-Hadoop-%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%9B%86%E7%BE%A4/&#34;&gt;《使用 Docker 快速部署 Spark + Hadoop 大数据集群》&lt;/a&gt;就是一个很棒的基础工作。&lt;/p&gt;&#xA;&lt;p&gt;大佬已经实现了 &lt;a href=&#34;https://github.com/s1mplecc/spark-hadoop-docker&#34;&gt;Spark + Hadoop 集群&lt;/a&gt;，我只需要新增以下内容：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;沿用一主（Master）二从（Worker）的配置&lt;/li&gt;&#xA;&lt;li&gt;启用 Worker 节点的 DataNode 以支持数据同步&lt;/li&gt;&#xA;&lt;li&gt;安装 Hive 环境&lt;/li&gt;&#xA;&lt;li&gt;安装并初始化 miniconda3&lt;/li&gt;&#xA;&lt;li&gt;安装与 Spark 版本配适的 Python 和 PySpark&lt;/li&gt;&#xA;&lt;li&gt;安装 JupyterLab&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;主要增加了 Hive、JupyterLab 和 miniconda3。Hive 让我们更轻松地管理分区表；JupyterLab 提供了用于调试开发的浏览器界面；miniconda3 用作 Python 包管理。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Hive SQL 笔记</title>
      <link>https://luochang212.github.io/posts/hive_sql_note/</link>
      <pubDate>Sun, 25 Dec 2022 00:00:00 +0000</pubDate>
      <guid>https://luochang212.github.io/posts/hive_sql_note/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;Hive SQL 不需要注释，它会自己解释自己&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;h3 id=&#34;1-数据表操作&#34;&gt;1. 数据表操作&lt;/h3&gt;&#xA;&lt;h4 id=&#34;11-创建-hive-表&#34;&gt;1.1 创建 Hive 表&lt;/h4&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;CREATE TABLE [DATABASE].[TABLE_NAME] (&#xA;    `id`    BIGINT    COMMENT &amp;#39;学号&amp;#39;,&#xA;    name    STRING    COMMENT &amp;#39;姓名&amp;#39;,&#xA;    ttl_score    DOUBLE    COMMENT &amp;#39;总分&amp;#39;&#xA;)&#xA;COMMENT &amp;#39;枝江中学五年级学生成绩明细表&amp;#39;&#xA;PARTITIONED BY (day STRING COMMENT &amp;#39;day&amp;#39;, hour STRING COMMENT &amp;#39;hour&amp;#39;)&#xA;ROW FORMAT DELIMITED &#xA;FIELDS TERMINATED BY &amp;#39;,&amp;#39; &#xA;STORED AS TEXTFILE;&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: 想了解更多，请参考 &lt;a href=&#34;https://learn.microsoft.com/en-us/azure/databricks/sql/language-manual/sql-ref-syntax-ddl-create-table-hiveformat&#34;&gt;CREATE TABLE with Hive format&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;h4 id=&#34;12-删除-hive-表&#34;&gt;1.2 删除 Hive 表&lt;/h4&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;DROP TABLE [DATABASE].[TABLE_NAME];&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;DROP TABLE IF EXISTS [DATABASE].[TABLE_NAME];&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;ALTER TABLE [DATABASE].[TABLE_NAME] DROP IF EXISTS PARTITION (dt=&amp;#39;2024-09-01&amp;#39;, country=&amp;#39;US&amp;#39;);&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&#34;13-插入新的行&#34;&gt;1.3 插入新的行&lt;/h4&gt;&#xA;&lt;p&gt;从查询结果插入：&lt;/p&gt;</description>
    </item>
    <item>
      <title>漫谈 Hadoop Streaming</title>
      <link>https://luochang212.github.io/posts/hadoop_intro/</link>
      <pubDate>Sat, 25 Jul 2020 00:00:00 +0000</pubDate>
      <guid>https://luochang212.github.io/posts/hadoop_intro/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;本文聚焦如何通过 Hadoop Streaming + Python 编写 Hadoop 程序。&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;!-- [Hadoop](https://hadoop.apache.org/) 是一个用于大数据处理的分布式计算框架。 --&gt;&#xA;&lt;p&gt;众所周知，实现分布式计算是一个繁琐的过程。&lt;a href=&#34;https://hadoop.apache.org/&#34;&gt;Hadoop&lt;/a&gt; 通过一个标准化的数据处理流程，简化操作步骤，让没有分布式计算背景的程序员也能轻松写出分布式程序。Hadoop 本身是用 Java 写的，因此对于非 Java 程序员来说，学 Hadoop 必须先学 Java，这大大降低了 Hadoop 的友好程度。&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://hadoop.apache.org/docs/current/hadoop-streaming/HadoopStreaming.html&#34;&gt;Hadoop Streaming&lt;/a&gt; 就是为了解决这个问题而生的，它支持用其他编程语言编写 Hadoop 程序。&lt;/p&gt;&#xA;&lt;h3 id=&#34;1-分布式系统的由来&#34;&gt;1. 分布式系统的由来&lt;/h3&gt;&#xA;&lt;p&gt;经历半个多世纪的高速增长，半导体工业在本世纪初触及了它的物理瓶颈，摩尔定律失灵，硬件算力不再高速增长，人们开始关注利用软件方法来提升算力。&lt;/p&gt;&#xA;&lt;p&gt;2003年，两名谷歌工程师开发了一个分布式存储系统，这是它的前身。经过几位后来者添枝加叶，该系统在 2006 年开源，并发展成为今天我们熟知的 Hadoop。&lt;/p&gt;&#xA;&lt;p&gt;使用分布式系统，显而易见的好处是能够缩短程序运行的时间。在常规时间就能跑完的程序上使用 Hadoop 无异于画蛇添足。但是对大数据开发人员来说，使用 Hadoop 意味着不必坐在电脑前为了结果等上一整天。如果集群效率够高，完全可能在几分钟内完成单机一天的计算量。&lt;/p&gt;&#xA;&lt;h3 id=&#34;2-hadoop-基本介绍&#34;&gt;2. Hadoop 基本介绍&lt;/h3&gt;&#xA;&lt;p&gt;Hadoop 有两个重要的组成部分：HDFS 和 MapReduce。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;HDFS&lt;/strong&gt; 是一个分布式存储系统，它负责将文件切割成分片，然后分发到集群中的目标机器上进行存储；&lt;strong&gt;MapReduce&lt;/strong&gt; 负责构建一个标准化的数据处理流程，在完成其规定的几道数据处理流程之后，用户将得到他们期望的结果。&lt;/p&gt;&#xA;&lt;p&gt;这意味着 Hadoop 的学习至少包括两个部分。要掌握 HDFS，你需要掌握 Hadoop 命令行命令，这将在第7节详细介绍。要掌握 MapReduce，如果你是 Python 开发者，你需要掌握 Hadoop Streaming，这将在下一节中介绍。&lt;/p&gt;&#xA;&lt;h3 id=&#34;3-mapreduce&#34;&gt;3. MapReduce&lt;/h3&gt;&#xA;&lt;p&gt;MapReduce 的重要性不言而喻，它定义了数据在 Hadoop 中被如何处理。MapReduce 包含三个重要过程：Map, Shuffle 和 Reduce。其中，Map 和 Reduce 由我们来编写，Shuffle 则由系统自动完成。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Elasticsearch 初探</title>
      <link>https://luochang212.github.io/posts/elastic_search/</link>
      <pubDate>Thu, 24 Oct 2019 00:00:00 +0000</pubDate>
      <guid>https://luochang212.github.io/posts/elastic_search/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/elastic/elasticsearch&#34;&gt;Elasticsearch&lt;/a&gt; 是一个开源分布式全文搜索引擎。它建立在当前最先进有效的搜索引擎库 &lt;a href=&#34;https://lucene.apache.org/&#34;&gt;Lucene&lt;/a&gt; 之上。Elasticsearch 集成了 Lucene 的检索功能，并通过一套简单的 API 隐藏了 Lucene 的复杂性，使之简单易用。&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;h2 id=&#34;初识&#34;&gt;初识&lt;/h2&gt;&#xA;&lt;hr&gt;ES 的初步介绍&#xA;&lt;p&gt;本节将介绍 ES 的几个特性。这些介绍能帮助我们理解 ES 是应什么需求诞生的？它解决了什么问题？它为何如此架构？以及这种架构方式为它带来哪些性能上的提升？这些信息虽然不能直接提升我们使用 ES 的能力，但能从更深的维度帮助我们使用好它。&lt;/p&gt;&#xA;&lt;h3 id=&#34;不仅仅是搜索&#34;&gt;不仅仅是搜索&lt;/h3&gt;&#xA;&lt;p&gt;ES 不仅能够搜索，它还提供一套分布式实时存储文档的解决方案。 ES 允许用户将数据存储在多个服务器节点上。这些节点能实时共享数据。一旦主节点的内容发生改变，这些改变会实时传递到副节点上，以保证主副节点的内容一致。如果主节点掉线，ES 能立即选举出一个副节点充当主节点。选举过程就像切换开关一样，能够在瞬间完成，从而保证了 ES 的可靠性。&lt;/p&gt;&#xA;&lt;p&gt;分布式的存储方案不仅仅是基于数据安全的考量，同时也是为了加快检索的速度。利用 &lt;a href=&#34;https://research.google.com/archive/mapreduce-osdi04-slides/index.html&#34;&gt;MapReduce&lt;/a&gt;，ES 可以在多个节点上并行地检索数据，大大缩短了海量数据处理的时间。&lt;/p&gt;&#xA;&lt;h3 id=&#34;领域专用语言&#34;&gt;领域专用语言&lt;/h3&gt;&#xA;&lt;p&gt;为了统一查询语法，ES 设计了一套领域专用语言 (DSL, domain specific language)。这套语言基于 JSON，优点是简单易学，缺点是在表达复杂的查询时，会显得格外冗长，阅读起来也不太友好。&lt;/p&gt;&#xA;&lt;h3 id=&#34;sql-和-nosql&#34;&gt;SQL 和 NoSQL&lt;/h3&gt;&#xA;&lt;p&gt;SQL 全称 Structured Query Language。SQL 中的 Structured 突出了它是结构化的查询语言。结构化即受字段限制。SQL 数据库中的每条数据都具有相同的长度，因此可以被视作一张数据表。&lt;!-- 比如有一组结构化的数据，已知它有3条数据、5个字段，那么我们可以确定它就是一张3乘5的数据表。--&gt;相比于 SQL，NoSQL 能表达更复杂的内部数据结构。字段之间不相互影响，可以拥有各自的层级结构。因此 NoSQL 数据库要比 SQL 数据库更加灵活且易于拓展。NoSQL 数据库中的数据通常用 JSON 表示。&lt;/p&gt;&#xA;&lt;h2 id=&#34;入门&#34;&gt;入门&lt;/h2&gt;&#xA;&lt;hr&gt;一些简单概念&#xA;&lt;h3 id=&#34;文档&#34;&gt;文档&lt;/h3&gt;&#xA;&lt;p&gt;在 ES 中，文档是一个特定的术语。它表示用来存储对象的存储单元。一个对象通常不会是简单的键值对，它可能包含更复杂的数据结构，比如日期、地理数据、数组等。为表达这种复杂的、多层次的数据，ES 将 JSON 作为文档存储的固定格式。也就是说在 ES 里，一个文档被存成一个 JSON 值。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
